from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import AllowAny, IsAuthenticated
from rest_framework.parsers import MultiPartParser, FormParser
from django.http import HttpResponse, Http404
from django.utils import timezone
from django.conf import settings
from django.contrib.auth import get_user_model
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from django.core.cache import cache
import requests
import hmac
import hashlib
import uuid
import os

from chat.serializers import UserSerializer, VideoChatSessionSerializer, VideoChatMessageSerializer, VideoAnalysisCacheSerializer
from chat.models import VideoChatSession, VideoChatMessage, VideoAnalysisCache, Video, User, SocialAccount
from ..utils.chatbot import ChatBot, chatbots
from ..utils.file_utils import process_uploaded_file, summarize_content
from ..utils.error_handlers import get_user_friendly_error_message
from ..services.optimal_response import (
    collect_multi_llm_responses,
    format_optimal_response,
    detect_question_type_from_content
)
from ..services.video_analysis_service import video_analysis_service
from ..enhanced_video_chat_handler import get_video_chat_handler
from ..llm_cache_manager import conversation_context_manager


class ChatView(APIView):
    def post(self, request, bot_name):
        try:
            data = request.data
            user_message = data.get('message')
            uploaded_file = request.FILES.get('file')
            
            if not user_message and not uploaded_file:
                return Response({'error': 'No message or file provided'}, status=status.HTTP_400_BAD_REQUEST)
            
            chatbot = chatbots.get(bot_name)
            if not chatbot:
                print(f"âŒ Invalid bot name: {bot_name}")
                print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(chatbots.keys())[:10]}...")
                return Response({'error': 'Invalid bot name'}, status=status.HTTP_400_BAD_REQUEST)

            # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ì²˜ë¦¬
            if uploaded_file:
                try:
                    print(f"íŒŒì¼ ì—…ë¡œë“œ ê°ì§€: {uploaded_file.name}")
                    
                    # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ì‹ë³„
                    extracted_content = process_uploaded_file(uploaded_file)
                    print(f"ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_content)}ì")
                    print(f"ğŸ“„ ì¶”ì¶œëœ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì): {extracted_content[:200]}...")
                    
                    # Ollamaë¡œ ë¶„ì„ (ì´ë¯¸ì§€ëŠ” ì§ì ‘, í…ìŠ¤íŠ¸ëŠ” ì „ì²´ ë‚´ìš© ì „ë‹¬)
                    print("Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë¶„ì„ ì¤‘...")
                    
                    # ì„ì‹œ íŒŒì¼ ì €ì¥
                    temp_file_path = None
                    if extracted_content.startswith("IMAGE_FILE:"):
                        # ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥
                        import tempfile
                        import shutil
                        temp_dir = tempfile.mkdtemp()
                        temp_file_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(temp_file_path, 'wb') as temp_file:
                            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                            for chunk in uploaded_file.chunks():
                                temp_file.write(chunk)
                        print(f"ì´ë¯¸ì§€ íŒŒì¼ ì„ì‹œ ì €ì¥: {temp_file_path}")
                    
                    # ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•œ ê²½ìš°: ì „ì²´ ë‚´ìš© ì „ë‹¬ (ìš”ì•½í•˜ì§€ ì•ŠìŒ)
                    # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìš”ì•½ ëª¨ë“œ ì‚¬ìš©
                    use_full_content = bool(user_message and user_message.strip())
                    
                    if use_full_content:
                        print(f"ğŸ“‹ ì „ì²´ ë‚´ìš© ëª¨ë“œ: ì¶”ì¶œëœ í…ìŠ¤íŠ¸({len(extracted_content)}ì)ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
                    else:
                        print(f"ğŸ“ ìš”ì•½ ëª¨ë“œ: Ollamaë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")
                    
                    analyzed_content = summarize_content(
                        extracted_content, 
                        file_path=temp_file_path,
                        full_content=use_full_content
                    )
                    
                    print(f"ğŸ“Š ìµœì¢… ë¶„ì„ ë‚´ìš© ê¸¸ì´: {len(analyzed_content)}ì")
                    
                    # ì‚¬ìš©ì ë©”ì‹œì§€ì™€ íŒŒì¼ ë¶„ì„ ê²°ê³¼ë¥¼ ê²°í•©
                    if user_message and user_message.strip():
                        # ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•œ ê²½ìš° - ì „ì²´ ë‚´ìš© ì „ë‹¬
                        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ íŒŒì¼ í•¨ê»˜ ì²˜ë¦¬: {user_message}")
                        if uploaded_file.name.lower().endswith('.pdf'):
                            final_message = f"""ë‹¤ìŒì€ ì—…ë¡œë“œëœ PDF ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì…ë‹ˆë‹¤:

{analyzed_content}

---
ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ìœ„ PDF ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—°ìŠµ ë¬¸ì œê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ê·¸ ì—°ìŠµ ë¬¸ì œë¥¼ ì°¾ì•„ì„œ í’€ì–´ì£¼ì„¸ìš”.
ë¬¸ì„œì˜ ëª¨ë“  ë‚´ìš©ì„ ì£¼ì˜ ê¹Šê²Œ ì½ê³ , ê´€ë ¨ëœ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                        else:
                            # ì´ë¯¸ì§€ì¸ ê²½ìš° (Ollamaê°€ ì˜ì–´ë¡œ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ì—¬ëŸ¬ LLMì´ í•œêµ­ì–´ë¡œ ë‹µë³€)
                            final_message = f"""ë‹¤ìŒì€ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ Ollamaë¡œ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤ (ì˜ì–´):

{analyzed_content}

ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ìœ„ ì˜ì–´ë¡œ ì‘ì„±ëœ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ìì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì˜ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                    else:
                        # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¶„ì„ ìš”ì²­
                        if uploaded_file.name.lower().endswith('.pdf'):
                            final_message = f"ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{analyzed_content}"
                        else:
                            final_message = f"""ë‹¤ìŒì€ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ Ollamaë¡œ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤ (ì˜ì–´):

{analyzed_content}

ìœ„ ì˜ì–´ë¡œ ì‘ì„±ëœ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ìì„¸í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì˜ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                    print("ë¶„ì„ ì™„ë£Œ")
                except Exception as e:
                    print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                    final_message = f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            else:
                final_message = user_message

            # optimal ëª¨ë¸ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
            if bot_name == 'optimal':
                # ì‚¬ìš©ì ì„ íƒ ì‹¬íŒ ëª¨ë¸ (ê¸°ë³¸ê°’: GPT-4o - ë¹ ë¥¸ ì†ë„ + ìš°ìˆ˜í•œ ì„±ëŠ¥)
                judge_model = request.data.get('judge_model', 'GPT-4o')
                
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ LLM ëª¨ë¸ë“¤ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬)
                selected_models = request.data.get('selected_models', None)
                
                # FormDataë¡œ ì „ë‹¬ëœ ê²½ìš° JSON íŒŒì‹±
                if isinstance(selected_models, str):
                    try:
                        import json
                        selected_models = json.loads(selected_models)
                        print(f"ğŸ“‹ JSON íŒŒì‹±ëœ selected_models: {selected_models}")
                    except Exception as e:
                        print(f"âš ï¸ selected_models JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        selected_models = None
                
                # selected_modelsê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
                if selected_models is not None and len(selected_models) == 0:
                    print(f"âš ï¸ selected_modelsê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                    selected_models = None
                
                print(f"ğŸ¯ ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ë“¤: {selected_models}")
                print(f"ğŸ¯ ì‹¬íŒ ëª¨ë¸: {judge_model}")
                print(f"ğŸ“ ì²˜ë¦¬í•  ë©”ì‹œì§€ ê¸¸ì´: {len(final_message)}ì")
                
                # ëª¨ë¸ ë³€ê²½ ê°ì§€ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì²˜ë¦¬
                session_id = request.data.get('user_id', 'default_user')
                
                # ëª¨ë¸ ì´ë¦„ ë§¤í•‘ (í‘œì‹œëª… -> ë‚´ë¶€ëª…)
                model_name_mapping = {
                    'GPT-5': 'gpt-5',
                    'GPT-5-Mini': 'gpt-5-mini',
                    'GPT-4.1': 'gpt-4.1',
                    'GPT-4.1-Mini': 'gpt-4.1-mini',
                    'GPT-4o': 'gpt-4o',
                    'GPT-4o-Mini': 'gpt-4o-mini',
                    'GPT-4-Turbo': 'gpt-4-turbo',
                    'GPT-3.5-Turbo': 'gpt-3.5-turbo',
                    'Gemini-2.5-Pro': 'gemini-2.5-pro',
                    'Gemini-2.5-Flash': 'gemini-2.5-flash',
                    'Gemini-2.0-Flash-Exp': 'gemini-2.0-flash-exp',
                    'Gemini-2.0-Flash-Lite': 'gemini-2.0-flash-lite',
                    'Claude-4-Opus': 'claude-4-opus',
                    'Claude-3.7-Sonnet': 'claude-3.7-sonnet',
                    'Claude-3.5-Sonnet': 'claude-3.5-sonnet',
                    'Claude-3.5-Haiku': 'claude-3.5-haiku',
                    'Claude-3-Opus': 'claude-3-opus',
                    'HCX-003': 'clova-hcx-003',
                    'HCX-DASH-001': 'clova-hcx-dash-001',
                }
                
                if selected_models and len(selected_models) > 0:
                    # ì´ì „ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    previous_models_key = f"previous_models_{session_id}"
                    previous_models = cache.get(previous_models_key, [])
                    
                    # í˜„ì¬ ëª¨ë¸ ëª©ë¡ ì •ê·œí™” (ì •ë ¬í•˜ì—¬ ë¹„êµ)
                    current_models = sorted([m.strip() for m in selected_models if m])
                    previous_models_sorted = sorted([m.strip() for m in previous_models if m]) if previous_models else []
                    
                    # ëª¨ë¸ ë³€ê²½ ì—¬ë¶€ í™•ì¸
                    if previous_models_sorted:
                        # êµì§‘í•© ê³„ì‚° (ê³µí†µ ëª¨ë¸)
                        common_models = set(current_models) & set(previous_models_sorted)
                        
                        # ëª¨ë“  ëª¨ë¸ì´ êµì²´ë˜ì—ˆëŠ”ì§€ í™•ì¸ (êµì§‘í•©ì´ 0ê°œ)
                        all_models_changed = len(common_models) == 0
                        
                        if all_models_changed:
                            print(f"ğŸ”„ ëª¨ë“  ëª¨ë¸ì´ êµì²´ë¨ ê°ì§€! ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")
                            print(f"   ì´ì „ ëª¨ë¸: {previous_models_sorted}")
                            print(f"   í˜„ì¬ ëª¨ë¸: {current_models}")
                            print(f"   ê³µí†µ ëª¨ë¸: {list(common_models)} (0ê°œ)")
                            
                            # 1. ConversationContextManagerì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
                            conversation_context_manager.clear_context(session_id)
                            print(f"   âœ… ConversationContextManager ì´ˆê¸°í™” ì™„ë£Œ")
                            
                            # 2. ëª¨ë“  ChatBot ì¸ìŠ¤í„´ìŠ¤ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (ì´ì „ + í˜„ì¬ ëª¨ë“  ëª¨ë¸)
                            all_models_to_clear = set(previous_models_sorted) | set(current_models)
                            for model_display_name in all_models_to_clear:
                                bot_name = model_name_mapping.get(model_display_name)
                                if bot_name and bot_name in chatbots:
                                    chatbots[bot_name].conversation_history = []
                                    print(f"   âœ… {model_display_name} ({bot_name}) ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")
                            
                            print(f"âœ… ëª¨ë“  ëª¨ë¸ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ ({len(all_models_to_clear)}ê°œ ëª¨ë¸)")
                        else:
                            print(f"âœ”ï¸ ì¼ë¶€ ëª¨ë¸ë§Œ ë³€ê²½ë¨ - ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€")
                            print(f"   ì´ì „ ëª¨ë¸: {previous_models_sorted}")
                            print(f"   í˜„ì¬ ëª¨ë¸: {current_models}")
                            print(f"   ê³µí†µ ëª¨ë¸ ({len(common_models)}ê°œ): {list(common_models)}")
                            print(f"   â†’ 1-2ê°œ ëª¨ë¸ êµì²´ì´ë¯€ë¡œ ì´ì „ ëŒ€í™” ë‚´ìš© ê¸°ì–µ")
                    else:
                        print(f"ğŸ“ ì²« ìš”ì²­ ë˜ëŠ” ì´ì „ ëª¨ë¸ ì •ë³´ ì—†ìŒ")
                    
                    # í˜„ì¬ ëª¨ë¸ ëª©ë¡ì„ ìºì‹œì— ì €ì¥ (ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´)
                    cache.set(previous_models_key, current_models, 3600)  # 1ì‹œê°„ ìœ ì§€
                
                # 1-4ë‹¨ê³„: ì„ íƒëœ LLM ë³‘ë ¬ ì§ˆì˜ â†’ ì‹¬íŒ ëª¨ë¸ ê²€ì¦ â†’ ìµœì  ë‹µë³€ ìƒì„±
                response = None
                try:
                    print(f"ğŸš€ ìµœì  ë‹µë³€ ìƒì„± ì‹œì‘...")
                    print(f"ğŸ“ ì‚¬ìš©ì ë©”ì‹œì§€: {final_message[:200]}...")
                    print(f"ğŸ¯ ì„ íƒëœ ëª¨ë¸: {selected_models}")
                    print(f"âš–ï¸ ì‹¬íŒ ëª¨ë¸: {judge_model}")
                    
                    # ì§ˆë¬¸ ìœ í˜• ê°ì§€
                    has_image = uploaded_file and not uploaded_file.name.lower().endswith('.pdf')
                    has_document = uploaded_file and uploaded_file.name.lower().endswith('.pdf')
                    
                    question_type = None
                    if has_image:
                        question_type = 'image'
                    elif has_document:
                        question_type = 'document'
                    else:
                        question_type = detect_question_type_from_content(final_message)
                    
                    # ëª¨ë“  ëª¨ë¸ êµì²´ ì—¬ë¶€ í™•ì¸
                    all_models_changed = False
                    if selected_models and len(selected_models) > 0:
                        previous_models_key = f"previous_models_{session_id}"
                        previous_models = cache.get(previous_models_key, [])
                        if previous_models:
                            current_models_sorted = sorted([m.strip() for m in selected_models if m])
                            previous_models_sorted = sorted([m.strip() for m in previous_models if m])
                            common_models = set(current_models_sorted) & set(previous_models_sorted)
                            all_models_changed = len(common_models) == 0
                    
                    final_result = collect_multi_llm_responses(
                        final_message, 
                        judge_model, 
                        selected_models, 
                        question_type=question_type,
                        session_id=session_id,
                        clear_history=all_models_changed
                    )
                    print(f"âœ… ìµœì  ë‹µë³€ ìƒì„± ì™„ë£Œ: {type(final_result)}")
                    print(f"âœ… ìµœì  ë‹µë³€ ê²°ê³¼ í‚¤: {list(final_result.keys()) if isinstance(final_result, dict) else 'N/A'}")
                    
                    # ìµœì  ë‹µë³€ ë‚´ìš© í™•ì¸
                    optimal_answer = final_result.get("ìµœì ì˜_ë‹µë³€", "")
                    if not optimal_answer:
                        # optimal_answerê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í‚¤ í™•ì¸
                        optimal_answer = final_result.get("optimal_answer", "")
                    print(f"ğŸ“„ ìµœì  ë‹µë³€ ë‚´ìš© ê¸¸ì´: {len(optimal_answer) if optimal_answer else 0}ì")
                    print(f"ğŸ“„ ìµœì  ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {optimal_answer[:300] if optimal_answer else 'None'}...")
                    
                    # optimal_answerê°€ ìˆìœ¼ë©´ ìµœì ì˜_ë‹µë³€ìœ¼ë¡œ ë³€í™˜
                    if optimal_answer and not final_result.get("ìµœì ì˜_ë‹µë³€"):
                        final_result["ìµœì ì˜_ë‹µë³€"] = optimal_answer
                    
                    # ê²°ê³¼ í¬ë§·íŒ…
                    response = format_optimal_response(final_result)
                    print(f"âœ… ê²°ê³¼ í¬ë§·íŒ… ì™„ë£Œ: {len(response) if response else 0}ì")
                    print(f"âœ… í¬ë§·íŒ…ëœ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:500] if response else 'None'}...")
                    
                    # ëŒ€í™” ë§¥ë½ì— ì¶”ê°€ (session_idëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì„ ì–¸ë¨)
                    conversation_context_manager.add_conversation(
                        session_id=session_id,
                        user_message=final_message,
                        ai_responses=final_result.get('llm_ê²€ì¦_ê²°ê³¼', {}),
                        optimal_response=final_result.get('ìµœì ì˜_ë‹µë³€', '')
                    )
                    
                    # responseê°€ Noneì´ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
                    if not response:
                        print(f"âŒ responseê°€ Noneì…ë‹ˆë‹¤!")
                        response = "ìµœì  ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                    
                    print(f"ğŸ“¤ ìµœì¢… ì‘ë‹µ ë°˜í™˜ (ê¸¸ì´: {len(response) if response else 0}ì)")
                    print(f"ğŸ“¤ ìµœì¢… ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:500] if response else 'None'}...")
                    
                    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë¶„ì„ ë°ì´í„°ë¥¼ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ JSON ë°ì´í„°ë„ í•¨ê»˜ ì „ì†¡
                    return Response({
                        'response': response,
                        'analysisData': final_result.get('llm_ê²€ì¦_ê²°ê³¼', {}),
                        'rationale': final_result.get('ë¶„ì„_ê·¼ê±°', '')
                    })
                    
                except Exception as e:
                    import traceback
                    error_trace = traceback.format_exc()
                    print(f"âŒ ìµœì  ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                    print(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{error_trace}")
                    # í´ë°±: ì‚¬ìš©ì ì¹œí™”ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
                    friendly_error = get_user_friendly_error_message(e)
                    return Response({'response': friendly_error})
            
            # optimal ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°
            # ë¹„ìš© ì ˆì•½: íŒŒì¼ ë¶„ì„ ì‹œ ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            has_image = uploaded_file and not uploaded_file.name.lower().endswith('.pdf')
            has_document = uploaded_file and uploaded_file.name.lower().endswith('.pdf')
            
            # ì§ˆë¬¸ ìœ í˜• ìë™ ê°ì§€
            question_type = None
            if has_image:
                question_type = 'image'
            elif has_document:
                question_type = 'document'
            else:
                question_type = detect_question_type_from_content(final_message)
            
            if uploaded_file and 'íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•´' in final_message:
                # ì´ë¯¸ Ollamaë¡œ ë¶„ì„ëœ ë‚´ìš©ì´ë¯€ë¡œ ê°„ë‹¨í•œ ì‘ë‹µ ìš”ì²­
                simplified_message = f"ë‹¤ìŒ ë¶„ì„ ë‚´ìš©ì— ëŒ€í•´ ê°„ë‹¨í•œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:\n\n{final_message.split('ë‹¤ìŒ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:')[1] if 'ë‹¤ìŒ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:' in final_message else final_message}"
                response = chatbot.chat(simplified_message, has_image=has_image, question_type=question_type)
            else:
                response = chatbot.chat(final_message, has_image=has_image, question_type=question_type)
            
            return Response({'response': response})
        except Exception as e:
            import traceback
            traceback.print_exc()
            # ì‚¬ìš©ì ì¹œí™”ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
            friendly_error = get_user_friendly_error_message(e)
            return Response({'error': friendly_error}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

def generate_unique_username(email, name=None):
    """ì´ë©”ì¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ ì‚¬ìš©ìëª… ìƒì„±"""
    base_username = email.split('@')[0]
    username = base_username
    counter = 1
    
    while User.objects.filter(username=username).exists():
        username = f"{base_username}_{counter}"
        counter += 1
    
    return username

