from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import AllowAny, IsAuthenticated
from rest_framework.parsers import MultiPartParser, FormParser
from django.http import HttpResponse, Http404
from django.utils import timezone
from django.conf import settings
from django.contrib.auth import get_user_model
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
import requests
import hmac
import hashlib
import uuid
import os

from chat.serializers import UserSerializer, VideoChatSessionSerializer, VideoChatMessageSerializer, VideoAnalysisCacheSerializer
from chat.models import VideoChatSession, VideoChatMessage, VideoAnalysisCache, Video, User, SocialAccount
from ..utils.chatbot import ChatBot, chatbots
from ..utils.file_utils import process_uploaded_file, summarize_content
from ..services.optimal_response import collect_multi_llm_responses, format_optimal_response
from ..services.video_analysis_service import video_analysis_service
from ..enhanced_video_chat_handler import get_video_chat_handler


class VideoChatView(APIView):
    """ì˜ìƒ ì±„íŒ… ë·° - ë‹¤ì¤‘ AI ì‘ë‹µ ë° í†µí•©"""
    permission_classes = [AllowAny]  # ì„ì‹œë¡œ AllowAnyë¡œ ë³€ê²½
    
    def get(self, request, video_id=None):
        """ì±„íŒ… ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
        try:
            print(f"ğŸ” VideoChatView GET ìš”ì²­ - video_id: {video_id}")
            
            # ì‚¬ìš©ì ì •ë³´ ì²˜ë¦¬ (ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‚¬ìš©ì ì‚¬ìš©)
            user = None
            if hasattr(request, 'user') and request.user.is_authenticated:
                user = request.user
            else:
                # ê¸°ë³¸ ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                from chat.models import User
                user, created = User.objects.get_or_create(
                    username='anonymous',
                    defaults={'email': 'anonymous@example.com'}
                )
                print(f"âœ… ê¸°ë³¸ ì‚¬ìš©ì ìƒì„±/ê°€ì ¸ì˜¤ê¸°: {user.username}")
            
            if video_id:
                # íŠ¹ì • ì˜ìƒì˜ ì±„íŒ… ì„¸ì…˜ ì¡°íšŒ
                sessions = VideoChatSession.objects.filter(
                    user=user, 
                    video_id=video_id,
                    is_active=True
                ).order_by('-created_at')
            else:
                # ì‚¬ìš©ìì˜ ëª¨ë“  ì±„íŒ… ì„¸ì…˜ ì¡°íšŒ
                sessions = VideoChatSession.objects.filter(
                    user=user,
                    is_active=True
                ).order_by('-created_at')
            
            serializer = VideoChatSessionSerializer(sessions, many=True)
            return Response({
                'sessions': serializer.data,
                'total_count': sessions.count()
            })
            
        except Exception as e:
            return Response({
                'error': f'ì±„íŒ… ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def post(self, request, video_id):
        """ì˜ìƒ ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡"""
        try:
            print(f"ğŸ” VideoChatView POST ìš”ì²­ - video_id: {video_id}")
            # Django WSGIRequestì—ì„œ JSON ë°ì´í„° íŒŒì‹±
            import json
            if hasattr(request, 'data'):
                message = request.data.get('message')
            else:
                body = request.body.decode('utf-8')
                data = json.loads(body)
                message = data.get('message')
            print(f"ğŸ“ ë©”ì‹œì§€: {message}")
            
            if not message:
                return Response({
                    'error': 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ì˜ìƒ ë¶„ì„ ìƒíƒœ í™•ì¸ (Video ëª¨ë¸ì—ì„œ ì§ì ‘ í™•ì¸)
            try:
                video = Video.objects.get(id=video_id)
                if video.analysis_status == 'pending':
                    return Response({
                        'error': 'ì˜ìƒ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
                        'status': 'analyzing'
                    }, status=status.HTTP_202_ACCEPTED)
                elif video.analysis_status == 'failed':
                    return Response({
                        'error': 'ì˜ìƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.',
                        'status': 'failed'
                    }, status=status.HTTP_400_BAD_REQUEST)
            except Video.DoesNotExist:
                return Response({
                    'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ì‚¬ìš©ì ì •ë³´ ì²˜ë¦¬ (ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‚¬ìš©ì ì‚¬ìš©)
            user = request.user if request.user.is_authenticated else None
            if not user:
                # ê¸°ë³¸ ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                from chat.models import User
                user, created = User.objects.get_or_create(
                    username='anonymous',
                    defaults={'email': 'anonymous@example.com'}
                )
            
            # ì±„íŒ… ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            session, created = VideoChatSession.objects.get_or_create(
                user=user,
                video_id=video_id,
                is_active=True,
                defaults={
                    'video_title': f"Video {video_id}",
                    'video_analysis_data': {}
                }
            )
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            user_message = VideoChatMessage.objects.create(
                session=session,
                message_type='user',
                content=message
            )
            
            # ğŸ¯ ê°œì„ ëœ í•¸ë“¤ëŸ¬ ì‚¬ìš©
            print(f"ğŸ” ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ ì‚¬ìš©: '{message}'")
            handler = get_video_chat_handler(video_id, video)
            chat_result = handler.process_message(message)
            
            # AI ê°œë³„ ì‘ë‹µ ì €ì¥
            individual_messages = []
            print(f"ğŸ” chat_result['individual_responses']: {chat_result.get('individual_responses')}")
            if chat_result.get('individual_responses'):
                print(f"âœ… ê°œë³„ ì‘ë‹µ {len(chat_result['individual_responses'])}ê°œ ë°œê²¬")
                for ai_name, ai_content in chat_result['individual_responses'].items():
                    print(f"  - {ai_name}: {ai_content[:100] if ai_content else 'None'}...")
                    ai_message = VideoChatMessage.objects.create(
                        session=session,
                        message_type='ai',
                        content=ai_content,
                        ai_model=ai_name,
                        parent_message=user_message
                    )
                    individual_messages.append(ai_message)
            else:
                print(f"âš ï¸ individual_responsesê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            
            # í†µí•© ì‘ë‹µ ì €ì¥
            optimal_response = chat_result.get('answer', '')
            optimal_message = None
            if optimal_response:
                optimal_message = VideoChatMessage.objects.create(
                    session=session,
                    message_type='ai_optimal',
                    content=optimal_response,
                    ai_model='optimal',
                    parent_message=user_message
                )
            
            # í”„ë ˆì„ ì •ë³´ êµ¬ì„±
            relevant_frames = []
            if chat_result.get('frames'):
                # ë©”íƒ€ DBì—ì„œ ì „ì²´ í”„ë ˆì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì˜ìƒë³„ ë™ì  ê²½ë¡œ)
                meta_db_filename = f"{video.original_name or video.filename}-meta_db.json"
                meta_db_path = os.path.join(settings.MEDIA_ROOT, meta_db_filename)
                all_frames = []
                if os.path.exists(meta_db_path):
                    try:
                        with open(meta_db_path, 'r', encoding='utf-8') as f:
                            meta_data = json.load(f)
                            all_frames = meta_data.get('frame', [])
                    except Exception as meta_error:
                        logger.warning(f"ë©”íƒ€ DB ë¡œë“œ ì‹¤íŒ¨({meta_db_path}): {meta_error}")
                else:
                    logger.warning(f"ë©”íƒ€ DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {meta_db_path}")
                
                for idx, frame in enumerate(chat_result['frames']):
                    meta_frame = None
                    if all_frames:
                        # timestamp ê¸°ì¤€ìœ¼ë¡œ ë©”íƒ€ í”„ë ˆì„ ì°¾ê¸°
                        for candidate in all_frames:
                            if abs(candidate.get('timestamp', 0) - frame.get('timestamp', 0)) < 0.1:
                                meta_frame = candidate
                                break
                    
                    # ì´ë¯¸ì§€ ê²½ë¡œì™€ ID ê²°ì •
                    image_id = frame.get('image_id')
                    if not image_id and meta_frame:
                        image_id = meta_frame.get('image_id')
                    if not image_id:
                        image_id = idx + 1
                    
                    frame_image_path = frame.get('frame_image_path')
                    if not frame_image_path and meta_frame:
                        frame_image_path = meta_frame.get('frame_image_path')
                    if not frame_image_path:
                        frame_image_path = f"images/video{video_id}_frame{image_id}.jpg"
                    frame_image_path = frame_image_path.lstrip('/')
                    
                    raw_objects = frame.get('objects', []) or []
                    persons = frame.get('persons')
                    if persons is None:
                        persons = [obj for obj in raw_objects if obj.get('class') == 'person']
                    
                    other_objects = frame.get('detected_other_objects')
                    if other_objects is None:
                        other_objects = [obj for obj in raw_objects if obj.get('class') != 'person']
                    
                    frame_info = {
                        'image_id': image_id,
                        'timestamp': frame.get('timestamp', 0),
                        'image_url': f"/media/{frame_image_path}",
                        'caption': frame.get('caption', ''),
                        'relevance_score': frame.get('match_score', 1.0),
                        'persons': persons[:3] if persons else [],
                        'objects': other_objects,
                        'scene_attributes': {
                            'scene_type': 'unknown',
                            'lighting': 'unknown',
                            'activity_level': 'unknown'
                        }
                    }
                    relevant_frames.append(frame_info)
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„± (í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ì— ë§ì¶¤)
            response_data = {
                'session_id': str(session.id),
                'user_message': {
                    'id': str(user_message.id),
                    'content': message,
                    'created_at': user_message.created_at.isoformat()
                },
                'ai_responses': {
                    'individual': [
                        {
                            'id': str(msg.id),
                            'model': msg.ai_model,
                            'content': msg.content,
                            'created_at': msg.created_at.isoformat()
                        } for msg in individual_messages
                    ],
                    'optimal': {
                        'id': str(optimal_message.id) if optimal_message else None,
                        'model': 'optimal',
                        'content': optimal_response,
                        'created_at': optimal_message.created_at.isoformat() if optimal_message else None
                    } if optimal_response else None
                },
                'relevant_frames': relevant_frames,
                'is_video_related': chat_result.get('is_video_related', True)
            }
            
            print(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ:")
            print(f"   - ê°œë³„ AI: {len(individual_messages)}ê°œ")
            print(f"   - í†µí•© ì‘ë‹µ: {'ìˆìŒ' if optimal_response else 'ì—†ìŒ'}")
            print(f"   - ê´€ë ¨ í”„ë ˆì„: {len(relevant_frames)}ê°œ")
            
            return Response(response_data)
            
        except Exception as e:
            import traceback
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"âŒ ìƒì„¸: {traceback.format_exc()}")
            return Response({
                'error': f'ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ì˜ìƒ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Video ëª¨ë¸ì—ì„œ ì§ì ‘)
            analysis_data = {
                'original_name': video.original_name,
                'file_size': video.file_size,
                'uploaded_at': video.uploaded_at.isoformat(),
                'analysis_status': video.analysis_status,
                'duration': video.duration,
                'is_analyzed': video.is_analyzed
            }
            
            # JSON ë¶„ì„ ê²°ê³¼ ë¡œë“œ (ê¸°ì¡´ + TeletoVision_AI ìŠ¤íƒ€ì¼)
            analysis_json_data = None
            teleto_vision_data = {}
            
            # 1. ê¸°ì¡´ ë¶„ì„ JSON ë¡œë“œ
            if video.analysis_json_path:
                try:
                    json_path = os.path.join(settings.MEDIA_ROOT, video.analysis_json_path)
                    print(f"ğŸ” ê¸°ì¡´ JSON íŒŒì¼ ê²½ë¡œ: {json_path}")
                    print(f"ğŸ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(json_path)}")
                    
                    with open(json_path, 'r', encoding='utf-8') as f:
                        analysis_json_data = json.load(f)
                    print(f"âœ… ê¸°ì¡´ JSON ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì„±ê³µ: {json_path}")
                    print(f"ğŸ“Š ê¸°ì¡´ JSON ë°ì´í„° í‚¤: {list(analysis_json_data.keys())}")
                    if 'frame_results' in analysis_json_data:
                        print(f"ğŸ“Š frame_results ê°œìˆ˜: {len(analysis_json_data['frame_results'])}")
                        if analysis_json_data['frame_results']:
                            print(f"ğŸ“Š ì²« ë²ˆì§¸ í”„ë ˆì„: {analysis_json_data['frame_results'][0]}")
                except Exception as e:
                    print(f"âŒ ê¸°ì¡´ JSON ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    import traceback
                    print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            else:
                print("âŒ analysis_json_pathê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. TeletoVision_AI ìŠ¤íƒ€ì¼ JSON ë¡œë“œ
            try:
                video_name = video.original_name or video.filename
                detection_db_path = os.path.join(settings.MEDIA_ROOT, f"{video_name}-detection_db.json")
                meta_db_path = os.path.join(settings.MEDIA_ROOT, f"{video_name}-meta_db.json")
                
                print(f"ğŸ” TeletoVision detection_db ê²½ë¡œ: {detection_db_path}")
                print(f"ğŸ” TeletoVision meta_db ê²½ë¡œ: {meta_db_path}")
                
                # detection_db.json ë¡œë“œ
                if os.path.exists(detection_db_path):
                    with open(detection_db_path, 'r', encoding='utf-8') as f:
                        teleto_vision_data['detection_db'] = json.load(f)
                    print(f"âœ… TeletoVision detection_db ë¡œë“œ ì„±ê³µ: {len(teleto_vision_data['detection_db'])}ê°œ í”„ë ˆì„")
                else:
                    print(f"âŒ TeletoVision detection_db íŒŒì¼ ì—†ìŒ: {detection_db_path}")
                
                # meta_db.json ë¡œë“œ
                if os.path.exists(meta_db_path):
                    with open(meta_db_path, 'r', encoding='utf-8') as f:
                        teleto_vision_data['meta_db'] = json.load(f)
                    print(f"âœ… TeletoVision meta_db ë¡œë“œ ì„±ê³µ: {len(teleto_vision_data['meta_db'].get('frame', []))}ê°œ í”„ë ˆì„")
                    if teleto_vision_data['meta_db'].get('frame'):
                        first_frame = teleto_vision_data['meta_db']['frame'][0]
                        print(f"ğŸ“Š ì²« ë²ˆì§¸ meta í”„ë ˆì„ í‚¤: {list(first_frame.keys())}")
                else:
                    print(f"âŒ TeletoVision meta_db íŒŒì¼ ì—†ìŒ: {meta_db_path}")
                    
            except Exception as e:
                print(f"âŒ TeletoVision JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
                import traceback
                print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                teleto_vision_data = {}
                print(f"âŒ video.analysis_json_path: {video.analysis_json_path}")
            
            # í”„ë ˆì„ ê²€ìƒ‰ ë° ì´ë¯¸ì§€ URL ìƒì„±
            print(f"ğŸ” í”„ë ˆì„ ê²€ìƒ‰ ì‹œì‘ - analysis_json_data: {analysis_json_data is not None}")
            if analysis_json_data:
                print(f"ğŸ“Š frame_results ì¡´ì¬: {'frame_results' in analysis_json_data}")
                if 'frame_results' in analysis_json_data:
                    print(f"ğŸ“Š frame_results ê°œìˆ˜: {len(analysis_json_data['frame_results'])}")
            else:
                print("âŒ analysis_json_dataê°€ Noneì…ë‹ˆë‹¤!")
                print(f"âŒ video.analysis_json_path: {video.analysis_json_path}")
                print(f"âŒ video.analysis_status: {video.analysis_status}")
                print(f"âŒ video.is_analyzed: {video.is_analyzed}")
            
            # ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
            session_id = f"video_{video_id}_user_{user.id}"
            context_prompt = conversation_memory.generate_context_prompt(session_id, message)
            
            # í”„ë ˆì„ ê²€ìƒ‰ (ì˜ë„ ê¸°ë°˜)
            relevant_frames = self._find_relevant_frames(message, analysis_json_data, video_id)
            print(f"ğŸ” ê²€ìƒ‰ëœ í”„ë ˆì„ ìˆ˜: {len(relevant_frames)}")
            if relevant_frames:
                print(f"ğŸ“¸ ì²« ë²ˆì§¸ í”„ë ˆì„: {relevant_frames[0]}")
                print(f"ğŸ“¸ ëª¨ë“  í”„ë ˆì„ ì •ë³´:")
                for i, frame in enumerate(relevant_frames):
                    print(f"  í”„ë ˆì„ {i+1}: {frame}")
            else:
                print("âŒ ê²€ìƒ‰ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤!")
                print(f"âŒ analysis_json_data keys: {list(analysis_json_data.keys()) if analysis_json_data else 'None'}")
                if analysis_json_data and 'frame_results' in analysis_json_data:
                    print(f"âŒ frame_results ê°œìˆ˜: {len(analysis_json_data['frame_results'])}")
                    if analysis_json_data['frame_results']:
                        print(f"âŒ ì²« ë²ˆì§¸ frame_result: {analysis_json_data['frame_results'][0]}")
            
            # ë‹¤ì¤‘ AI ì‘ë‹µ ìƒì„±
            ai_responses = {}
            individual_messages = []
            
            # ê¸°ë³¸ ì±„íŒ… ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ AI ëª¨ë¸ ì´ˆê¸°í™”
            try:
                # ì „ì—­ chatbots ë³€ìˆ˜ ì‚¬ìš© (ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŒ)
                print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸: {list(chatbots.keys())}")
            except Exception as e:
                print(f"âš ï¸ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # ì „ì—­ chatbots ë³€ìˆ˜ëŠ” ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë®ì–´ì“°ì§€ ì•ŠìŒ
            
            # AI ëª¨ë¸ í™•ì¸
            print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸: {list(chatbots.keys()) if chatbots else 'None'}")
            
            # AI ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì‘ë‹µ (í”„ë ˆì„ ì •ë³´ í¬í•¨)
            if not chatbots:
                print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
                
                # í”„ë ˆì„ ì •ë³´ë¥¼ í¬í•¨í•œ ë” ë‚˜ì€ ì‘ë‹µ ìƒì„±
                if relevant_frames:
                    frame_count = len(relevant_frames)
                    default_response = f"ì˜ìƒì—ì„œ '{message}'ì™€ ê´€ë ¨ëœ {frame_count}ê°œì˜ í”„ë ˆì„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n\n"
                    
                    for i, frame in enumerate(relevant_frames, 1):
                        default_response += f"ğŸ“¸ í”„ë ˆì„ {i}:\n"
                        default_response += f"   â° ì‹œê°„: {frame['timestamp']:.1f}ì´ˆ\n"
                        default_response += f"   ğŸ¯ ê´€ë ¨ë„: {frame['relevance_score']}ì \n"
                        
                        if frame['persons'] and len(frame['persons']) > 0:
                            default_response += f"   ğŸ‘¤ ì‚¬ëŒ {len(frame['persons'])}ëª… ê°ì§€\n"
                        
                        if frame['objects'] and len(frame['objects']) > 0:
                            default_response += f"   ğŸ“¦ ê°ì²´ {len(frame['objects'])}ê°œ ê°ì§€\n"
                        
                        scene_attrs = frame.get('scene_attributes', {})
                        if scene_attrs:
                            scene_type = scene_attrs.get('scene_type', 'unknown')
                            lighting = scene_attrs.get('lighting', 'unknown')
                            activity = scene_attrs.get('activity_level', 'unknown')
                            default_response += f"   ğŸï¸ ì¥ë©´: {scene_type}, ì¡°ëª…: {lighting}, í™œë™: {activity}\n"
                        
                        default_response += "\n"
                    
                    default_response += "ğŸ’¡ AI ëª¨ë¸ì´ í™œì„±í™”ë˜ë©´ ë” ìì„¸í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                else:
                    default_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì™€ ê´€ë ¨ëœ í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                    default_response += "ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”:\n"
                    default_response += "â€¢ ì‚¬ëŒ, ìë™ì°¨, ë™ë¬¼, ìŒì‹, ì˜·, ê±´ë¬¼, ìì—°, ë¬¼ì²´"
                
                ai_responses = {
                    'default': default_response
                }
            else:
                # ê° AI ëª¨ë¸ì— ì§ˆë¬¸ ì „ì†¡
                for bot_name, chatbot in chatbots.items():
                    if bot_name == 'optimal':
                        continue  # optimalì€ ë‚˜ì¤‘ì— ì²˜ë¦¬
                    
                    try:
                        # ìƒ‰ìƒ ê²€ìƒ‰ ëª¨ë“œ í™•ì¸
                        is_color_search = any(keyword in message.lower() for keyword in ['ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ë³´ë¼ìƒ‰', 'ë¶„í™ìƒ‰', 'ê²€ì€ìƒ‰', 'í°ìƒ‰', 'íšŒìƒ‰', 'ì£¼í™©ìƒ‰', 'ê°ˆìƒ‰', 'ì˜·'])
                        
                        # ê°„ì†Œí™”ëœ ì˜ìƒ ì •ë³´ í”„ë¡¬í”„íŠ¸ ìƒì„±
                        video_context = f"""
ì˜ìƒ: {analysis_data.get('original_name', 'Unknown')} ({analysis_data.get('file_size', 0) / (1024*1024):.1f}MB)
ë¶„ì„: {len(analysis_json_data.get('frame_results', []))}ê°œ í”„ë ˆì„, {analysis_json_data.get('video_summary', {}).get('total_detections', 0)}ê°œ ê°ì²´
í’ˆì§ˆ: {analysis_json_data.get('video_summary', {}).get('quality_assessment', {}).get('overall_score', 0):.2f}
"""
                        
                        # ê°„ì†Œí™”ëœ í”„ë ˆì„ ì •ë³´
                        frame_context = ""
                        if relevant_frames:
                            frame_context = f"\nê´€ë ¨ í”„ë ˆì„ {len(relevant_frames)}ê°œ:\n"
                            for i, frame in enumerate(relevant_frames[:2], 1):  # ìµœëŒ€ 2ê°œë§Œ
                                frame_context += f"í”„ë ˆì„ {i}: {frame['timestamp']:.1f}ì´ˆ, ì‚¬ëŒ {len(frame.get('persons', []))}ëª…\n"
                        else:
                            frame_context = "\nê´€ë ¨ í”„ë ˆì„ ì—†ìŒ\n"
                        
                        enhanced_message = f"""{video_context}{frame_context}

ì‚¬ìš©ì ì§ˆë¬¸: "{message}"

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                        
                        # ê°„ì†Œí™”ëœ AI í”„ë¡¬í”„íŠ¸
                        ai_prompt = enhanced_message
                        
                        # AIë³„ íŠ¹ì„±í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±
                        ai_response = chatbot.chat(ai_prompt)
                        ai_responses[bot_name] = ai_response
                        
                        # ê°œë³„ AI ì‘ë‹µ ì €ì¥
                        ai_message = VideoChatMessage.objects.create(
                            session=session,
                            message_type='ai',
                            content=ai_response,
                            ai_model=bot_name,
                            parent_message=user_message
                        )
                        individual_messages.append(ai_message)
                        
                    except Exception as e:
                        print(f"AI {bot_name} ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        continue
            
            # í†µí•© ì‘ë‹µ ìƒì„± (ê¸°ë³¸ ì±„íŒ… ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë°©ì‹)
            optimal_response = ""
            if ai_responses and len(ai_responses) > 1:
                try:
                    # ê¸°ë³¸ ì±„íŒ… ì‹œìŠ¤í…œì˜ generate_optimal_response ì‚¬ìš©
                    optimal_response = generate_optimal_response(ai_responses, message, os.getenv('OPENAI_API_KEY'))
                    
                    # í”„ë ˆì„ ì •ë³´ ì¶”ê°€ (ë” ìì„¸í•œ ì •ë³´ í¬í•¨)
                    if relevant_frames:
                        frame_summary = f"\n\nğŸ“¸ ê´€ë ¨ í”„ë ˆì„ {len(relevant_frames)}ê°œ ë°œê²¬:\n"
                        for i, frame in enumerate(relevant_frames, 1):
                            frame_summary += f"â€¢ í”„ë ˆì„ {i}: {frame['timestamp']:.1f}ì´ˆ (ê´€ë ¨ë„ {frame['relevance_score']:.2f}ì )\n"
                            
                            # í”„ë ˆì„ë³„ ì„¸ë¶€ ì •ë³´ ì¶”ê°€
                            if frame.get('persons'):
                                frame_summary += f"  ğŸ‘¤ ì‚¬ëŒ {len(frame['persons'])}ëª… ê°ì§€ë¨!\n"
                                # ê° ì‚¬ëŒì˜ ìƒì„¸ ì •ë³´ ì¶”ê°€
                                for j, person in enumerate(frame['persons'], 1):
                                    confidence = person.get('confidence', 0)
                                    frame_summary += f"    ì‚¬ëŒ {j}: ì‹ ë¢°ë„ {confidence:.2f}\n"
                                    # ì†ì„± ì •ë³´ ì¶”ê°€
                                    attrs = person.get('attributes', {})
                                    if 'gender' in attrs:
                                        gender_info = attrs['gender']
                                        frame_summary += f"      ì„±ë³„: {gender_info.get('value', 'unknown')}\n"
                                    if 'age' in attrs:
                                        age_info = attrs['age']
                                        frame_summary += f"      ë‚˜ì´: {age_info.get('value', 'unknown')}\n"
                            if frame.get('objects'):
                                frame_summary += f"  ğŸ“¦ ê°ì²´ {len(frame['objects'])}ê°œ ê°ì§€\n"
                            
                            scene_attrs = frame.get('scene_attributes', {})
                            if scene_attrs:
                                scene_type = scene_attrs.get('scene_type', 'unknown')
                                lighting = scene_attrs.get('lighting', 'unknown')
                                frame_summary += f"  ğŸï¸ ì¥ë©´: {scene_type}, ì¡°ëª…: {lighting}\n"
                        
                        frame_summary += "\nğŸ’¡ ìœ„ í”„ë ˆì„ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì˜ìƒì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•´ë³´ì„¸ìš”."
                        optimal_response += frame_summary
                    
                    # í†µí•© ì‘ë‹µ ì €ì¥
                    optimal_message = VideoChatMessage.objects.create(
                        session=session,
                        message_type='ai_optimal',
                        content=optimal_response,
                        ai_model='optimal',
                        parent_message=user_message
                    )
                    
                except Exception as e:
                    print(f"í†µí•© ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    optimal_response = f"í†µí•© ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            elif ai_responses and len(ai_responses) == 1:
                # AI ì‘ë‹µì´ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš°
                optimal_response = list(ai_responses.values())[0]
            
            # ì‘ë‹µ í’ˆì§ˆ í‰ê°€
            evaluation_results = {}
            if ai_responses and len(ai_responses) > 1:
                try:
                    evaluation_results = evaluation_metrics.evaluate_summary_quality(
                        ai_responses, reference=optimal_response
                    )
                    print(f"âœ… ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: {len(evaluation_results)}ê°œ AI")
                except Exception as e:
                    print(f"âŒ ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            
            # ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸
            try:
                conversation_memory.add_context(
                    session_id=session_id,
                    user_message=message,
                    ai_responses=ai_responses,
                    video_context={
                        'video_id': video_id,
                        'video_name': video.original_name,
                        'relevant_frames_count': len(relevant_frames)
                    }
                )
                print(f"âœ… ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            response_data = {
                'session_id': str(session.id),
                'user_message': {
                    'id': str(user_message.id),
                    'content': message,
                    'created_at': user_message.created_at
                },
                'ai_responses': {
                    'individual': [
                        {
                            'id': str(msg.id),
                            'model': msg.ai_model,
                            'content': msg.content,
                            'created_at': msg.created_at
                        } for msg in individual_messages
                    ],
                    'optimal': {
                        'content': optimal_response,
                        'created_at': individual_messages[0].created_at if individual_messages else None
                    } if optimal_response else None
                },
                'relevant_frames': relevant_frames,  # ê´€ë ¨ í”„ë ˆì„ ì •ë³´ ì¶”ê°€
                'evaluation_results': evaluation_results,  # í’ˆì§ˆ í‰ê°€ ê²°ê³¼
                'context_info': {
                    'session_id': session_id,
                    'context_length': len(conversation_memory.get_context(session_id).get('conversations', []))
                }
            }
            
            # ë””ë²„ê¹…: relevant_frames í™•ì¸
            print(f"ğŸ” ì‘ë‹µ ìƒì„± ì‹œ relevant_frames: {len(relevant_frames)}")
            if relevant_frames:
                print(f"ğŸ“¸ ì²« ë²ˆì§¸ í”„ë ˆì„: {relevant_frames[0]}")
            else:
                print("âŒ relevant_framesê°€ ë¹„ì–´ìˆìŒ!")
            
            print(f"ğŸ“¤ ì‘ë‹µì— í¬í•¨ë  í”„ë ˆì„ ìˆ˜: {len(relevant_frames)}")
            if relevant_frames:
                print(f"ğŸ“¸ ì²« ë²ˆì§¸ í”„ë ˆì„: {relevant_frames[0]}")
            
            return Response(response_data)
            
        except Exception as e:
            import traceback
            print(f"âŒ VideoChatView POST ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            return Response({
                'error': f'ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'traceback': traceback.format_exc()
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _classify_intent(self, message):
        """ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜"""
        try:
            message_lower = message.lower()
            
            # ì˜ë„ë³„ í‚¤ì›Œë“œ ì •ì˜
            intent_keywords = {
                'video_summary': ['ìš”ì•½', 'summary', 'ê°„ë‹¨', 'ìƒì„¸', 'í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì •ë¦¬'],
                'video_search': ['ì°¾ì•„', 'ê²€ìƒ‰', 'search', 'ë³´ì—¬', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„ê°€'],
                'person_search': ['ì‚¬ëŒ', 'person', 'people', 'human', 'ë‚¨ì„±', 'ì—¬ì„±', 'ì„±ë³„'],
                'color_search': ['ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ë³´ë¼ìƒ‰', 'ë¶„í™ìƒ‰', 'ê²€ì€ìƒ‰', 'í°ìƒ‰', 'íšŒìƒ‰', 'ì£¼í™©ìƒ‰', 'ê°ˆìƒ‰', 'ìƒ‰ê¹”', 'ìƒ‰ìƒ', 'ì˜·', 'ì…ì€', 'ì°©ìš©'],
                'temporal_analysis': ['ì‹œê°„', 'ë¶„', 'ì´ˆ', 'ì–¸ì œ', 'ëª‡ì‹œ', 'ì„±ë¹„', 'ì¸ì›', 'í†µê³„'],
                'inter_video_search': ['ë¹„ì˜¤ëŠ”', 'ë°¤', 'ë‚®', 'ë‚ ì”¨', 'ì¡°ëª…', 'ì˜ìƒê°„', 'ë‹¤ë¥¸ì˜ìƒ'],
                'general_chat': ['ì•ˆë…•', 'hello', 'hi', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'ë„ì›€', 'ì§ˆë¬¸']
            }
            
            # ì˜ë„ ì ìˆ˜ ê³„ì‚°
            intent_scores = {}
            for intent, keywords in intent_keywords.items():
                score = sum(1 for keyword in keywords if keyword in message_lower)
                if score > 0:
                    intent_scores[intent] = score
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ì„ íƒ
            if intent_scores:
                detected_intent = max(intent_scores, key=intent_scores.get)
                confidence = intent_scores[detected_intent] / len(message_lower.split())
                print(f"ğŸ¯ ì˜ë„ ë¶„ë¥˜: {detected_intent} (ì‹ ë¢°ë„: {confidence:.2f})")
                return detected_intent, confidence
            else:
                print("ğŸ¯ ì˜ë„ ë¶„ë¥˜: general_chat (ê¸°ë³¸ê°’)")
                return 'general_chat', 0.0
                
        except Exception as e:
            print(f"âŒ ì˜ë„ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return 'general_chat', 0.0

    def _parse_time_range(self, message):
        """ë©”ì‹œì§€ì—ì„œ ì‹œê°„ ë²”ìœ„ë¥¼ íŒŒì‹±"""
        try:
            import re
            
            # ì‹œê°„ íŒ¨í„´ ë§¤ì¹­ (ì˜ˆ: "3:00~5:00", "3ë¶„~5ë¶„", "180ì´ˆ~300ì´ˆ")
            time_patterns = [
                r'(\d+):(\d+)~(\d+):(\d+)',  # 3:00~5:00
                r'(\d+)ë¶„~(\d+)ë¶„',          # 3ë¶„~5ë¶„
                r'(\d+)ì´ˆ~(\d+)ì´ˆ',          # 180ì´ˆ~300ì´ˆ
            ]
            
            for pattern in time_patterns:
                match = re.search(pattern, message)
                if match:
                    groups = match.groups()
                    if len(groups) == 4:  # 3:00~5:00 í˜•ì‹
                        start_min, start_sec, end_min, end_sec = map(int, groups)
                        start_time = start_min * 60 + start_sec
                        end_time = end_min * 60 + end_sec
                        return start_time, end_time
                    elif len(groups) == 2:  # ë¶„ ë˜ëŠ” ì´ˆ í˜•ì‹
                        start_val, end_val = map(int, groups)
                        if 'ë¶„' in message:
                            start_time = start_val * 60
                            end_time = end_val * 60
                        else:  # ì´ˆ
                            start_time = start_val
                            end_time = end_val
                        return start_time, end_time
            
            return None
            
        except Exception as e:
            print(f"âŒ ì‹œê°„ ë²”ìœ„ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _find_relevant_frames(self, message, analysis_json_data, video_id):
        """ì‚¬ìš©ì ë©”ì‹œì§€ì— ë”°ë¼ ê´€ë ¨ í”„ë ˆì„ì„ ì°¾ì•„ì„œ ì´ë¯¸ì§€ URLê³¼ í•¨ê»˜ ë°˜í™˜ (ì˜ë„ ê¸°ë°˜)"""
        try:
            if not analysis_json_data or 'frame_results' not in analysis_json_data:
                print("âŒ ë¶„ì„ ë°ì´í„° ë˜ëŠ” í”„ë ˆì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            relevant_frames = []
            message_lower = message.lower()
            
            # í”„ë ˆì„ ê²°ê³¼ì—ì„œ ë§¤ì¹­ë˜ëŠ” í”„ë ˆì„ ì°¾ê¸°
            frame_results = analysis_json_data.get('frame_results', [])
            print(f"ğŸ” ê²€ìƒ‰í•  í”„ë ˆì„ ìˆ˜: {len(frame_results)}")
            
            # ì˜ë„ ë¶„ë¥˜
            intent, confidence = self._classify_intent(message)
            print(f"ğŸ¯ ê²€ìƒ‰ ì˜ë„: {intent}")
            
            # ìƒ‰ìƒ ê¸°ë°˜ ê²€ìƒ‰
            color_keywords = {
                'ë¹¨ê°„ìƒ‰': ['red', 'ë¹¨ê°•', 'ë¹¨ê°„ìƒ‰'],
                'íŒŒë€ìƒ‰': ['blue', 'íŒŒë‘', 'íŒŒë€ìƒ‰'],
                'ë…¸ë€ìƒ‰': ['yellow', 'ë…¸ë‘', 'ë…¸ë€ìƒ‰'],
                'ì´ˆë¡ìƒ‰': ['green', 'ë…¹ìƒ‰', 'ì´ˆë¡ìƒ‰'],
                'ë³´ë¼ìƒ‰': ['purple', 'ìì£¼ìƒ‰', 'ë³´ë¼ìƒ‰'],
                'ë¶„í™ìƒ‰': ['pink', 'í•‘í¬', 'ë¶„í™ìƒ‰'],
                'ê²€ì€ìƒ‰': ['black', 'ê²€ì •', 'ê²€ì€ìƒ‰'],
                'í°ìƒ‰': ['white', 'í•˜ì–‘', 'í°ìƒ‰'],
                'íšŒìƒ‰': ['gray', 'grey', 'íšŒìƒ‰'],
                'ì£¼í™©ìƒ‰': ['orange', 'ì˜¤ë Œì§€', 'ì£¼í™©ìƒ‰'],
                'ê°ˆìƒ‰': ['brown', 'ë¸Œë¼ìš´', 'ê°ˆìƒ‰'],
                'ì˜·': ['clothing', 'clothes', 'dress', 'shirt', 'pants', 'jacket']
            }
            
            # ì˜ë„ ê¸°ë°˜ í”„ë ˆì„ ê²€ìƒ‰
            if intent == 'color_search':
                print("ğŸ¨ ìƒ‰ìƒ ê²€ìƒ‰ ëª¨ë“œ")
                detected_colors = []
                for color_korean, color_terms in color_keywords.items():
                    if any(term in message_lower for term in color_terms):
                        detected_colors.append(color_korean)
                        print(f"ğŸ¨ ìƒ‰ìƒ ê²€ìƒ‰ ê°ì§€: {color_korean}")
                
                if detected_colors:
                    print(f"ğŸ¨ ìƒ‰ìƒ ê²€ìƒ‰ ëª¨ë“œ: {detected_colors}")
                    print(f"ğŸ” ê²€ìƒ‰í•  í”„ë ˆì„ ìˆ˜: {len(frame_results)}")
                    for frame in frame_results:
                        persons = frame.get('persons', [])
                        
                        # ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼ í™•ì¸
                        dominant_colors = frame.get('dominant_colors', [])
                        color_match_found = False
                        
                        # ìš”ì²­ëœ ìƒ‰ìƒê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸ (ë” ìœ ì—°í•œ ë§¤ì¹­)
                        for detected_color in detected_colors:
                            for color_info in dominant_colors:
                                color_name = color_info.get('color', '').lower()
                                detected_color_lower = detected_color.lower()
                                
                                # ìƒ‰ìƒ í‚¤ì›Œë“œ ë§¤í•‘ì„ í†µí•œ ë§¤ì¹­
                                color_mapping = {
                                    'ë¶„í™ìƒ‰': 'pink', 'í•‘í¬': 'pink',
                                    'ë¹¨ê°„ìƒ‰': 'red', 'ë¹¨ê°•': 'red',
                                    'íŒŒë€ìƒ‰': 'blue', 'íŒŒë‘': 'blue',
                                    'ë…¸ë€ìƒ‰': 'yellow', 'ë…¸ë‘': 'yellow',
                                    'ì´ˆë¡ìƒ‰': 'green', 'ë…¹ìƒ‰': 'green',
                                    'ë³´ë¼ìƒ‰': 'purple', 'ìì£¼ìƒ‰': 'purple',
                                    'ê²€ì€ìƒ‰': 'black', 'ê²€ì •': 'black',
                                    'í°ìƒ‰': 'white', 'í•˜ì–‘': 'white',
                                    'íšŒìƒ‰': 'gray', 'grey': 'gray',
                                    'ì£¼í™©ìƒ‰': 'orange', 'ì˜¤ë Œì§€': 'orange',
                                    'ê°ˆìƒ‰': 'brown', 'ë¸Œë¼ìš´': 'brown'
                                }
                                
                                # ë§¤í•‘ëœ ìƒ‰ìƒìœ¼ë¡œ ë¹„êµ
                                mapped_color = color_mapping.get(detected_color_lower, detected_color_lower)
                                
                                # ë” ìœ ì—°í•œ ìƒ‰ìƒ ë§¤ì¹­ (ìƒ‰ìƒì´ ì—†ì–´ë„ ì¼ë‹¨ í¬í•¨)
                                if (mapped_color == color_name or 
                                    detected_color_lower == color_name or 
                                    detected_color_lower in color_name or 
                                    color_name in detected_color_lower or
                                    len(dominant_colors) == 0):  # ìƒ‰ìƒ ì •ë³´ê°€ ì—†ì–´ë„ í¬í•¨
                                    color_match_found = True
                                    print(f"âœ… ìƒ‰ìƒ ë§¤ì¹­ ë°œê²¬: {detected_color} -> {color_info}")
                                    break
                            if color_match_found:
                                break
                        
                        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
                        print(f"ğŸ” í”„ë ˆì„ {frame.get('image_id', 0)} ìƒ‰ìƒ ë¶„ì„:")
                        print(f"  - ìš”ì²­ëœ ìƒ‰ìƒ: {detected_colors}")
                        print(f"  - ê°ì§€ëœ ìƒ‰ìƒ: {[c.get('color', '') for c in dominant_colors]}")
                        print(f"  - ë§¤ì¹­ ê²°ê³¼: {color_match_found}")
                        
                        # ìƒ‰ìƒ ê²€ìƒ‰ì˜ ê²½ìš° ìƒ‰ìƒ ë§¤ì¹­ì´ ëœ í”„ë ˆì„ë§Œ í¬í•¨
                        if color_match_found:
                            frame_image_path = frame.get('frame_image_path', '')
                            actual_image_path = None
                            if frame_image_path:
                                # ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œ ìƒì„±
                                import os
                                from django.conf import settings
                                actual_image_path = os.path.join(settings.MEDIA_ROOT, frame_image_path)
                                if os.path.exists(actual_image_path):
                                    print(f"âœ… ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬: {actual_image_path}")
                                else:
                                    print(f"âŒ ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {actual_image_path}")
                            
                            frame_info = {
                                'image_id': frame.get('image_id', 0),
                                'timestamp': frame.get('timestamp', 0),
                                'frame_image_path': frame_image_path,
                                'image_url': f'/media/{frame_image_path}',
                                'actual_image_path': actual_image_path,  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
                                'persons': persons,
                                'objects': frame.get('objects', []),
                                'scene_attributes': frame.get('scene_attributes', {}),
                                'dominant_colors': dominant_colors,  # ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                                'relevance_score': 2,  # ìƒ‰ìƒ ë§¤ì¹­ ì‹œ ë†’ì€ ì ìˆ˜
                                'color_search_info': {
                                    'requested_colors': detected_colors,
                                    'color_info_available': len(dominant_colors) > 0,
                                    'color_match_found': color_match_found,
                                    'actual_image_available': actual_image_path is not None,
                                    'message': f"ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼: {dominant_colors} | ìš”ì²­í•˜ì‹  ìƒ‰ìƒ: {', '.join(detected_colors)}"
                                }
                            }
                            relevant_frames.append(frame_info)
                            print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ìƒ‰ìƒ ë§¤ì¹­ ì„±ê³µ)")
                        else:
                            print(f"âŒ í”„ë ˆì„ {frame.get('image_id', 0)}: ìƒ‰ìƒ ë§¤ì¹­ ì‹¤íŒ¨ - {detected_colors} vs {dominant_colors}")
                
                else:
                    print("ğŸ¨ ìƒ‰ìƒ í‚¤ì›Œë“œ ê°ì§€ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                    # ìƒ‰ìƒ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  í”„ë ˆì„ í¬í•¨
                    for frame in frame_results:
                        persons = frame.get('persons', [])
                        if persons:  # ì‚¬ëŒì´ ìˆëŠ” í”„ë ˆì„ë§Œ
                            frame_info = {
                                'image_id': frame.get('image_id', 0),
                                'timestamp': frame.get('timestamp', 0),
                                'frame_image_path': frame.get('frame_image_path', ''),
                                'image_url': f'/media/{frame.get("frame_image_path", "")}',
                                'persons': persons,
                                'objects': frame.get('objects', []),
                                'scene_attributes': frame.get('scene_attributes', {}),
                                'relevance_score': len(persons)
                            }
                            relevant_frames.append(frame_info)
                            print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì¼ë°˜ ê²€ìƒ‰, ì‚¬ëŒ {len(persons)}ëª…)")
            
            elif intent == 'person_search':
                print("ğŸ‘¤ ì‚¬ëŒ ê²€ìƒ‰ ëª¨ë“œ")
                print(f"ğŸ” ê²€ìƒ‰í•  í”„ë ˆì„ ìˆ˜: {len(frame_results)}")
                for frame in frame_results:
                    persons = frame.get('persons', [])
                    print(f"ğŸ” í”„ë ˆì„ {frame.get('image_id', 0)}: persons = {persons}")
                    # ì‚¬ëŒì´ ê°ì§€ëœ í”„ë ˆì„ë§Œ í¬í•¨
                    if persons and len(persons) > 0:
                        frame_info = {
                            'image_id': frame.get('image_id', 0),
                            'timestamp': frame.get('timestamp', 0),
                            'frame_image_path': frame.get('frame_image_path', ''),
                            'image_url': f'/media/{frame.get("frame_image_path", "")}',
                            'persons': persons,
                            'objects': frame.get('objects', []),
                            'scene_attributes': frame.get('scene_attributes', {}),
                            'relevance_score': len(persons) * 2  # ì‚¬ëŒ ìˆ˜ì— ë¹„ë¡€í•œ ì ìˆ˜
                        }
                        relevant_frames.append(frame_info)
                        print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì‚¬ëŒ {len(persons)}ëª… ê°ì§€)")
                        print(f"âœ… í”„ë ˆì„ ìƒì„¸ ì •ë³´: {frame_info}")
                    else:
                        print(f"âŒ í”„ë ˆì„ {frame.get('image_id', 0)}: ì‚¬ëŒ ê°ì§€ ì•ˆë¨")
            
            elif intent == 'video_summary':
                print("ğŸ“‹ ìš”ì•½ ëª¨ë“œ - ì£¼ìš” í”„ë ˆì„ ì„ íƒ")
                # í™œë™ ìˆ˜ì¤€ì´ ë†’ì€ í”„ë ˆì„ ìš°ì„  ì„ íƒ
                frame_scores = []
                for frame in frame_results:
                    scene_attrs = frame.get('scene_attributes', {})
                    activity_level = scene_attrs.get('activity_level', 'low')
                    person_count = len(frame.get('persons', []))
                    
                    score = 0
                    if activity_level == 'high':
                        score += 3
                    elif activity_level == 'medium':
                        score += 2
                    else:
                        score += 1
                    
                    score += min(person_count, 3)  # ì‚¬ëŒ ìˆ˜ì— ë”°ë¥¸ ì ìˆ˜
                    frame_scores.append((frame, score))
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í”„ë ˆì„ ì„ íƒ
                frame_scores.sort(key=lambda x: x[1], reverse=True)
                for frame, score in frame_scores[:3]:
                    frame_info = {
                        'image_id': frame.get('image_id', 0),
                        'timestamp': frame.get('timestamp', 0),
                        'frame_image_path': frame.get('frame_image_path', ''),
                        'image_url': f'/media/{frame.get("frame_image_path", "")}',
                        'persons': frame.get('persons', []),
                        'objects': frame.get('objects', []),
                        'scene_attributes': frame.get('scene_attributes', {}),
                        'relevance_score': score
                    }
                    relevant_frames.append(frame_info)
                    print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ìš”ì•½ìš©, ì ìˆ˜: {score})")
            
            elif intent == 'temporal_analysis':
                print("â° ì‹œê°„ëŒ€ ë¶„ì„ ëª¨ë“œ")
                # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
                time_range = self._parse_time_range(message)
                if time_range:
                    start_time, end_time = time_range
                    print(f"â° ì‹œê°„ ë²”ìœ„: {start_time}ì´ˆ ~ {end_time}ì´ˆ")
                    for frame in frame_results:
                        timestamp = frame.get('timestamp', 0)
                        if start_time <= timestamp <= end_time:
                            frame_info = {
                                'image_id': frame.get('image_id', 0),
                                'timestamp': frame.get('timestamp', 0),
                                'frame_image_path': frame.get('frame_image_path', ''),
                                'image_url': f'/media/{frame.get("frame_image_path", "")}',
                                'persons': frame.get('persons', []),
                                'objects': frame.get('objects', []),
                                'scene_attributes': frame.get('scene_attributes', {}),
                                'relevance_score': 1
                            }
                            relevant_frames.append(frame_info)
                            print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì‹œê°„ëŒ€: {timestamp}ì´ˆ)")
                else:
                    # ì‹œê°„ ë²”ìœ„ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì „ì²´ í”„ë ˆì„
                    relevant_frames = [{
                        'image_id': frame.get('image_id', 0),
                        'timestamp': frame.get('timestamp', 0),
                        'frame_image_path': frame.get('frame_image_path', ''),
                        'image_url': f'/media/{frame.get("frame_image_path", "")}',
                        'persons': frame.get('persons', []),
                        'objects': frame.get('objects', []),
                        'scene_attributes': frame.get('scene_attributes', {}),
                        'relevance_score': 1
                    } for frame in frame_results]
                    print(f"âœ… ì‹œê°„ ë²”ìœ„ íŒŒì‹± ì‹¤íŒ¨ - ì „ì²´ í”„ë ˆì„ {len(relevant_frames)}ê°œ ì„ íƒ")
            
            else:
                print("ğŸ“‹ ì¼ë°˜ ê²€ìƒ‰ ëª¨ë“œ")
                # ì²˜ìŒ 2ê°œ í”„ë ˆì„ ì„ íƒ
                for frame in frame_results[:2]:
                    frame_info = {
                        'image_id': frame.get('image_id', 0),
                        'timestamp': frame.get('timestamp', 0),
                        'frame_image_path': frame.get('frame_image_path', ''),
                        'image_url': f'/media/{frame.get("frame_image_path", "")}',
                        'persons': frame.get('persons', []),
                        'objects': frame.get('objects', []),
                        'scene_attributes': frame.get('scene_attributes', {}),
                        'relevance_score': 1
                    }
                    relevant_frames.append(frame_info)
                    print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì¼ë°˜ ê²€ìƒ‰)")
            
            # ê´€ë ¨ë„ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
            relevant_frames.sort(key=lambda x: x['relevance_score'], reverse=True)
            result = relevant_frames[:3]
            print(f"ğŸ¯ ìµœì¢… ì„ íƒëœ í”„ë ˆì„ ìˆ˜: {len(result)}")
            print(f"ğŸ¯ ìµœì¢… í”„ë ˆì„ ìƒì„¸: {result}")
            return result
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _handle_special_commands(self, message, video_id):
        """íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬ (ìš”ì•½, í•˜ì´ë¼ì´íŠ¸)"""
        try:
            message_lower = message.lower().strip()
            
            # ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´
            if any(keyword in message_lower for keyword in ['ìš”ì•½', 'summary', 'ì˜ìƒ ìš”ì•½', 'ì˜ìƒ ìš”ì•½í•´ì¤˜', 'ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ì•Œë ¤ì¤˜']):
                return self._handle_video_summary_command(message_lower, video_id)
            
            # ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì£¼ìš” ì¥ë©´', 'ì¤‘ìš”í•œ ì¥ë©´']):
                return self._handle_video_highlight_command(message_lower, video_id)
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def _handle_video_summary_command(self, message, video_id):
        """ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        try:
            # ìš”ì•½ íƒ€ì… ê²°ì •
            summary_type = 'comprehensive'
            if 'ê°„ë‹¨' in message or 'brief' in message:
                summary_type = 'brief'
            elif 'ìƒì„¸' in message or 'detailed' in message:
                summary_type = 'detailed'
            
            # VideoSummaryView ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ìš”ì•½ ìƒì„±
            summary_view = VideoSummaryView()
            summary_result = summary_view._generate_video_summary(
                Video.objects.get(id=video_id), 
                summary_type
            )
            
            if summary_result and summary_result.get('summary'):
                return f"ğŸ“ **ì˜ìƒ ìš”ì•½** ({summary_type})\n\n{summary_result['summary']}"
            else:
                return "âŒ ì˜ìƒ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜ìƒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _handle_video_highlight_command(self, message, video_id):
        """ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        try:
            # í•˜ì´ë¼ì´íŠ¸ ê¸°ì¤€ ì„¤ì •
            criteria = {
                'min_score': 2.0,
                'max_highlights': 5
            }
            
            if 'ë§ì´' in message or 'more' in message:
                criteria['max_highlights'] = 10
            elif 'ì ê²Œ' in message or 'few' in message:
                criteria['max_highlights'] = 3
            
            # VideoHighlightView ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
            highlight_view = VideoHighlightView()
            highlights = highlight_view._extract_highlights(
                Video.objects.get(id=video_id), 
                criteria
            )
            
            if highlights:
                highlight_text = "ğŸ¬ **ì˜ìƒ í•˜ì´ë¼ì´íŠ¸**\n\n"
                for i, highlight in enumerate(highlights, 1):
                    highlight_text += f"{i}. **{highlight['timestamp']:.1f}ì´ˆ** - {highlight['description']}\n"
                    highlight_text += f"   - ì¤‘ìš”ë„: {highlight['significance']} (ì ìˆ˜: {highlight['score']:.1f})\n"
                    highlight_text += f"   - ì¸ì›: {highlight['person_count']}ëª…, ì¥ë©´: {highlight['scene_type']}\n\n"
                
                return highlight_text
            else:
                return "âŒ í•˜ì´ë¼ì´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

