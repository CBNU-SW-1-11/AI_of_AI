from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import AllowAny, IsAuthenticated
from rest_framework.parsers import MultiPartParser, FormParser
from django.http import HttpResponse, Http404
from chat.serializers import UserSerializer, VideoChatSessionSerializer, VideoChatMessageSerializer, VideoAnalysisCacheSerializer
from chat.models import VideoChatSession, VideoChatMessage, VideoAnalysisCache, Video
from .services.video_analysis_service import video_analysis_service
from .enhanced_video_chat_handler import get_video_chat_handler
from .person_search_handler import handle_person_search_command
from .advanced_search_view import InterVideoSearchView, IntraVideoSearchView, TemporalAnalysisView
from .advanced_command_handler import handle_inter_video_search_command, handle_intra_video_search_command, handle_temporal_analysis_command
from .ai_response_generator import ai_response_generator
from .evaluation_metrics import evaluation_metrics
from .conversation_memory import conversation_memory
from .integrated_chat_service import integrated_chat_service
from .llm_cache_manager import llm_cache_manager, conversation_context_manager
from django.utils import timezone
import threading
import openai
import anthropic
from groq import Groq
import ollama
import anthropic
import google.generativeai as genai
import os
import sys
import io
import PyPDF2
from PIL import Image
import pytesseract
# import cv2  # NumPy í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¡°ê±´ë¶€ import
# import numpy as np  # NumPy í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¡°ê±´ë¶€ import
from pdf2image import convert_from_bytes
import base64
import tempfile
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
import requests
import uuid
import hmac
import hashlib
from django.contrib.auth import get_user_model
from chat.models import User, SocialAccount
from django.conf import settings
import json
import logging
import re
from datetime import datetime, timedelta

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# íŒŒì¼ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def extract_text_from_pdf(file_content):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì§ì ‘ ì¶”ì¶œ + OCR ë°±ì—…)"""
    try:
        pdf_file = io.BytesIO(file_content)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        
        # ë¨¼ì € ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        for page_num in range(len(pdf_reader.pages)):
            page = pdf_reader.pages[page_num]
            page_text = page.extract_text()
            text += page_text + "\n"
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ OCR ì‹œë„
        if len(text.strip()) < 100:  # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ OCR ì‚¬ìš©
            print("PDF ì§ì ‘ ì¶”ì¶œ í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ì—¬ OCRì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return extract_text_from_pdf_ocr(file_content)
        
        return text.strip()
    except Exception as e:
        print(f"PDF ì§ì ‘ ì¶”ì¶œ ì‹¤íŒ¨, OCRì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {str(e)}")
        return extract_text_from_pdf_ocr(file_content)

def extract_text_from_pdf_ocr(file_content):
    """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_bytes(file_content, dpi=300)
        all_text = ""
        
        for i, image in enumerate(images):
            # ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (NumPy ì—†ì´)
            # ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            if image.mode != 'L':
                image = image.convert('L')
            
            # OCR ìˆ˜í–‰ (ì „ì²˜ë¦¬ ì—†ì´)
            page_text = pytesseract.image_to_string(image, lang='kor+eng')
            all_text += f"\n--- í˜ì´ì§€ {i+1} ---\n{page_text}\n"
        
        return all_text.strip()
    except Exception as e:
        return f"PDF OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def extract_text_from_image(file_content):
    """ì´ë¯¸ì§€ì—ì„œ OCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ì§€ ì—´ê¸°
        image = Image.open(io.BytesIO(file_content))
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ê°„ë‹¨í•œ ë°©ì‹)
        if image.mode != 'L':
            image = image.convert('L')  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        
        # OCR ìˆ˜í–‰ (í•œêµ­ì–´ + ì˜ì–´)
        text = pytesseract.image_to_string(image, lang='kor+eng')
        
        return text.strip()
    except Exception as e:
        return f"ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def process_uploaded_file(file):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
    try:
        # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™
        if hasattr(file, 'seek'):
            file.seek(0)
        file_content = file.read()
        
        if not file_content:
            print(f"âš ï¸ íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {file.name}")
            return "íŒŒì¼ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        file_extension = file.name.split('.')[-1].lower()
        
        if file_extension == 'pdf':
            extracted_text = extract_text_from_pdf(file_content)
            print(f"âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(extracted_text)}ì")
            if len(extracted_text.strip()) < 50:
                print(f"âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ì§§ìŠµë‹ˆë‹¤. OCRì„ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return extracted_text
        elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
            # ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ìš° íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜ (Ollamaê°€ ì§ì ‘ ì½ë„ë¡)
            return f"IMAGE_FILE:{file.name}"
        else:
            return "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def summarize_content(content, api_key=None, file_path=None, full_content=False):
    """ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜ (Ollama ì‚¬ìš©)
    
    Args:
        content: í…ìŠ¤íŠ¸ ë‚´ìš© ë˜ëŠ” IMAGE_FILE: ì ‘ë‘ì‚¬ê°€ ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ëª…
        api_key: API í‚¤ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        file_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        full_content: Trueë©´ ì „ì²´ ë‚´ìš©ì„ ë°˜í™˜, Falseë©´ ìš”ì•½ë§Œ ë°˜í™˜
    """
    try:
        # ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸
        if content.startswith("IMAGE_FILE:"):
            if file_path and os.path.exists(file_path):
                return analyze_image_with_ollama(file_path)
            else:
                return "ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í…ìŠ¤íŠ¸ ë‚´ìš©ì¸ ê²½ìš°
        if full_content:
            # ì „ì²´ ë‚´ìš©ì„ ë°˜í™˜í•˜ë˜, ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ (ìµœëŒ€ 50000ì)
            if len(content) > 50000:
                print(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({len(content)}ì). ì²˜ìŒ 50000ìë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return content[:50000] + "\n\n...(ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë©ë‹ˆë‹¤)..."
            return content
        
        # ìš”ì•½ ëª¨ë“œ: ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (í† í° ì œí•œ ê³ ë ¤)
        if len(content) > 12000:
            content = content[:12000] + "..."
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ì£¼ì–´ì§„ ë‚´ìš©ì´ PDFì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì¸ ê²½ìš°:
- OCR ì˜¤ë¥˜ë‚˜ ë¶ˆì™„ì „í•œ í…ìŠ¤íŠ¸ê°€ ìˆì„ ìˆ˜ ìˆìŒì„ ê³ ë ¤
- ê°€ëŠ¥í•œ í•œ ì›ë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ìš”ì•½
- ì¤‘ìš”í•œ ì •ë³´ëŠ” ë³´ì¡´í•˜ë˜ ê°„ê²°í•˜ê²Œ ì •ë¦¬

ìš”ì•½ ì‹œ ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œ/ëª©ì 
2. í•µì‹¬ ë‚´ìš©ê³¼ ì¤‘ìš”í•œ í¬ì¸íŠ¸
3. ê²°ë¡ ì´ë‚˜ ìš”ì•½ (ìˆëŠ” ê²½ìš°)

ì›ë¬¸ì˜ ì£¼ìš” ë‚´ìš©ì„ ë³´ì¡´í•˜ë©´ì„œë„ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”:

{content}"""
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ë¡œ ìš”ì•½ ìˆ˜í–‰
        response = ollama.chat(
                   model='llama3.2:latest',  # ë˜ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ë‹¤ë¥¸ ëª¨ë¸
            messages=[
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            options={
                'temperature': 0.3,
                'num_predict': 1500
            }
        )
        
        return response['message']['content']
    except Exception as e:
        print(f"Ollama ìš”ì•½ ì˜¤ë¥˜: {str(e)}")
        # Ollama ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½
        if len(content) > 1000:
            return f"ë¬¸ì„œ ìš”ì•½ (Ollama ì˜¤ë¥˜ë¡œ ê°„ë‹¨ ìš”ì•½): {content[:500]}..."
        return content

def analyze_image_with_ollama(image_path):
    """í•˜ì´ë¸Œë¦¬ë“œ ì´ë¯¸ì§€ ë¶„ì„ (OCR + Ollama)"""
    try:
        # 1ë‹¨ê³„: OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        try:
            from PIL import Image
            import pytesseract
            
            image = Image.open(image_path)
            ocr_text = pytesseract.image_to_string(image, lang='kor+eng')
            
            if len(ocr_text.strip()) > 10:  # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„íˆ ìˆìœ¼ë©´ OCR ê²°ê³¼ ì‚¬ìš©
                return f"ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤: {ocr_text.strip()[:200]}"
        except:
            pass
        
        # 2ë‹¨ê³„: OCR ì‹¤íŒ¨ ì‹œ Ollamaë¡œ ê°„ë‹¨í•œ ë¶„ì„ (ì˜ì–´ë¡œ ë‹µë³€)
        prompt = """IMPORTANT: Count objects very carefully. Look at the image multiple times.

Count the exact number of objects in this image. Be very precise about the count.
Then describe each object's type and main colors.

Examples:
- "1 gray and white cat, blue background"
- "2 dogs, white background" 
- "3 cars, street scene"

Answer in English very concisely. Double-check your count."""
        
        # ì„±ëŠ¥ ìµœì í™”: ë” ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©
        try:
            # llava:7b ì‚¬ìš© (ê°€ì¥ ê°€ë²¼ìš´ ë¹„ì „ ëª¨ë¸)
            response = ollama.chat(
                model='llava:7b',
                messages=[
                    {
                        'role': 'user',
                        'content': prompt,
                        'images': [image_path]
                    }
                ],
                options={
                    'temperature': 0.1,  # ë” ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í–¥ìƒ
                    'num_predict': 300,  # í† í° ìˆ˜ ë” ì¤„ì„
                    'num_ctx': 1024  # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ë” ì œí•œ
                }
            )
            
            # Ollama ì‘ë‹µ ë¡œê¹…
            ollama_response = response['message']['content']
            print(f"Ollama ë¶„ì„ ê²°ê³¼: {ollama_response}")
            return ollama_response
            
        except Exception as e:
            print(f"Ollama ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨, GPT APIë¡œ fallback: {str(e)}")
            # GPT APIë¡œ fallback (ë¹„ìš©ì´ ë“¤ì§€ë§Œ ì •í™•ë„ ë†’ìŒ)
            try:
                import openai
                import base64
                
                with open(image_path, "rb") as image_file:
                    base64_image = base64.b64encode(image_file.read()).decode('utf-8')
                
                response = openai.chat.completions.create(
                    model="gpt-4o-mini",  # ê°€ì¥ ì €ë ´í•œ GPT-4 ë¹„ì „ ëª¨ë¸
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "Count the exact number of objects in this image. Then describe each object's type and main colors only. Answer in English."},
                                {
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                                }
                            ]
                        }
                    ],
                    max_tokens=100  # í† í° ìˆ˜ ì œí•œìœ¼ë¡œ ë¹„ìš© ì ˆì•½
                )
                
                gpt_response = response.choices[0].message.content
                print(f"GPT ë¶„ì„ ê²°ê³¼: {gpt_response}")
                return gpt_response
            except Exception as gpt_error:
                print(f"GPT API fallbackë„ ì‹¤íŒ¨: {str(gpt_error)}")
                return "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    except Exception as e:
        print(f"Ollama ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_optimal_response_with_ollama(ai_responses, user_question):
    """Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ë‹µë³€ ìƒì„± (ë¹„ìš© ì ˆì•½ + í’ˆì§ˆ í–¥ìƒ)"""
    try:
        # AI ì‘ë‹µë“¤ì„ ì •ë¦¬
        responses_text = ""
        model_names = []
        for model_name, response in ai_responses.items():
            responses_text += f"### {model_name.upper()}:\n{response}\n\n"
            model_names.append(model_name.upper())
        
        # AI ë¶„ì„ ì„¹ì…˜ ìƒì„±
        analysis_sections = ""
        for name in model_names:
            analysis_sections += f"### {name}\n- ì¥ì : [ì£¼ìš” ì¥ì ]\n- ë‹¨ì : [ì£¼ìš” ë‹¨ì ]\n- íŠ¹ì§•: [íŠ¹ë³„í•œ íŠ¹ì§•]\n"
        
        # ë¹„ìš© ì ˆì•½ì„ ìœ„í•œ ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸
        prompt = f"""AI ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í†µí•© ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

í˜•ì‹:
## í†µí•© ë‹µë³€
[ëª¨ë“  AIì˜ ì¥ì ì„ ê²°í•©í•œ ìµœì  ë‹µë³€]

## ê° AI ë¶„ì„
{analysis_sections}
## ë¶„ì„ ê·¼ê±°
[í†µí•© ë‹µë³€ì„ ë§Œë“  êµ¬ì²´ì  ì´ìœ ]

## ìµœì¢… ì¶”ì²œ
[ìƒí™©ë³„ AI ì„ íƒ ê°€ì´ë“œ]

ì§ˆë¬¸: {user_question}

AI ë‹µë³€ë“¤:
{responses_text}

ìœ„ ë‹µë³€ë“¤ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í†µí•© ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
        
        response = ollama.chat(
                   model='llama3.2:latest',
            messages=[
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            options={
                'temperature': 0.7,
                'num_predict': 2500
            }
        )
        
        return response['message']['content']
    except Exception as e:
        return f"Ollama ìµœì  ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_optimal_response(ai_responses, user_question, api_key=None):
    """AIë“¤ì˜ ì‘ë‹µì„ í†µí•©í•˜ì—¬ ìµœì ì˜ ë‹µë³€ ìƒì„± (Ollama ì‚¬ìš©)"""
    try:
        # Ollamaë¡œ ìµœì  ë‹µë³€ ìƒì„± (ë¹„ìš© ì ˆì•½)
        if not api_key:
            return generate_optimal_response_with_ollama(ai_responses, user_question)
        
        import openai
        client = openai.OpenAI(api_key=api_key)
        
        # AI ì‘ë‹µë“¤ì„ ì •ë¦¬
        responses_text = ""
        model_names = []
        for model_name, response in ai_responses.items():
            responses_text += f"### {model_name.upper()}:\n{response}\n\n"
            model_names.append(model_name.upper())
        
        # ëª¨ë¸ë³„ ë¶„ì„ ì„¹ì…˜ ë™ì  ìƒì„±
        analysis_sections = ""
        for model_name in model_names:
            analysis_sections += f"""
### {model_name}
- ì¥ì : [ì£¼ìš” ì¥ì ]
- ë‹¨ì : [ì£¼ìš” ë‹¨ì ]
- íŠ¹ì§•: [íŠ¹ë³„í•œ íŠ¹ì§•]
"""
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"""ë‹¹ì‹ ì€ AI ì‘ë‹µ ë¶„ì„ ë° ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ AIì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì™„ì „í•˜ê³  ì •í™•í•œ í†µí•© ë‹µë³€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

## ğŸ¯ í†µí•© ë‹µë³€
[ê°€ì¥ ì™„ì „í•˜ê³  ì •í™•í•œ í†µí•© ë‹µë³€ - ëª¨ë“  AIì˜ ì¥ì ì„ ê²°í•©í•œ ìµœì ì˜ ë‹µë³€]

## ğŸ“Š ê° AI ë¶„ì„
{analysis_sections}

## ğŸ” ë¶„ì„ ê·¼ê±°
[ê° AIì˜ ì •ë³´ë¥¼ ì–´ë–»ê²Œ ì¡°í•©í•˜ì—¬ í†µí•© ë‹µë³€ì„ ë§Œë“¤ì—ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]

## ğŸ† ìµœì¢… ì¶”ì²œ
[ê°€ì¥ ì¶”ì²œí•˜ëŠ” ë‹µë³€ê³¼ ê·¸ ì´ìœ  - ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–¤ AIë¥¼ ì„ íƒí•´ì•¼ í•˜ëŠ”ì§€ í¬í•¨]

## ğŸ’¡ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸
[ì§ˆë¬¸ì— ëŒ€í•œ ë” ê¹Šì€ ì´í•´ë‚˜ ì¶”ê°€ ê³ ë ¤ì‚¬í•­]"""},
                {"role": "user", "content": f"ì§ˆë¬¸: {user_question}\n\në‹¤ìŒì€ ì—¬ëŸ¬ AIì˜ ë‹µë³€ì…ë‹ˆë‹¤:\n\n{responses_text}\nìœ„ ë‹µë³€ë“¤ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í†µí•© ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."}
            ],
            temperature=0.7,
            max_tokens=2500
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ìµœì í™”ëœ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

class ChatBot:
    def __init__(self, api_key, model, api_type):
        self.conversation_history = []
        self.model = model
        self.api_type = api_type
        self.api_key = api_key  # api_key ì†ì„± ì¶”ê°€
        
        # API í‚¤ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not api_key:
            raise ValueError(f"{api_type.upper()} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if api_type == 'openai':
            self.client = openai.OpenAI(api_key=api_key)
        elif api_type == 'anthropic':
            self.client = anthropic.Client(api_key=api_key)
        elif api_type == 'groq':
            self.client = Groq(api_key=api_key)
        elif api_type == 'gemini':
            genai.configure(api_key=api_key)
            self.client = genai.GenerativeModel(model)
        elif api_type == 'clova':
            # HyperCLOVA X Studio API ë°©ì‹
            self.client = None  # HTTP ìš”ì²­ìœ¼ë¡œ ì²˜ë¦¬
            self.hyperclova_api_key = os.getenv('HYPERCLOVA_API_KEY', '')
            self.hyperclova_apigw_key = os.getenv('HYPERCLOVA_APIGW_KEY', '')  # ì„ íƒì‚¬í•­
    
    def chat(self, user_input, has_image=False, question_type=None):
        try:
            # ì§ˆë¬¸ ìœ í˜• ìë™ ê°ì§€ (ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš°)
            if question_type is None:
                question_type = detect_question_type_from_content(user_input)
            
            # ëŒ€í™” ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€ (ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
            if not self.conversation_history:
                # ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ system message ìƒì„±
                if question_type == 'code':
                    # ì½”ë“œ ì‘ì„± ì§ˆë¬¸ì¸ ê²½ìš°ì—ë§Œ ì½”ë“œ ì‘ì„± ê´€ë ¨ í”„ë¡¬í”„íŠ¸
                    if self.api_type == 'openai':
                        system_content = """You are GPT, a programming assistant that helps with code in Korean. When the user asks for code, provide complete, working code examples with proper formatting.

IMPORTANT: When providing code examples, ALWAYS format them using markdown code blocks:
- Python code: Use ```python ... ```
- JavaScript code: Use ```javascript ... ```
- Other code: Use ```language ... ```
- Inline code: Use `code`

Always wrap code in proper markdown code blocks so it can be properly rendered.
Only provide code when the user explicitly asks for code or programming help."""
                    elif self.api_type == 'anthropic':
                        system_content = "You are Claude, a programming assistant that helps with code in Korean. Provide complete, working code examples when the user asks for code. Only provide code when explicitly requested."
                    elif self.api_type == 'gemini':
                        system_content = "You are Gemini, a programming assistant that helps with code in Korean. Provide complete, working code examples when the user asks for code. Only provide code when explicitly requested."
                    elif self.api_type == 'groq':
                        system_content = "You are Mixtral, a programming assistant that helps with code in Korean. Provide complete, working code examples when the user asks for code. Only provide code when explicitly requested."
                    elif self.api_type == 'clova':
                        system_content = "ë‹¹ì‹ ì€ Clova X, í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì½”ë“œë¥¼ ìš”ì²­í•  ë•Œë§Œ ì½”ë“œë¥¼ ì œê³µí•˜ê³ , ì½”ë“œê°€ ì•„ë‹Œ ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” ì½”ë“œ ì—†ì´ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    else:
                        system_content = "You are a programming assistant that helps with code in Korean. Only provide code when the user explicitly asks for code."
                elif question_type == 'image' or has_image:
                    # ì´ë¯¸ì§€ ë¶„ì„ ì§ˆë¬¸ì¸ ê²½ìš°
                    if self.api_type == 'anthropic':
                        system_content = "You are Claude, an AI assistant that can analyze images and respond in Korean. When you receive image analysis results from other AI systems (like Ollama), you should treat them as if you analyzed the image yourself and provide detailed, natural descriptions in Korean. Make the descriptions rich, engaging, and easy to understand while maintaining the accuracy of the original analysis."
                    elif self.api_type == 'openai':
                        system_content = """You are GPT, an AI assistant that can analyze images and respond in Korean. When you receive image analysis results from other AI systems (like Ollama), you should treat them as if you analyzed the image yourself and provide detailed, natural descriptions in Korean. Make the descriptions rich, engaging, and easy to understand while maintaining the accuracy of the original analysis.

IMPORTANT: When providing code examples, ALWAYS format them using markdown code blocks:
- Python code: Use ```python ... ```
- JavaScript code: Use ```javascript ... ```
- Other code: Use ```language ... ```
- Inline code: Use `code`

Always wrap code in proper markdown code blocks so it can be properly rendered."""
                    elif self.api_type == 'groq':
                        system_content = "You are Mixtral, an AI assistant that can analyze images and respond in Korean. When you receive image analysis results from other AI systems (like Ollama), you should treat them as if you analyzed the image yourself and provide detailed, natural descriptions in Korean. Make the descriptions rich, engaging, and easy to understand while maintaining the accuracy of the original analysis."
                    elif self.api_type == 'gemini':
                        system_content = "You are Gemini, an AI assistant that can analyze images and respond in Korean. When you receive image analysis results from other AI systems (like Ollama), you should treat them as if you analyzed the image yourself and provide detailed, natural descriptions in Korean. Make the descriptions rich, engaging, and easy to understand while maintaining the accuracy of the original analysis."
                    elif self.api_type == 'clova':
                        system_content = "ë‹¹ì‹ ì€ Clova X, í•œêµ­ì–´ì— íŠ¹í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ë¥¸ AI ì‹œìŠ¤í…œ(Ollama ë“±)ì˜ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ìœ¼ë©´ ì§ì ‘ ë¶„ì„í•œ ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ìƒì„¸í•˜ê²Œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                    else:
                        system_content = "You are an AI assistant that can analyze images and respond in Korean. When you receive image analysis results from other AI systems (like Ollama), you should treat them as if you analyzed the image yourself and provide detailed, natural descriptions in Korean."
                elif question_type == 'document':
                    # ë¬¸ì„œ ë¶„ì„ ì§ˆë¬¸ì¸ ê²½ìš°
                    if self.api_type == 'anthropic':
                        system_content = "You are Claude, an AI assistant that analyzes documents and responds in Korean. Provide accurate summaries and analysis of document content. Only analyze documents when the user explicitly asks for document analysis."
                    elif self.api_type == 'openai':
                        system_content = """You are GPT, an AI assistant that analyzes documents and responds in Korean. Provide accurate summaries and analysis of document content. Only analyze documents when the user explicitly asks for document analysis.

IMPORTANT: When providing code examples, ALWAYS format them using markdown code blocks:
- Python code: Use ```python ... ```
- JavaScript code: Use ```javascript ... ```
- Other code: Use ```language ... ```
- Inline code: Use `code`

Always wrap code in proper markdown code blocks so it can be properly rendered."""
                    elif self.api_type == 'gemini':
                        system_content = "You are Gemini, an AI assistant that analyzes documents and responds in Korean. Provide accurate summaries and analysis of document content. Only analyze documents when the user explicitly asks for document analysis."
                    elif self.api_type == 'groq':
                        system_content = "You are Mixtral, an AI assistant that analyzes documents and responds in Korean. Provide accurate summaries and analysis of document content. Only analyze documents when the user explicitly asks for document analysis."
                    elif self.api_type == 'clova':
                        system_content = "ë‹¹ì‹ ì€ Clova X, ë¬¸ì„œ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë¬¸ì„œ ë¶„ì„ì„ ìš”ì²­í•  ë•Œë§Œ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³ , ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    else:
                        system_content = "You are an AI assistant that analyzes documents and responds in Korean. Only analyze documents when the user explicitly asks for document analysis."
                elif question_type == 'creative':
                    # ì°½ì‘/ê¸€ì“°ê¸° ì§ˆë¬¸ì¸ ê²½ìš°
                    if self.api_type == 'anthropic':
                        system_content = "You are Claude, a creative writing assistant that helps with writing in Korean. Provide creative, engaging, and well-written content when the user asks for creative writing. Only provide creative writing when explicitly requested."
                    elif self.api_type == 'openai':
                        system_content = """You are GPT, a creative writing assistant that helps with writing in Korean. Provide creative, engaging, and well-written content when the user asks for creative writing. Only provide creative writing when explicitly requested.

IMPORTANT: When providing code examples, ALWAYS format them using markdown code blocks:
- Python code: Use ```python ... ```
- JavaScript code: Use ```javascript ... ```
- Other code: Use ```language ... ```
- Inline code: Use `code`

Always wrap code in proper markdown code blocks so it can be properly rendered."""
                    elif self.api_type == 'gemini':
                        system_content = "You are Gemini, a creative writing assistant that helps with writing in Korean. Provide creative, engaging, and well-written content when the user asks for creative writing. Only provide creative writing when explicitly requested."
                    elif self.api_type == 'groq':
                        system_content = "You are Mixtral, a creative writing assistant that helps with writing in Korean. Provide creative, engaging, and well-written content when the user asks for creative writing. Only provide creative writing when explicitly requested."
                    elif self.api_type == 'clova':
                        system_content = "ë‹¹ì‹ ì€ Clova X, ì°½ì‘ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê¸€ì“°ê¸°ë‚˜ ì°½ì‘ì„ ìš”ì²­í•  ë•Œë§Œ ì°½ì‘ ë‚´ìš©ì„ ì œê³µí•˜ê³ , ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    else:
                        system_content = "You are a creative writing assistant that helps with writing in Korean. Only provide creative writing when the user explicitly asks for it."
                else:
                    # ì¼ë°˜ ì§ˆë¬¸ (ê¸°ë³¸ê°’)
                    if self.api_type == 'anthropic':
                        system_content = "You are Claude, an AI assistant that responds in Korean. Provide helpful, accurate, and detailed responses to user questions. Do not provide code unless explicitly asked."
                    elif self.api_type == 'openai':
                        system_content = """You are GPT, an AI assistant that responds in Korean. Provide helpful, accurate, and detailed responses to user questions. Do not provide code unless explicitly asked.

IMPORTANT: When providing code examples, ALWAYS format them using markdown code blocks:
- Python code: Use ```python ... ```
- JavaScript code: Use ```javascript ... ```
- Other code: Use ```language ... ```
- Inline code: Use `code`

Always wrap code in proper markdown code blocks so it can be properly rendered."""
                    elif self.api_type == 'groq':
                        system_content = "You are Mixtral, an AI assistant that responds in Korean. Provide helpful, accurate, and detailed responses to user questions. Do not provide code unless explicitly asked."
                    elif self.api_type == 'gemini':
                        system_content = "You are Gemini, an AI assistant that responds in Korean. Provide helpful, accurate, and detailed responses to user questions. Do not provide code unless explicitly asked."
                    elif self.api_type == 'clova':
                        system_content = "ë‹¹ì‹ ì€ Clova X, í•œêµ­ì–´ì— íŠ¹í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì½”ë“œëŠ” ìš”ì²­ë°›ì„ ë•Œë§Œ ì œê³µí•´ì£¼ì„¸ìš”."
                    else:
                        system_content = "You are an AI assistant that responds in Korean. Provide helpful, accurate, and detailed responses to user questions. Do not provide code unless explicitly asked."
                
                self.conversation_history.append({
                    "role": "system",
                    "content": system_content
                })

                # ì‚¬ìš©ì ì…ë ¥ ì¶œë ¥ (ì¸ì½”ë”© ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
                try:
                    safe_input = user_input.encode('ascii', 'ignore').decode('ascii')
                    print(f"User input: {safe_input}")
                except:
                    print("User input received")
            
            self.conversation_history.append({"role": "user", "content": user_input})
            
            # ì¸ì½”ë”© ì•ˆì „í•œ ì‘ë‹µ ë³€ìˆ˜ ì´ˆê¸°í™”
            assistant_response = ""
            
            if self.api_type == 'openai':
                # OpenAI ë°©ì‹ ì²˜ë¦¬
                # ìµœì‹  OpenAI ëª¨ë¸(o1, o3, gpt-5 ë“±)ì€ max_completion_tokens ì‚¬ìš© ë° temperature ë¯¸ì§€ì›
                is_latest_model = any(model in self.model.lower() for model in ['o1', 'o3', 'gpt-5'])
                
                api_params = {
                    "model": self.model,
                    "messages": self.conversation_history,
                }
                
                # ìµœì‹  ëª¨ë¸ì€ temperatureë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
                if not is_latest_model:
                    api_params["temperature"] = 0.7
                
                if is_latest_model:
                    # GPT-5 ë“± ìµœì‹  ëª¨ë¸ì€ ë” í° í† í° ì œí•œ ì„¤ì • (ìµœëŒ€ 16384)
                    api_params["max_completion_tokens"] = 16384
                else:
                    api_params["max_tokens"] = 16384
                
                try:
                    response = self.client.chat.completions.create(**api_params)
                    assistant_response = response.choices[0].message.content
                    
                    # ì‘ë‹µì´ ì˜ë ¸ëŠ”ì§€ í™•ì¸
                    if response.choices[0].finish_reason == 'length':
                        print(f"âš ï¸ {self.model} ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤ (finish_reason: length)")
                        assistant_response += "\n\n[ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì¸í•´ ì˜ë ¸ìŠµë‹ˆë‹¤. ë” ê¸´ ë‹µë³€ì´ í•„ìš”í•˜ì‹œë©´ ì§ˆë¬¸ì„ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”.]"
                    elif response.choices[0].finish_reason:
                        print(f"ğŸ“ {self.model} ì‘ë‹µ ì™„ë£Œ (finish_reason: {response.choices[0].finish_reason})")
                    
                    print(f"ğŸ“ {self.model} ì‘ë‹µ ê¸¸ì´: {len(assistant_response) if assistant_response else 0}ì")
                except Exception as openai_error:
                    print(f"âŒ {self.model} API error: {str(openai_error)}")
                    import traceback
                    traceback.print_exc()
                    # API ì˜¤ë¥˜ì¸ ê²½ìš° ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜ (ì—°ê²° ì˜¤ë¥˜ ë©”ì‹œì§€ ì—†ìŒ)
                    if "connection" in str(openai_error).lower() or "network" in str(openai_error).lower():
                        assistant_response = user_input  # ì›ë³¸ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
                    else:
                        raise  # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ì¬ë°œìƒ
            
            elif self.api_type == 'anthropic':
                # Anthropic Messages API ë°©ì‹ ì²˜ë¦¬
                try:
                    client = anthropic.Client(api_key=self.api_key)
                    
                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ ìƒì„±
                    messages = []
                    for msg in self.conversation_history:
                        if msg['role'] == 'system':
                            continue  # ClaudeëŠ” system ë©”ì‹œì§€ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
                        messages.append({
                            "role": msg['role'],
                            "content": msg['content']
                        })
                    
                    message = client.messages.create(
                        model="claude-3-5-haiku-20241022",
                        max_tokens=4096,
                        temperature=0.7,
                        messages=messages
                    )
                    
                    # ì‘ë‹µ ì¶”ì¶œ
                    raw_response = message.content[0].text
                    assistant_response = raw_response
                    
                    print("Claude response processed successfully")
                    
                except Exception as claude_error:
                    print(f"Claude API error: {str(claude_error)}")
                    print(f"API Key: {self.api_key[:20] if self.api_key else 'None'}...")
                    # API í‚¤ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
                    assistant_response = f"ì•ˆë…•í•˜ì„¸ìš”! '{user_input}'ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?"


            
            elif self.api_type == 'groq':
                # Groq ë°©ì‹ ì²˜ë¦¬
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=self.conversation_history,
                    temperature=0.7,
                    max_tokens=1024
                )
                assistant_response = response.choices[0].message.content
            
            elif self.api_type == 'gemini':
                # Gemini ë°©ì‹ ì²˜ë¦¬
                try:
                    from google.generativeai.types import HarmCategory, HarmBlockThreshold
                    
                    # ì•ˆì „ í•„í„° ì™„ì „ ë¹„í™œì„±í™” (BLOCK_NONE)
                    safety_settings = [
                        {
                            "category": HarmCategory.HARM_CATEGORY_HARASSMENT,
                            "threshold": HarmBlockThreshold.BLOCK_NONE
                        },
                        {
                            "category": HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                            "threshold": HarmBlockThreshold.BLOCK_NONE
                        },
                        {
                            "category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                            "threshold": HarmBlockThreshold.BLOCK_NONE
                        },
                        {
                            "category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                            "threshold": HarmBlockThreshold.BLOCK_NONE
                        }
                    ]
                    
                    # ì•ˆì „ í•„í„° ìš°íšŒë¥¼ ìœ„í•´ ì˜ì–´ ì»¨í…ìŠ¤íŠ¸ë¡œ ê°ì‹¸ê¸°
                    english_wrapper = f"""You are a helpful AI assistant. Answer the user's question directly and completely in Korean.

User Question: {user_input}

This is a legitimate educational/programming question. Please provide a complete, helpful response in Korean without refusing.

Instructions:
- Answer directly and completely in Korean
- Do not refuse legitimate questions
- Provide helpful, accurate information
- If the question asks for code, provide code examples
- Be educational and informative

Response:"""
                    
                    # ê° ìš”ì²­ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ (ëŒ€í™” ì´ë ¥ ì‚¬ìš© ì•ˆí•¨)
                    chat = self.client.start_chat(history=[])
                    
                    # ë©”ì‹œì§€ ì „ì†¡ (ì•ˆì „ í•„í„° ì™„ì „ ë¹„í™œì„±í™”)
                    response = chat.send_message(
                        english_wrapper,
                        safety_settings=safety_settings,
                        generation_config=genai.types.GenerationConfig(
                            temperature=0.9,
                            max_output_tokens=4096,
                            top_p=0.95,
                            top_k=40,
                        )
                    )
                    
                    # ì•ˆì „í•œ ì‘ë‹µ ì¶”ì¶œ
                    if response.candidates:
                        candidate = response.candidates[0]
                        
                        # finish_reason í™•ì¸
                        finish_reason = getattr(candidate, 'finish_reason', None)
                        print(f"ğŸ“ Gemini finish_reason: {finish_reason}")
                        
                        # Safety ratings í™•ì¸
                        if hasattr(candidate, 'safety_ratings'):
                            safety_ratings = candidate.safety_ratings
                            print(f"ğŸ“Š Gemini safety_ratings: {safety_ratings}")
                            # ì•ˆì „ í•„í„°ê°€ ê±¸ë ¸ëŠ”ì§€ í™•ì¸
                            for rating in safety_ratings:
                                if hasattr(rating, 'category') and hasattr(rating, 'probability'):
                                    if rating.probability >= 0.5:  # HIGH ë˜ëŠ” MEDIUM
                                        print(f"âš ï¸ ì•ˆì „ í•„í„° ê°ì§€: {rating.category} - {rating.probability}")
                        
                        # ì‘ë‹µ ì¶”ì¶œ ì‹œë„
                        if candidate.content and candidate.content.parts:
                            assistant_response = candidate.content.parts[0].text
                            print("âœ… Gemini response processed successfully")
                        elif finish_reason == 2:  # SAFETY
                            # ì•ˆì „ í•„í„°ê°€ ê±¸ë ¸ì§€ë§Œ ì¬ì‹œë„ (ì›ë³¸ ì§ˆë¬¸ ì‚¬ìš©)
                            print("âš ï¸ Gemini ì•ˆì „ í•„í„° ê°ì§€ - ì¬ì‹œë„ ì¤‘...")
                            try:
                                # ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ì§ì ‘ ì¬ì‹œë„
                                retry_response = chat.send_message(
                                    user_input,  # ì˜ì–´ ë˜í¼ ì—†ì´ ì›ë³¸ ì§ˆë¬¸
                                    safety_settings=safety_settings,
                                    generation_config=genai.types.GenerationConfig(
                                        temperature=0.9,
                                        max_output_tokens=4096,
                                    )
                                )
                                if retry_response.candidates and retry_response.candidates[0].content:
                                    assistant_response = retry_response.candidates[0].content.parts[0].text
                                    print("âœ… Gemini ì¬ì‹œë„ ì„±ê³µ")
                                else:
                                    assistant_response = user_input  # ì›ë³¸ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì•ˆì „ í•„í„° ì˜¤ë¥˜ ë©”ì‹œì§€ ì—†ìŒ)
                                    print("âš ï¸ Gemini ì¬ì‹œë„ ì‹¤íŒ¨ - ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜")
                            except Exception as retry_error:
                                print(f"âš ï¸ Gemini ì¬ì‹œë„ ì˜¤ë¥˜: {retry_error}")
                                assistant_response = user_input  # ì›ë³¸ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
                        elif finish_reason == 3:  # RECITATION
                            assistant_response = "ì´ ì‘ë‹µì€ ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        else:
                            print(f"âš ï¸ Gemini finish_reason: {finish_reason}")
                            assistant_response = user_input  # ì›ë³¸ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì˜¤ë¥˜ ë©”ì‹œì§€ ì—†ìŒ)
                    else:
                        print("âš ï¸ Gemini ì‘ë‹µì— candidatesê°€ ì—†ìŒ - ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜")
                        assistant_response = user_input  # ì›ë³¸ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
                    
                except Exception as gemini_error:
                    print(f"âŒ Gemini API error: {str(gemini_error)}")
                    import traceback
                    traceback.print_exc()
                    # ì•ˆì „ í•„í„° ì˜¤ë¥˜ì¸ ê²½ìš° ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜ (ì˜¤ë¥˜ ë©”ì‹œì§€ ì—†ìŒ)
                    if "safety" in str(gemini_error).lower() or "block" in str(gemini_error).lower():
                        print("âš ï¸ Gemini ì•ˆì „ í•„í„° ì˜¤ë¥˜ - ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜")
                        assistant_response = user_input  # ì›ë³¸ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
                    else:
                        assistant_response = f"Gemini ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(gemini_error)}"
            
            elif self.api_type == 'clova':
                # HyperCLOVA X Studio API ë°©ì‹ ì²˜ë¦¬ (ììœ  ëŒ€í™” ê°€ëŠ¥)
                try:
                    import requests
                    import json
                    
                    print(f"ğŸ” HyperCLOVA X ìš”ì²­ ì‹œì‘...")
                    print(f"   - ëª¨ë¸: {self.model}")
                    print(f"   - ë©”ì‹œì§€: {user_input}")
                    
                    if not self.hyperclova_api_key:
                        print("âŒ HyperCLOVA X API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
                        assistant_response = "HyperCLOVA X APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    else:
                        # HyperCLOVA X API ì—”ë“œí¬ì¸íŠ¸ (v3 ì‚¬ìš©)
                        clova_api_url = f"https://clovastudio.stream.ntruss.com/v3/chat-completions/{self.model}"
                        
                        # í—¤ë” ì„¤ì • (Bearer í† í° ë°©ì‹)
                        headers = {
                            "Authorization": f"Bearer {self.hyperclova_api_key}",
                            "X-NCP-CLOVASTUDIO-REQUEST-ID": str(uuid.uuid4()).replace('-', ''),
                            "Content-Type": "application/json",
                            "Accept": "application/json"
                        }
                        
                        # API Gateway í‚¤ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                        if self.hyperclova_apigw_key:
                            headers["X-NCP-APIGW-API-KEY"] = self.hyperclova_apigw_key
                        
                        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ HyperCLOVA X v3 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        clova_messages = []
                        
                        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€ (ì„ íƒì‚¬í•­, contentëŠ” ë°°ì—´)
                        clova_messages.append({
                            "role": "system",
                            "content": ""  # ë¹ˆ ë¬¸ìì—´ ì‚¬ìš©
                        })
                        
                        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (contentëŠ” ë¬¸ìì—´)
                        for msg in self.conversation_history:
                            if msg['role'] != 'system':
                                clova_messages.append({
                                    "role": msg['role'],
                                    "content": msg['content']
                                })
                        
                        # HyperCLOVA X Chat Completions API v3 í˜•ì‹
                        payload = {
                            "messages": clova_messages,
                            "topP": 0.8,
                            "topK": 0,
                            "maxTokens": 1024,
                            "temperature": 0.5,
                            "repetitionPenalty": 1.1,
                            "stop": [],
                            "seed": 0,
                            "includeAiFilters": False
                        }
                        
                        print(f"   - API URL: {clova_api_url}")
                        print(f"   - Messages: {len(clova_messages)}ê°œ")
                        
                        response = requests.post(clova_api_url, headers=headers, json=payload, timeout=30)
                        
                        print(f"   - ì‘ë‹µ ì½”ë“œ: {response.status_code}")
                        
                        if response.status_code == 200:
                            result = response.json()
                            
                            # status í™•ì¸
                            status_code = result.get('status', {}).get('code', '')
                            
                            if status_code == '20000':  # ì„±ê³µ
                                # HyperCLOVA X v3 ì‘ë‹µ íŒŒì‹±
                                # ì‘ë‹µ êµ¬ì¡°: result > message > content (ë¬¸ìì—´)
                                message_obj = result.get('result', {}).get('message', {})
                                content = message_obj.get('content', '')
                                
                                if content:
                                    assistant_response = content
                                    print(f"âœ… HyperCLOVA X ì‘ë‹µ ì„±ê³µ: {len(assistant_response)}ì")
                                else:
                                    print(f"âš ï¸ contentê°€ ë¹„ì–´ìˆìŒ")
                                    assistant_response = 'ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                            else:
                                print(f"âš ï¸ Status code: {status_code}, Message: {result.get('status', {}).get('message', '')}")
                                assistant_response = 'ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                        else:
                            print(f"âš ï¸ HyperCLOVA X API error: {response.status_code}")
                            print(f"âš ï¸ Response: {response.text}")
                            assistant_response = f"HyperCLOVA X API ì˜¤ë¥˜ (ì½”ë“œ: {response.status_code})"
                    
                except Exception as clova_error:
                    print(f"âŒ HyperCLOVA X API error: {str(clova_error)}")
                    import traceback
                    traceback.print_exc()
                    assistant_response = f"HyperCLOVA X API ì˜¤ë¥˜: {str(clova_error)}"
            
            # ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
            self.conversation_history.append({"role": "assistant", "content": assistant_response})
            return assistant_response
        except Exception as e:
            # ì¸ì½”ë”© ì•ˆì „í•œ ì˜¤ë¥˜ ì²˜ë¦¬
            try:
                error_msg = str(e)
                # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
                import re
                safe_error_msg = re.sub(r'[^\x00-\x7F]+', '', error_msg)
                print(f"Error: {safe_error_msg}")
                return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {safe_error_msg}"
            except:
                print("Error occurred (encoding issue)")
                return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ì¸ì½”ë”© ë¬¸ì œ"

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '')
GROQ_API_KEY = os.getenv('GROQ_API_KEY', '')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '')
HYPERCLOVA_API_KEY = os.getenv('HYPERCLOVA_API_KEY', '')
HYPERCLOVA_APIGW_KEY = os.getenv('HYPERCLOVA_APIGW_KEY', '')



# API í‚¤ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ChatBot ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chatbots = {}

# === GPT ëª¨ë¸ë“¤ ===
try:
    if OPENAI_API_KEY:
        # GPT-5 ì‹œë¦¬ì¦ˆ (ìµœì‹ )
        chatbots['gpt-5'] = ChatBot(OPENAI_API_KEY, 'gpt-5', 'openai')
        chatbots['gpt-5-mini'] = ChatBot(OPENAI_API_KEY, 'gpt-5-mini', 'openai')
        
        # GPT-4.1 ì‹œë¦¬ì¦ˆ
        chatbots['gpt-4.1'] = ChatBot(OPENAI_API_KEY, 'gpt-4.1', 'openai')
        chatbots['gpt-4.1-mini'] = ChatBot(OPENAI_API_KEY, 'gpt-4.1-mini', 'openai')
        
        # GPT-4o ì‹œë¦¬ì¦ˆ
        chatbots['gpt-4o'] = ChatBot(OPENAI_API_KEY, 'gpt-4o', 'openai')
        chatbots['gpt-4o-mini'] = ChatBot(OPENAI_API_KEY, 'gpt-4o-mini', 'openai')
        
        # ê¸°íƒ€
        chatbots['gpt-4-turbo'] = ChatBot(OPENAI_API_KEY, 'gpt-4-turbo', 'openai')
        chatbots['gpt-3.5-turbo'] = ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai')
        
        # í•˜ìœ„ í˜¸í™˜ì„±
        chatbots['gpt'] = ChatBot(OPENAI_API_KEY, 'gpt-4o', 'openai')
        print(f"âœ… GPT ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: GPT-5, GPT-5-Mini, GPT-4.1, GPT-4o, GPT-4o-mini")
except ValueError as e:
    print(f"âŒ GPT ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# === Claude ëª¨ë¸ë“¤ ===
try:
    if ANTHROPIC_API_KEY:
        # Claude-4 ì‹œë¦¬ì¦ˆ (ìµœì‹ )
        chatbots['claude-4-opus'] = ChatBot(ANTHROPIC_API_KEY, 'claude-4-opus', 'anthropic')
        
        # Claude-3.7 ì‹œë¦¬ì¦ˆ
        chatbots['claude-3.7-sonnet'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-7-sonnet', 'anthropic')
        
        # Claude-3.5 ì‹œë¦¬ì¦ˆ
        chatbots['claude-3.5-sonnet'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-sonnet-20241022', 'anthropic')
        chatbots['claude-3.5-haiku'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic')
        
        # Claude-3 ì‹œë¦¬ì¦ˆ (í•˜ìœ„ í˜¸í™˜)
        chatbots['claude-3-opus'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-opus-20240229', 'anthropic')
        chatbots['claude-3-sonnet'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-sonnet-20241022', 'anthropic')
        chatbots['claude-3-haiku'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic')
        
        # í•˜ìœ„ í˜¸í™˜ì„±
        chatbots['claude'] = ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-sonnet-20241022', 'anthropic')
        print(f"âœ… Claude ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: Claude-4, 3.7, 3.5, 3")
except ValueError as e:
    print(f"âŒ Claude ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# === Gemini ëª¨ë¸ë“¤ ===
try:
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        
        # Gemini 2.5 ì‹œë¦¬ì¦ˆ
        chatbots['gemini-2.5-pro'] = ChatBot(GEMINI_API_KEY, 'gemini-2.5-pro', 'gemini')
        chatbots['gemini-2.5-flash'] = ChatBot(GEMINI_API_KEY, 'gemini-2.5-flash', 'gemini')
        
        # Gemini 2.0 ì‹œë¦¬ì¦ˆ
        chatbots['gemini-2.0-flash-exp'] = ChatBot(GEMINI_API_KEY, 'gemini-2.0-flash-exp', 'gemini')
        chatbots['gemini-2.0-flash-lite'] = ChatBot(GEMINI_API_KEY, 'gemini-2.0-flash-lite', 'gemini')
        
        # í•˜ìœ„ í˜¸í™˜ì„± (ê¸°ì¡´ í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜)
        chatbots['gemini-pro-1.5'] = ChatBot(GEMINI_API_KEY, 'gemini-2.0-flash-exp', 'gemini')
        chatbots['gemini-pro-1.0'] = ChatBot(GEMINI_API_KEY, 'gemini-2.5-flash', 'gemini')
        chatbots['gemini'] = ChatBot(GEMINI_API_KEY, 'gemini-2.5-flash', 'gemini')
        
        print(f"âœ… Gemini ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: 2.5-Pro, 2.5-Flash, 2.0-Flash-Exp, 2.0-Flash-Lite")
except ValueError as e:
    print(f"âŒ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# === HyperCLOVA X ëª¨ë¸ë“¤ (Naver Clova Studio) ===
try:
    if HYPERCLOVA_API_KEY:
        # HyperCLOVA X Studio APIë¡œ ììœ  ëŒ€í™” ê°€ëŠ¥
        # HCX-003: ê³ ì„±ëŠ¥ ëª¨ë¸ (ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        # HCX-DASH-001: ë¹ ë¥¸ ëª¨ë¸ (ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        # HCX-005: ê¸°ë³¸ ëª¨ë¸ (ê¶Œì¥)
        chatbots['clova-hcx-003'] = ChatBot('dummy_key', 'HCX-005', 'clova')  # HCX-005 ì‚¬ìš©
        chatbots['clova-hcx-dash-001'] = ChatBot('dummy_key', 'HCX-005', 'clova')  # HCX-005 ì‚¬ìš©
        print(f"âœ… HyperCLOVA X ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: HCX-005 (ê³ ì„±ëŠ¥), HCX-005 (ë¹ ë¦„)")
    else:
        print(f"âš ï¸ HyperCLOVA X API ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. HYPERCLOVA_API_KEYë¥¼ .envì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
except ValueError as e:
    print(f"âŒ HyperCLOVA X ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# === ê¸°íƒ€ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜ì„±) ===
try:
    if GROQ_API_KEY:
        chatbots['mixtral'] = ChatBot(GROQ_API_KEY, 'llama-3.1-8b-instant', 'groq')
        chatbots['optimal'] = ChatBot(GROQ_API_KEY, 'llama-3.1-8b-instant', 'groq')
except ValueError as e:
    print(f"âŒ Groq ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

class ChatView(APIView):
    def post(self, request, bot_name):
        try:
            data = request.data
            user_message = data.get('message')
            uploaded_file = request.FILES.get('file')
            
            if not user_message and not uploaded_file:
                return Response({'error': 'No message or file provided'}, status=status.HTTP_400_BAD_REQUEST)
            
            chatbot = chatbots.get(bot_name)
            if not chatbot:
                print(f"âŒ Invalid bot name: {bot_name}")
                print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(chatbots.keys())[:10]}...")
                return Response({'error': 'Invalid bot name'}, status=status.HTTP_400_BAD_REQUEST)

            # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ì²˜ë¦¬
            if uploaded_file:
                try:
                    print(f"íŒŒì¼ ì—…ë¡œë“œ ê°ì§€: {uploaded_file.name}")
                    
                    # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ì‹ë³„
                    extracted_content = process_uploaded_file(uploaded_file)
                    print(f"ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_content)}ì")
                    print(f"ğŸ“„ ì¶”ì¶œëœ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì): {extracted_content[:200]}...")
                    
                    # Ollamaë¡œ ë¶„ì„ (ì´ë¯¸ì§€ëŠ” ì§ì ‘, í…ìŠ¤íŠ¸ëŠ” ì „ì²´ ë‚´ìš© ì „ë‹¬)
                    print("Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë¶„ì„ ì¤‘...")
                    
                    # ì„ì‹œ íŒŒì¼ ì €ì¥
                    temp_file_path = None
                    if extracted_content.startswith("IMAGE_FILE:"):
                        # ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥
                        import tempfile
                        import shutil
                        temp_dir = tempfile.mkdtemp()
                        temp_file_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(temp_file_path, 'wb') as temp_file:
                            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                            for chunk in uploaded_file.chunks():
                                temp_file.write(chunk)
                        print(f"ì´ë¯¸ì§€ íŒŒì¼ ì„ì‹œ ì €ì¥: {temp_file_path}")
                    
                    # ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•œ ê²½ìš°: ì „ì²´ ë‚´ìš© ì „ë‹¬ (ìš”ì•½í•˜ì§€ ì•ŠìŒ)
                    # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìš”ì•½ ëª¨ë“œ ì‚¬ìš©
                    use_full_content = bool(user_message and user_message.strip())
                    
                    if use_full_content:
                        print(f"ğŸ“‹ ì „ì²´ ë‚´ìš© ëª¨ë“œ: ì¶”ì¶œëœ í…ìŠ¤íŠ¸({len(extracted_content)}ì)ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
                    else:
                        print(f"ğŸ“ ìš”ì•½ ëª¨ë“œ: Ollamaë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")
                    
                    analyzed_content = summarize_content(
                        extracted_content, 
                        file_path=temp_file_path,
                        full_content=use_full_content
                    )
                    
                    print(f"ğŸ“Š ìµœì¢… ë¶„ì„ ë‚´ìš© ê¸¸ì´: {len(analyzed_content)}ì")
                    
                    # ì‚¬ìš©ì ë©”ì‹œì§€ì™€ íŒŒì¼ ë¶„ì„ ê²°ê³¼ë¥¼ ê²°í•©
                    if user_message and user_message.strip():
                        # ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•œ ê²½ìš° - ì „ì²´ ë‚´ìš© ì „ë‹¬
                        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ íŒŒì¼ í•¨ê»˜ ì²˜ë¦¬: {user_message}")
                        if uploaded_file.name.lower().endswith('.pdf'):
                            final_message = f"""ë‹¤ìŒì€ ì—…ë¡œë“œëœ PDF ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì…ë‹ˆë‹¤:

{analyzed_content}

---
ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ìœ„ PDF ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—°ìŠµ ë¬¸ì œê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ê·¸ ì—°ìŠµ ë¬¸ì œë¥¼ ì°¾ì•„ì„œ í’€ì–´ì£¼ì„¸ìš”.
ë¬¸ì„œì˜ ëª¨ë“  ë‚´ìš©ì„ ì£¼ì˜ ê¹Šê²Œ ì½ê³ , ê´€ë ¨ëœ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                        else:
                            # ì´ë¯¸ì§€ì¸ ê²½ìš°
                            final_message = f"""ë‹¤ìŒì€ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

{analyzed_content}

ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ìœ„ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ìì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                    else:
                        # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¶„ì„ ìš”ì²­
                        if uploaded_file.name.lower().endswith('.pdf'):
                            final_message = f"ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{analyzed_content}"
                        else:
                            final_message = f"""ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤:

{analyzed_content}

ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ìì„¸í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
                    print("ë¶„ì„ ì™„ë£Œ")
                except Exception as e:
                    print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                    final_message = f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            else:
                final_message = user_message

            # optimal ëª¨ë¸ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
            if bot_name == 'optimal':
                # ì‚¬ìš©ì ì„ íƒ ì‹¬íŒ ëª¨ë¸ (ê¸°ë³¸ê°’: GPT-4o - ë¹ ë¥¸ ì†ë„ + ìš°ìˆ˜í•œ ì„±ëŠ¥)
                judge_model = request.data.get('judge_model', 'GPT-4o')
                
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ LLM ëª¨ë¸ë“¤ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬)
                selected_models = request.data.get('selected_models', None)
                
                # FormDataë¡œ ì „ë‹¬ëœ ê²½ìš° JSON íŒŒì‹±
                if isinstance(selected_models, str):
                    try:
                        import json
                        selected_models = json.loads(selected_models)
                        print(f"ğŸ“‹ JSON íŒŒì‹±ëœ selected_models: {selected_models}")
                    except Exception as e:
                        print(f"âš ï¸ selected_models JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        selected_models = None
                
                # selected_modelsê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
                if selected_models is not None and len(selected_models) == 0:
                    print(f"âš ï¸ selected_modelsê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                    selected_models = None
                
                print(f"ğŸ¯ ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ë“¤: {selected_models}")
                print(f"ğŸ¯ ì‹¬íŒ ëª¨ë¸: {judge_model}")
                print(f"ğŸ“ ì²˜ë¦¬í•  ë©”ì‹œì§€ ê¸¸ì´: {len(final_message)}ì")
                
                # 1-4ë‹¨ê³„: ì„ íƒëœ LLM ë³‘ë ¬ ì§ˆì˜ â†’ ì‹¬íŒ ëª¨ë¸ ê²€ì¦ â†’ ìµœì  ë‹µë³€ ìƒì„±
                response = None
                try:
                    print(f"ğŸš€ ìµœì  ë‹µë³€ ìƒì„± ì‹œì‘...")
                    print(f"ğŸ“ ì‚¬ìš©ì ë©”ì‹œì§€: {final_message[:200]}...")
                    print(f"ğŸ¯ ì„ íƒëœ ëª¨ë¸: {selected_models}")
                    print(f"âš–ï¸ ì‹¬íŒ ëª¨ë¸: {judge_model}")
                    
                    final_result = collect_multi_llm_responses(final_message, judge_model, selected_models)
                    print(f"âœ… ìµœì  ë‹µë³€ ìƒì„± ì™„ë£Œ: {type(final_result)}")
                    print(f"âœ… ìµœì  ë‹µë³€ ê²°ê³¼ í‚¤: {list(final_result.keys()) if isinstance(final_result, dict) else 'N/A'}")
                    
                    # ìµœì  ë‹µë³€ ë‚´ìš© í™•ì¸
                    optimal_answer = final_result.get("ìµœì ì˜_ë‹µë³€", "")
                    if not optimal_answer:
                        # optimal_answerê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í‚¤ í™•ì¸
                        optimal_answer = final_result.get("optimal_answer", "")
                    print(f"ğŸ“„ ìµœì  ë‹µë³€ ë‚´ìš© ê¸¸ì´: {len(optimal_answer) if optimal_answer else 0}ì")
                    print(f"ğŸ“„ ìµœì  ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {optimal_answer[:300] if optimal_answer else 'None'}...")
                    
                    # optimal_answerê°€ ìˆìœ¼ë©´ ìµœì ì˜_ë‹µë³€ìœ¼ë¡œ ë³€í™˜
                    if optimal_answer and not final_result.get("ìµœì ì˜_ë‹µë³€"):
                        final_result["ìµœì ì˜_ë‹µë³€"] = optimal_answer
                    
                    # ê²°ê³¼ í¬ë§·íŒ…
                    response = format_optimal_response(final_result)
                    print(f"âœ… ê²°ê³¼ í¬ë§·íŒ… ì™„ë£Œ: {len(response) if response else 0}ì")
                    print(f"âœ… í¬ë§·íŒ…ëœ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:500] if response else 'None'}...")
                    
                    # ëŒ€í™” ë§¥ë½ì— ì¶”ê°€
                    session_id = request.data.get('user_id', 'default_user')
                    conversation_context_manager.add_conversation(
                        session_id=session_id,
                        user_message=final_message,
                        ai_responses=final_result.get('llm_ê²€ì¦_ê²°ê³¼', {}),
                        optimal_response=final_result.get('ìµœì ì˜_ë‹µë³€', '')
                    )
                    
                    # responseê°€ Noneì´ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
                    if not response:
                        print(f"âŒ responseê°€ Noneì…ë‹ˆë‹¤!")
                        response = "ìµœì  ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                    
                    print(f"ğŸ“¤ ìµœì¢… ì‘ë‹µ ë°˜í™˜ (ê¸¸ì´: {len(response) if response else 0}ì)")
                    print(f"ğŸ“¤ ìµœì¢… ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:500] if response else 'None'}...")
                    
                    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë¶„ì„ ë°ì´í„°ë¥¼ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ JSON ë°ì´í„°ë„ í•¨ê»˜ ì „ì†¡
                    return Response({
                        'response': response,
                        'analysisData': final_result.get('llm_ê²€ì¦_ê²°ê³¼', {}),
                        'rationale': final_result.get('ë¶„ì„_ê·¼ê±°', '')
                    })
                    
                except Exception as e:
                    import traceback
                    error_trace = traceback.format_exc()
                    print(f"âŒ ìµœì  ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                    print(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{error_trace}")
                    # í´ë°±: ê¸°ë³¸ ì‘ë‹µ
                    response = f"ìµœì  ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ëŠ” ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                    return Response({'response': response})
            
            # optimal ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°
            # ë¹„ìš© ì ˆì•½: íŒŒì¼ ë¶„ì„ ì‹œ ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            has_image = uploaded_file and not uploaded_file.name.lower().endswith('.pdf')
            has_document = uploaded_file and uploaded_file.name.lower().endswith('.pdf')
            
            # ì§ˆë¬¸ ìœ í˜• ìë™ ê°ì§€
            question_type = None
            if has_image:
                question_type = 'image'
            elif has_document:
                question_type = 'document'
            else:
                question_type = detect_question_type_from_content(final_message)
            
            if uploaded_file and 'íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•´' in final_message:
                # ì´ë¯¸ Ollamaë¡œ ë¶„ì„ëœ ë‚´ìš©ì´ë¯€ë¡œ ê°„ë‹¨í•œ ì‘ë‹µ ìš”ì²­
                simplified_message = f"ë‹¤ìŒ ë¶„ì„ ë‚´ìš©ì— ëŒ€í•´ ê°„ë‹¨í•œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:\n\n{final_message.split('ë‹¤ìŒ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:')[1] if 'ë‹¤ìŒ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:' in final_message else final_message}"
                response = chatbot.chat(simplified_message, has_image=has_image, question_type=question_type)
            else:
                response = chatbot.chat(final_message, has_image=has_image, question_type=question_type)
            
            return Response({'response': response})
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

def collect_multi_llm_responses(user_message, judge_model="GPT-4o", selected_models=None):
    """1ë‹¨ê³„: ì„ íƒëœ LLMë“¤ì—ê²Œ ë³‘ë ¬ ì§ˆì˜ í›„ ì‹¬íŒ ëª¨ë¸ë¡œ ê²€ì¦"""
    import asyncio
    import aiohttp
    import json
    import time
    
    responses = {}
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ë“¤ (ëª…ì‹œì  ëª¨ë¸ëª… ì‚¬ìš©)
    all_llm_endpoints = {
        # GPT ëª¨ë¸ë“¤ (ìµœì‹  ì¶”ê°€)
        'GPT-5': 'http://localhost:8000/chat/gpt-5/',
        'GPT-5-Mini': 'http://localhost:8000/chat/gpt-5-mini/',
        'GPT-4.1': 'http://localhost:8000/chat/gpt-4.1/',
        'GPT-4.1-Mini': 'http://localhost:8000/chat/gpt-4.1-mini/',
        'GPT-4o': 'http://localhost:8000/chat/gpt-4o/',
        'GPT-4o-Mini': 'http://localhost:8000/chat/gpt-4o-mini/',
        'GPT-4-Turbo': 'http://localhost:8000/chat/gpt-4-turbo/',
        'GPT-3.5-Turbo': 'http://localhost:8000/chat/gpt-3.5-turbo/',
        
        # Gemini ëª¨ë¸ë“¤ (ìµœì‹  ì¶”ê°€)
        'Gemini-2.5-Pro': 'http://localhost:8000/chat/gemini-2.5-pro/',
        'Gemini-2.5-Flash': 'http://localhost:8000/chat/gemini-2.5-flash/',
        'Gemini-2.0-Flash-Exp': 'http://localhost:8000/chat/gemini-2.0-flash-exp/',
        'Gemini-2.0-Flash-Lite': 'http://localhost:8000/chat/gemini-2.0-flash-lite/',
        
        # Claude ëª¨ë¸ë“¤ (ìµœì‹  ì¶”ê°€)
        'Claude-4-Opus': 'http://localhost:8000/chat/claude-4-opus/',
        'Claude-3.7-Sonnet': 'http://localhost:8000/chat/claude-3.7-sonnet/',
        'Claude-3.5-Sonnet': 'http://localhost:8000/chat/claude-3.5-sonnet/',
        'Claude-3.5-Haiku': 'http://localhost:8000/chat/claude-3.5-haiku/',
        'Claude-3-Opus': 'http://localhost:8000/chat/claude-3-opus/',
        
        # HyperCLOVA X ëª¨ë¸ë“¤
        'HCX-003': 'http://localhost:8000/chat/clova-hcx-003/',
        'HCX-DASH-001': 'http://localhost:8000/chat/clova-hcx-dash-001/',
    }
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ë“¤ë§Œ í•„í„°ë§ (ê¸°ë³¸ê°’: ëª¨ë“  ëª¨ë¸)
    if selected_models:
        print(f"ğŸ“‹ selected_models ì…ë ¥: {selected_models} (íƒ€ì…: {type(selected_models)})")
        # ì„ íƒëœ ëª¨ë¸ëª…ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        model_mapping = {
            # GPT ëª¨ë¸ë“¤
            'gpt-5': 'GPT-5',
            'gpt-5-mini': 'GPT-5-Mini',
            'gpt-4.1': 'GPT-4.1',
            'gpt-4.1-mini': 'GPT-4.1-Mini',
            'gpt-4o': 'GPT-4o',
            'gpt-4o-mini': 'GPT-4o-Mini',
            'gpt-4-turbo': 'GPT-4-Turbo',
            'gpt-3.5-turbo': 'GPT-3.5-Turbo',
            
            # Gemini ëª¨ë¸ë“¤
            'gemini-2.5-pro': 'Gemini-2.5-Pro',
            'gemini-2.5-flash': 'Gemini-2.5-Flash',
            'gemini-2.0-flash-exp': 'Gemini-2.0-Flash-Exp',
            'gemini-2.0-flash-lite': 'Gemini-2.0-Flash-Lite',
            
            # Claude ëª¨ë¸ë“¤
            'claude-4-opus': 'Claude-4-Opus',
            'claude-3.7-sonnet': 'Claude-3.7-Sonnet',
            'claude-3.5-sonnet': 'Claude-3.5-Sonnet',
            'claude-3.5-haiku': 'Claude-3.5-Haiku',
            'claude-3-opus': 'Claude-3-Opus',
            
            # HyperCLOVA X ëª¨ë¸ë“¤
            'clova-hcx-003': 'HCX-003',
            'clova-hcx-dash-001': 'HCX-DASH-001',
        }
        
        selected_standard_models = []
        for model in selected_models:
            model_lower = model.lower() if isinstance(model, str) else str(model).lower()
            if model_lower in model_mapping:
                selected_standard_models.append(model_mapping[model_lower])
            else:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ëª…: {model}")
        
        # ì„ íƒëœ ëª¨ë¸ë“¤ì˜ ì—”ë“œí¬ì¸íŠ¸ë§Œ ì‚¬ìš©
        llm_endpoints = {k: v for k, v in all_llm_endpoints.items() if k in selected_standard_models}
        print(f"ğŸ“‹ ë§¤í•‘ëœ í‘œì¤€ ëª¨ë¸: {selected_standard_models}")
    else:
        # ì„ íƒëœ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ 3ê°œ ì‚¬ìš© (ë¹„ìš© ì ˆê°)
        print(f"âš ï¸ selected_modelsê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ 3ê°œ ì‚¬ìš©")
        default_models = ['GPT-4o-Mini', 'Gemini-2.0-Flash-Lite', 'Claude-3.5-Haiku']
        llm_endpoints = {k: v for k, v in all_llm_endpoints.items() if k in default_models}
    
    if not llm_endpoints:
        print(f"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤!")
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. selected_modelsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    print(f"ğŸ¯ ì„ íƒëœ LLM ëª¨ë¸ë“¤: {list(llm_endpoints.keys())} (ì´ {len(llm_endpoints)}ê°œ)")
    
    async def fetch_response(session, ai_name, endpoint):
        """ê°œë³„ LLMì—ì„œ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°"""
        try:
            payload = {
                'message': user_message,
                'user_id': 'system'
            }
            
            async with session.post(endpoint, json=payload, timeout=30) as response:
                if response.status == 200:
                    result = await response.json()
                    return ai_name, result.get('response', 'ì‘ë‹µ ì—†ìŒ')
                else:
                    return ai_name, f'ì˜¤ë¥˜: HTTP {response.status}'
        except Exception as e:
            return ai_name, f'ì˜¤ë¥˜: {str(e)}'
    
    async def collect_all_responses():
        """ëª¨ë“  LLMì—ì„œ ë™ì‹œì— ì‘ë‹µ ìˆ˜ì§‘"""
        async with aiohttp.ClientSession() as session:
            tasks = []
            for ai_name, endpoint in llm_endpoints.items():
                task = fetch_response(session, ai_name, endpoint)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in results:
                if isinstance(result, tuple):
                    ai_name, response = result
                    responses[ai_name] = response
                elif isinstance(result, Exception):
                    print(f"LLM ì‘ë‹µ ìˆ˜ì§‘ ì˜¤ë¥˜: {result}")
    
    try:
        # ë¹„ë™ê¸° ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(collect_all_responses())
        loop.close()
        
        print(f"âœ… {len(responses)}ê°œ LLMì—ì„œ ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ: {list(responses.keys())}")
        
        if not responses:
            print(f"âŒ ìˆ˜ì§‘ëœ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤!")
            raise ValueError("LLMì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # 3ë‹¨ê³„: ì‹¬íŒ ëª¨ë¸ë¡œ ê²€ì¦ ë° ìµœì  ë‹µë³€ ìƒì„±
        print(f"âš–ï¸ ì‹¬íŒ ëª¨ë¸({judge_model})ë¡œ ê²€ì¦ ë° ìµœì  ë‹µë³€ ìƒì„± ì‹œì‘...")
        final_result = judge_and_generate_optimal_response(responses, user_message, judge_model)
        print(f"âœ… ìµœì  ë‹µë³€ ìƒì„± ì™„ë£Œ: {type(final_result)}, í‚¤: {list(final_result.keys()) if isinstance(final_result, dict) else 'N/A'}")
        return final_result
        
    except Exception as e:
        print(f"âŒ LLM ì‘ë‹µ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ ì‘ë‹µë“¤
        fallback_responses = {
            'GPT-3.5-turbo': f'GPT ì‘ë‹µ (ìˆ˜ì§‘ ì‹¤íŒ¨): {user_message}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.',
            'Claude-3.5-haiku': f'Claude ì‘ë‹µ (ìˆ˜ì§‘ ì‹¤íŒ¨): {user_message}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.',
            'Llama-3.1-8b': f'Llama ì‘ë‹µ (ìˆ˜ì§‘ ì‹¤íŒ¨): {user_message}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.'
        }
        return judge_and_generate_optimal_response(fallback_responses, user_message, judge_model)

def detect_conflicts_in_responses(llm_responses):
    """LLM ì‘ë‹µì—ì„œ ìƒí˜¸ëª¨ìˆœ ê°ì§€ (í•˜ë“œì½”ë”© ì—†ì´ ë²”ìš©ì )"""
    import re
    from collections import defaultdict
    
    conflicts = {
        "dates": defaultdict(list),
        "locations": defaultdict(list), 
        "numbers": defaultdict(list),
        "general_facts": defaultdict(list)
    }
    
    # ê° LLM ì‘ë‹µì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
    for model_name, response in llm_responses.items():
        # ì—°ë„ íŒ¨í„´ ì¶”ì¶œ (4ìë¦¬ ìˆ«ì, 1900-2024 ë²”ìœ„)
        year_pattern = r'(\d{4})'
        year_matches = re.findall(year_pattern, response)
        
        for year_str in year_matches:
            try:
                year = int(year_str)
                if 1900 <= year <= 2024:  # í•©ë¦¬ì ì¸ ì—°ë„ ë²”ìœ„
                    conflicts["dates"][year_str].append(model_name)
            except ValueError:
                continue
        
        # ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (ì‹œ/ë„/êµ¬/êµ° íŒ¨í„´)
        locations = re.findall(r'[ê°€-í£]+(?:ì‹œ|ë„|êµ¬|êµ°)', response)
        for location in locations:
            conflicts["locations"][location].append(model_name)
        
        # ìˆ˜ì¹˜ ì •ë³´ ì¶”ì¶œ (ë‹¨ìœ„ í¬í•¨, ì—°ë„ ì œì™¸)
        numbers = re.findall(r'\d+(?:ëª…|ê°œ|ì›”|ì¼|ì–µ|ë§Œ|ì²œ)', response)
        for number in numbers:
            conflicts["numbers"][number].append(model_name)
    
    # ìƒí˜¸ëª¨ìˆœ í•„í„°ë§ (2ê°œ ì´ìƒ ë‹¤ë¥¸ ê°’ì´ ìˆì„ ë•Œë§Œ)
    detected_conflicts = {}
    
    for category, items in conflicts.items():
        if len(items) > 1:  # ì„œë¡œ ë‹¤ë¥¸ ê°’ì´ 2ê°œ ì´ìƒ
            detected_conflicts[category] = dict(items)
    
    return detected_conflicts

def quick_web_verify(conflict_type, conflict_values, question):
    """ê°œì„ ëœ ì›¹ ê²€ì¦ (Wikipedia + Google Search) - ë²”ìš©ì """
    import requests
    import time
    import re
    
    try:
        print(f"ğŸŒ ì›¹ ê²€ì¦ ì‹œì‘: '{question}'")
        
        # 1ì°¨: Wikipedia API ê²€ìƒ‰ (ì§ˆë¬¸ ê¸°ë°˜)
        print("ğŸ” Wikipedia ê²€ìƒ‰ ì‹œë„...")
        wiki_result = search_wikipedia(question, [])
        if wiki_result.get("verified"):
            print(f"âœ… Wikipedia ê²€ì¦ ì„±ê³µ")
            return wiki_result
        
        # 2ì°¨: Google Search (ê°„ë‹¨í•œ ë°©ë²•)
        print("ğŸ” Google ê²€ìƒ‰ ì‹œë„...")
        google_result = search_google_simple(question, [])
        if google_result.get("verified"):
            print(f"âœ… Google ê²€ì¦ ì„±ê³µ")
            return google_result
        
        # ëª¨ë“  ê²€ìƒ‰ì´ ì‹¤íŒ¨í•œ ê²½ìš°
        print("âš ï¸ ëª¨ë“  ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨")
        return {"verified": False, "error": "ëª¨ë“  ê²€ìƒ‰ ì—”ì§„ ì‹¤íŒ¨"}
                
    except Exception as e:
        print(f"âš ï¸ ì›¹ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {"verified": False, "error": str(e)}

def search_wikipedia(question, keywords):
    """Wikipedia APIë¥¼ í†µí•œ ìë™ ê²€ì¦ (í•˜ë“œì½”ë”© ì—†ìŒ)"""
    import requests
    import re
    
    try:
        # 1ë‹¨ê³„: ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        search_terms = extract_search_terms_from_question(question)
        
        if not search_terms:
            print("âš ï¸ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨")
            return {"verified": False, "error": "ê²€ìƒ‰ í‚¤ì›Œë“œ ì—†ìŒ"}
        
        print(f"ğŸ” Wikipedia ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_terms}")
        
        # 2ë‹¨ê³„: ê° ê²€ìƒ‰ì–´ë¡œ Wikipedia ê²€ìƒ‰ ì‹œë„
        for term in search_terms[:3]:  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ ì‹œë„
            # í•œê¸€ Wikipedia ê²€ìƒ‰
            wiki_results = search_wikipedia_api(term, 'ko')
            
            if wiki_results.get("verified"):
                return wiki_results
            
            # ì‹¤íŒ¨ ì‹œ ì˜ì–´ Wikipedia ê²€ìƒ‰
            wiki_results_en = search_wikipedia_api(term, 'en')
            
            if wiki_results_en.get("verified"):
                return wiki_results_en
        
        print("âš ï¸ ëª¨ë“  Wikipedia ê²€ìƒ‰ ì‹¤íŒ¨")
        return {"verified": False, "error": "Wikipedia ê²€ìƒ‰ ì‹¤íŒ¨"}
        
    except Exception as e:
        print(f"âš ï¸ Wikipedia ê²€ì¦ ì˜¤ë¥˜: {e}")
        return {"verified": False, "error": f"Wikipedia ì˜¤ë¥˜: {e}"}

def extract_search_terms_from_question(question):
    """ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ (ë²”ìš©ì )"""
    import re
    
    keywords = []
    
    # 1. ì¼ë°˜ì ì¸ ëª…ì‚¬ íŒ¨í„´ (í•˜ë“œì½”ë”© ì—†ì´)
    # í•œêµ­ì–´ ëª…ì‚¬ íŒ¨í„´ (2ê¸€ì ì´ìƒ)
    korean_nouns = re.findall(r'[ê°€-í£]{2,}', question)
    keywords.extend(korean_nouns)
    
    # ì˜ì–´ ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë‹¨ì–´ë“¤ (ê³ ìœ ëª…ì‚¬)
    english_proper_nouns = re.findall(r'[A-Z][a-z]+(?:\s[A-Z][a-z]+)*', question)
    keywords.extend(english_proper_nouns)
    
    # ìˆ«ìì™€ í•¨ê»˜ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ (ì—°ë„, ìˆ˜ì¹˜ ë“±)
    number_words = re.findall(r'\d{4}ë…„?|\d+ëª…?|\d+ê°œ?', question)
    keywords.extend(number_words)
    
    # íŠ¹ìˆ˜ íŒ¨í„´ë“¤ (ë²”ìš©ì )
    special_patterns = [
        r'([ê°€-í£]+ëŒ€í•™êµ?)',  # ëŒ€í•™êµ
        r'([ê°€-í£]+ëŒ€í•™?)',    # ëŒ€í•™
        r'([ê°€-í£]+íšŒì‚¬?)',    # íšŒì‚¬
        r'([ê°€-í£]+ì •ë¶€?)',    # ì •ë¶€
        r'([ê°€-í£]+ì‚¬ê±´?)',    # ì‚¬ê±´
        r'([ê°€-í£]+ì „ìŸ?)',    # ì „ìŸ
        r'([ê°€-í£]+í˜ëª…?)',    # í˜ëª…
        r'([ê°€-í£]+ì˜¬ë¦¼í”½?)',  # ì˜¬ë¦¼í”½
    ]
    
    for pattern in special_patterns:
        matches = re.findall(pattern, question)
        keywords.extend(matches)
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
    unique_keywords = []
    for kw in keywords:
        if kw and kw not in unique_keywords and len(kw.strip()) > 1:
            # ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤ ì œì™¸
            common_words = ['ì„¤ëª…', 'ëŒ€í•´', 'ì•Œë ¤', 'ì¤˜', 'í•´ì¤˜', 'ì–´ë–¤', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””', 'ì™œ', 'ì–´ë–»ê²Œ']
            if kw.strip() not in common_words:
                unique_keywords.append(kw.strip())
    
    # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ë°˜í™˜ (ë„ˆë¬´ ë§ìœ¼ë©´ ê²€ìƒ‰ì´ ë¹„íš¨ìœ¨ì )
    print(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: {unique_keywords[:3]}")
    return unique_keywords[:3]

def search_wikipedia_api(search_term, lang='ko'):
    """Wikipedia API ì‹¤ì œ ê²€ìƒ‰"""
    import requests
    import re
    from collections import Counter
    
    try:
        # User-Agent í—¤ë” ì¶”ê°€ (Wikipedia API ìš”êµ¬ì‚¬í•­)
        headers = {
            'User-Agent': 'AI_of_AI_ChatBot/1.0 (Educational Project)'
        }
        
        # Wikipedia Search APIë¡œ í˜ì´ì§€ ì°¾ê¸°
        search_url = f"https://{lang}.wikipedia.org/w/api.php"
        search_params = {
            'action': 'opensearch',
            'search': search_term,
            'limit': 1,
            'namespace': 0,
            'format': 'json'
        }
        
        response = requests.get(search_url, params=search_params, headers=headers, timeout=5)
        
        if response.status_code != 200:
            return {"verified": False, "error": f"ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code}"}
        
        search_results = response.json()
        
        if not search_results or len(search_results) < 2 or not search_results[1]:
            print(f"âš ï¸ '{search_term}' Wikipedia í˜ì´ì§€ ì—†ìŒ")
            return {"verified": False, "error": "í˜ì´ì§€ ì—†ìŒ"}
        
        page_title = search_results[1][0]
        print(f"ğŸ“„ Wikipedia í˜ì´ì§€ ë°œê²¬: {page_title}")
        
        # í˜ì´ì§€ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°
        summary_url = f"https://{lang}.wikipedia.org/api/rest_v1/page/summary/{page_title}"
        summary_response = requests.get(summary_url, headers=headers, timeout=5)
        
        if summary_response.status_code == 200:
            data = summary_response.json()
            extract = data.get('extract', '')
            
            if extract and len(extract) > 20:
                print(f"âœ… Wikipedia ìš”ì•½: {extract[:100]}...")
                
                # ëª¨ë“  ì •ë³´ ì¶”ì¶œ (ì—°ë„, ìœ„ì¹˜, ê¸°íƒ€ ì •ë³´)
                extracted_info = {
                    "verified": True,
                    "source": f"Wikipedia ({lang})",
                    "abstract": extract[:400] + "..." if len(extract) > 400 else extract,
                    "full_text": extract,  # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
                    "confidence": 0.95,
                    "page_title": page_title
                }
                
                # ì—°ë„ íŒ¨í„´ ì¶”ì¶œ (ì„¤ë¦½, ì°½ë¦½, ê°œêµ ë“±)
                years = re.findall(r'(\d{4})', extract)
                valid_years = [year for year in years if 1900 <= int(year) <= 2024]
                
                if valid_years:
                    # ì„¤ë¦½/ê°œêµ ê´€ë ¨ ì—°ë„ ìš°ì„  ì¶”ì¶œ
                    founding_patterns = [
                        r'(\d{4})ë…„[^\d]*(?:ì„¤ë¦½|ì°½ë¦½|ê°œêµ|ëŒ€í•™.*ì„¤ë¦½|ëŒ€í•™êµ.*ì„¤ë¦½|ì„¤ë¦½.*ëŒ€í•™)',
                        r'(?:ì„¤ë¦½|ì°½ë¦½|ê°œêµ)[^\d]*(\d{4})ë…„',
                        r'(\d{4})ë…„.*(?:ì¶œë²”|íƒ„ìƒ|ìƒì„±)'
                    ]
                    
                    # ê° íŒ¨í„´ì—ì„œ ê°€ì¥ ë¨¼ì € ë§¤ì¹˜ë˜ëŠ” ì—°ë„ ì°¾ê¸° (ìœ„ì¹˜ ê¸°ì¤€)
                    first_matches = []
                    for pattern in founding_patterns:
                        match = re.search(pattern, extract, re.IGNORECASE)
                        if match:
                            matched_year = match.group(1)
                            if matched_year in valid_years:
                                position = match.start()
                                first_matches.append((position, matched_year))
                    
                    if first_matches:
                        # ìœ„ì¹˜ê°€ ê°€ì¥ ì•ì„  ì—°ë„ ì„ íƒ
                        first_matches.sort()
                        most_common_year = first_matches[0][1]
                    else:
                        # ì„¤ë¦½ ì—°ë„ íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê°€ì¥ ìì£¼ ì–¸ê¸‰ëœ ì—°ë„
                        year_counts = Counter(valid_years)
                        most_common_year = year_counts.most_common(1)[0][0]
                    
                    extracted_info["extracted_year"] = most_common_year
                    print(f"ğŸ“… ì¶”ì¶œëœ ì—°ë„: {most_common_year}ë…„")
                
                # ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (ì‹œ, ë„, êµ¬ ë“±)
                location_patterns = [
                    r'([ê°€-í£]+íŠ¹ë³„ì‹œ|[ê°€-í£]+ê´‘ì—­ì‹œ|[ê°€-í£]+ì‹œ)\s+([ê°€-í£]+êµ¬|[ê°€-í£]+êµ°)',
                    r'([ê°€-í£]+íŠ¹ë³„ì‹œ|[ê°€-í£]+ê´‘ì—­ì‹œ|[ê°€-í£]+ì‹œ)',
                    r'([ê°€-í£]+ë„)\s+([ê°€-í£]+ì‹œ)',
                ]
                
                for pattern in location_patterns:
                    location_matches = re.findall(pattern, extract)
                    if location_matches:
                        if isinstance(location_matches[0], tuple):
                            location = ' '.join(location_matches[0])
                        else:
                            location = location_matches[0]
                        extracted_info["location"] = location
                        print(f"ğŸ“ ì¶”ì¶œëœ ìœ„ì¹˜: {location}")
                        break
                
                # êµ­ë¦½/ì‚¬ë¦½/ê³µë¦½ ì •ë³´ ì¶”ì¶œ
                if 'êµ­ë¦½' in extract:
                    extracted_info["type"] = "êµ­ë¦½"
                    print(f"ğŸ›ï¸ ìœ í˜•: êµ­ë¦½")
                elif 'ì‚¬ë¦½' in extract:
                    extracted_info["type"] = "ì‚¬ë¦½"
                    print(f"ğŸ›ï¸ ìœ í˜•: ì‚¬ë¦½")
                
                # ì—°ë„ê°€ ì—†ìœ¼ë©´ ë³¸ë¬¸ì—ì„œ ì¶”ê°€ ê²€ìƒ‰
                if not extracted_info.get("extracted_year"):
                    print("âš ï¸ ìš”ì•½ì— ì—°ë„ ì—†ìŒ, ë³¸ë¬¸ APIë¡œ fallback...")
                    full_text_result = get_wikipedia_full_text(page_title, lang, headers)
                    if full_text_result.get("verified") and full_text_result.get("extracted_year"):
                        extracted_info["extracted_year"] = full_text_result["extracted_year"]
                        print(f"ğŸ“… ë³¸ë¬¸ì—ì„œ ì¶”ì¶œëœ ì„¤ë¦½ì—°ë„: {full_text_result['extracted_year']}ë…„")
                
                return extracted_info
        
        return {"verified": False, "error": "ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨"}
        
    except Exception as e:
        return {"verified": False, "error": f"API ì˜¤ë¥˜: {e}"}

def get_wikipedia_full_text(page_title, lang, headers):
    """Wikipedia ë³¸ë¬¸ì—ì„œ ì—°ë„ ì •ë³´ ì¶”ì¶œ"""
    import requests
    import re
    from collections import Counter
    
    try:
        # Wikipedia Parse APIë¡œ ë³¸ë¬¸ ì¼ë¶€ ê°€ì ¸ì˜¤ê¸°
        parse_url = f"https://{lang}.wikipedia.org/w/api.php"
        parse_params = {
            'action': 'query',
            'prop': 'extracts',
            'exintro': True,  # ì„œë¡ ë§Œ ê°€ì ¸ì˜¤ê¸°
            'explaintext': True,  # ìˆœìˆ˜ í…ìŠ¤íŠ¸
            'titles': page_title,
            'format': 'json'
        }
        
        response = requests.get(parse_url, params=parse_params, headers=headers, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            pages = data.get('query', {}).get('pages', {})
            
            if pages:
                page = list(pages.values())[0]
                full_text = page.get('extract', '')
                
                if full_text and len(full_text) > 50:
                    print(f"ğŸ“„ Wikipedia ë³¸ë¬¸: {full_text[:150]}...")
                    
                    # ì—°ë„ íŒ¨í„´ ì¶”ì¶œ (ì„¤ë¦½/ê°œêµ ê´€ë ¨ ì—°ë„ ìš°ì„ )
                    years = re.findall(r'(\d{4})', full_text)
                    valid_years = [year for year in years if 1900 <= int(year) <= 2024]
                    
                    if valid_years:
                        # ì„¤ë¦½/ê°œêµ í‚¤ì›Œë“œê°€ ìˆëŠ” ë¬¸ì¥ì—ì„œ ì—°ë„ ìš°ì„  ì¶”ì¶œ
                        founding_patterns = [
                            r'(\d{4})ë…„[^\d]*(?:ì„¤ë¦½|ì°½ë¦½|ê°œêµ|ëŒ€í•™.*ì„¤ë¦½|ëŒ€í•™êµ.*ì„¤ë¦½|ì„¤ë¦½.*ëŒ€í•™)',
                            r'(?:ì„¤ë¦½|ì°½ë¦½|ê°œêµ)[^\d]*(\d{4})ë…„',
                            r'(\d{4})ë…„.*(?:ì¶œë²”|íƒ„ìƒ|ìƒì„±)'
                        ]
                        # ê° íŒ¨í„´ì—ì„œ ê°€ì¥ ë¨¼ì € ë§¤ì¹˜ë˜ëŠ” ì—°ë„ ì°¾ê¸° (ìœ„ì¹˜ ê¸°ì¤€)
                        first_matches = []
                        for pattern in founding_patterns:
                            match = re.search(pattern, full_text, re.IGNORECASE)
                            if match:
                                matched_year = match.group(1)
                                if matched_year in valid_years:
                                    position = match.start()
                                    first_matches.append((position, matched_year))
                        
                        if first_matches:
                            # ìœ„ì¹˜ê°€ ê°€ì¥ ì•ì„  ì—°ë„ ì„ íƒ (ì›ë˜ ì„¤ë¦½ ì—°ë„ ìš°ì„ )
                            first_matches.sort()  # ìœ„ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬
                            most_common_year = first_matches[0][1]
                        else:
                            # ì—†ìœ¼ë©´ ê°€ì¥ ìì£¼ ì–¸ê¸‰ëœ ì—°ë„ ì„ íƒ
                            year_counts = Counter(valid_years)
                            most_common_year = year_counts.most_common(1)[0][0]
                        
                        return {
                            "verified": True,
                            "source": f"Wikipedia Full Text ({lang})",
                            "extracted_year": most_common_year,
                            "abstract": full_text[:200] + "..." if len(full_text) > 200 else full_text,
                            "confidence": 0.85,
                            "page_title": page_title
                        }
        
        return {"verified": False, "error": "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"}
        
    except Exception as e:
        return {"verified": False, "error": f"ë³¸ë¬¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}

def search_google_simple(question, keywords):
    """ëŒ€ì²´ ê²€ìƒ‰ ë°©ë²• (Wikipedia ì‹¤íŒ¨ ì‹œ)"""
    # Wikipedia APIê°€ ì‹¤íŒ¨í•œ ê²½ìš° ë‹¤ë¥¸ ê³µê°œ API ì‹œë„ ê°€ëŠ¥
    # í˜„ì¬ëŠ” Wikipediaì—ë§Œ ì˜ì¡´
    return {"verified": False, "error": "Wikipedia ì™¸ ê²€ìƒ‰ ë¯¸êµ¬í˜„"}

def detect_question_type_from_content(content):
    """ì§ˆë¬¸ ë‚´ìš©ì—ì„œ ì‹¤ì œ ì§ˆë¬¸ ìœ í˜• ê°ì§€: code, image, document, creative, general"""
    import re
    
    content_lower = content.lower()
    
    # ì½”ë“œ ê´€ë ¨ í‚¤ì›Œë“œ (ì½”ë“œ ì‘ì„±, êµ¬í˜„, í•¨ìˆ˜, ì•Œê³ ë¦¬ì¦˜ ë“±)
    code_keywords = ['ì½”ë“œ', 'code', 'í•¨ìˆ˜', 'function', 'í”„ë¡œê·¸ë˜ë°', 'programming', 'ì•Œê³ ë¦¬ì¦˜', 'algorithm', 
                     'êµ¬í˜„', 'implement', 'ì‘ì„±', 'write', 'ê°œë°œ', 'develop', 'ìŠ¤í¬ë¦½íŠ¸', 'script',
                     'íŒŒì´ì¬', 'python', 'ìë°”', 'java', 'ìë°”ìŠ¤í¬ë¦½íŠ¸', 'javascript', 'c++', 'c#']
    
    # ì´ë¯¸ì§€ ê´€ë ¨ í‚¤ì›Œë“œ
    image_keywords = ['ì´ë¯¸ì§€', 'image', 'ì‚¬ì§„', 'photo', 'ê·¸ë¦¼', 'picture', 'ì‹œê°', 'visual', 'í™”ë©´']
    
    # ë¬¸ì„œ ê´€ë ¨ í‚¤ì›Œë“œ
    document_keywords = ['ë¬¸ì„œ', 'document', 'pdf', 'íŒŒì¼', 'file', 'ìš”ì•½', 'summary', 'ë‚´ìš©', 'content']
    
    # ì°½ì‘/ê¸€ì“°ê¸° ê´€ë ¨ í‚¤ì›Œë“œ
    creative_keywords = ['ê¸€ì“°ê¸°', 'writing', 'ì°½ì‘', 'creative', 'ì†Œì„¤', 'novel', 'ì‹œ', 'poem', 'ì—ì„¸ì´', 'essay',
                        'ì´ì•¼ê¸°', 'story', 'ë‚´ìš© ì‘ì„±', 'write content', 'ë¬¸ì¥', 'sentence']
    
    # ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
    if any(keyword in content_lower for keyword in code_keywords):
        # ì‹¤ì œ ì½”ë“œ ì‘ì„± ìš”ì²­ì¸ì§€ í™•ì¸ (ì˜ˆ: "ì½”ë“œ ì‘ì„±", "í•¨ìˆ˜ ë§Œë“¤ì–´ì¤˜", "êµ¬í˜„í•´ì¤˜" ë“±)
        code_patterns = [
            r'ì½”ë“œ.*ì‘ì„±|ì‘ì„±.*ì½”ë“œ',
            r'í•¨ìˆ˜.*ë§Œë“¤|ë§Œë“¤.*í•¨ìˆ˜',
            r'êµ¬í˜„.*í•´|í•´.*êµ¬í˜„',
            r'ì½”ë“œ.*ë³´ì—¬|ë³´ì—¬.*ì½”ë“œ',
            r'í”„ë¡œê·¸ë¨.*ì‘ì„±|ì‘ì„±.*í”„ë¡œê·¸ë¨',
            r'íŒŒì´ì¬.*ì½”ë“œ|ì½”ë“œ.*íŒŒì´ì¬',
            r'ì•Œê³ ë¦¬ì¦˜.*êµ¬í˜„|êµ¬í˜„.*ì•Œê³ ë¦¬ì¦˜'
        ]
        if any(re.search(pattern, content_lower) for pattern in code_patterns):
            return 'code'
    
    # ì´ë¯¸ì§€ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€ (ì´ë¯¸ì§€ê°€ ì‹¤ì œë¡œ ì—…ë¡œë“œëœ ê²½ìš°ëŠ” has_imageë¡œ ì²˜ë¦¬ë¨)
    if any(keyword in content_lower for keyword in image_keywords):
        # ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ì¸ì§€ í™•ì¸
        image_patterns = [
            r'ì´ë¯¸ì§€.*ë¶„ì„|ë¶„ì„.*ì´ë¯¸ì§€',
            r'ì‚¬ì§„.*ì„¤ëª…|ì„¤ëª….*ì‚¬ì§„',
            r'ê·¸ë¦¼.*ë­|ë­.*ê·¸ë¦¼',
            r'ì´ë¯¸ì§€.*ë­|ë­.*ì´ë¯¸ì§€'
        ]
        if any(re.search(pattern, content_lower) for pattern in image_patterns):
            return 'image'
    
    # ë¬¸ì„œ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
    if any(keyword in content_lower for keyword in document_keywords):
        # ë¬¸ì„œ ë¶„ì„ ìš”ì²­ì¸ì§€ í™•ì¸
        document_patterns = [
            r'ë¬¸ì„œ.*ë¶„ì„|ë¶„ì„.*ë¬¸ì„œ',
            r'íŒŒì¼.*ë‚´ìš©|ë‚´ìš©.*íŒŒì¼',
            r'pdf.*ìš”ì•½|ìš”ì•½.*pdf',
            r'ë¬¸ì„œ.*ìš”ì•½|ìš”ì•½.*ë¬¸ì„œ'
        ]
        if any(re.search(pattern, content_lower) for pattern in document_patterns):
            return 'document'
    
    # ì°½ì‘/ê¸€ì“°ê¸° ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
    if any(keyword in content_lower for keyword in creative_keywords):
        # ì°½ì‘ ìš”ì²­ì¸ì§€ í™•ì¸
        creative_patterns = [
            r'ê¸€.*ì“°|ì“°.*ê¸€',
            r'ì†Œì„¤.*ì‘ì„±|ì‘ì„±.*ì†Œì„¤',
            r'ì‹œ.*ì‘ì„±|ì‘ì„±.*ì‹œ',
            r'ì´ì•¼ê¸°.*ë§Œë“¤|ë§Œë“¤.*ì´ì•¼ê¸°',
            r'ì°½ì‘.*í•´|í•´.*ì°½ì‘',
            r'ì—ì„¸ì´.*ì‘ì„±|ì‘ì„±.*ì—ì„¸ì´'
        ]
        if any(re.search(pattern, content_lower) for pattern in creative_patterns):
            return 'creative'
    
    # ê¸°ë³¸ê°’: ì¼ë°˜ ì§ˆë¬¸
    return 'general'

def classify_question_type(question):
    """ì§ˆë¬¸ ìœ í˜• ìë™ ë¶„ë¥˜: ì‚¬ì‹¤(Factual) vs ì˜ê²¬(Opinion)"""
    try:
        import openai
        import os
        
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        classification_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì´ "ì‚¬ì‹¤ì  ì§ˆë¬¸", "ì˜ê²¬/ì¶”ì²œ ì§ˆë¬¸", ë˜ëŠ” "ì½”ë“œ/í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸"ì¸ì§€ ë¶„ë¥˜í•˜ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ë¶„ë¥˜ ê¸°ì¤€:
- ì‚¬ì‹¤ì  ì§ˆë¬¸: ê°ê´€ì  ì‚¬ì‹¤, ì •í™•í•œ ë‹µì´ ì¡´ì¬ (ì˜ˆ: ì„¤ë¦½ì—°ë„, ìœ„ì¹˜, ì—­ì‚¬ì  ì‚¬ì‹¤)
- ì˜ê²¬/ì¶”ì²œ ì§ˆë¬¸: ì£¼ê´€ì  í‰ê°€, ì¶”ì²œ, ì„ í˜¸ë„ (ì˜ˆ: ë§›ì§‘ ì¶”ì²œ, ì¢‹ì€ ì¹´í˜, ìµœê³ ì˜ ì œí’ˆ)
- ì½”ë“œ/í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸: ì½”ë“œ ì‘ì„±, í”„ë¡œê·¸ë˜ë° ì˜ˆì œ, ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ìš”ì²­ (ì˜ˆ: "ë³„ì°ê¸° ì½”ë“œ", "íŒŒì´ì¬ìœ¼ë¡œ ì‘ì„±", "í•¨ìˆ˜ ë§Œë“¤ì–´ì¤˜")

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
  "type": "factual" ë˜ëŠ” "opinion" ë˜ëŠ” "code",
  "confidence": 0.0-1.0,
  "reason": "ë¶„ë¥˜ ì´ìœ "
}}
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                {"role": "user", "content": classification_prompt}
            ],
            temperature=0.0,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        print(f"ğŸ“ ì§ˆë¬¸ ìœ í˜•: {result['type']} (ì‹ ë¢°ë„: {result['confidence']})")
        print(f"   ì´ìœ : {result['reason']}")
        
        return result['type']
        
    except Exception as e:
        print(f"âš ï¸ ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ 'factual' ì‚¬ìš©")
        return "factual"

def judge_and_generate_optimal_response(llm_responses, user_question, judge_model="GPT-5"):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦ ì‹œìŠ¤í…œ: LLM ë¹„êµ + ì„ íƒì  ì›¹ ê²€ì¦ + ë‹¤ìˆ˜ê²°"""
    try:
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦ ì‹œì‘: {user_question}")
        
        # 0ë‹¨ê³„: ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
        question_type = classify_question_type(user_question)
        
        # 1ë‹¨ê³„: ìƒí˜¸ëª¨ìˆœ ê°ì§€
        conflicts = detect_conflicts_in_responses(llm_responses)
        print(f"ğŸ“Š ê°ì§€ëœ ìƒí˜¸ëª¨ìˆœ: {conflicts}")
        print(f"ğŸ” ìƒí˜¸ëª¨ìˆœ ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(conflicts)}")
        for category, items in conflicts.items():
            print(f"  - {category}: {items}")
        
        # 2ë‹¨ê³„: ì˜ê²¬ ì§ˆë¬¸ - Tie-breaker í™•ì¸
        if question_type == "opinion" and len(llm_responses) == 2:
            print("ğŸ—³ï¸ ì˜ê²¬ ì§ˆë¬¸ + 2ê°œ ëª¨ë¸ â†’ Tie-breaker í˜¸ì¶œ")
            # Tie-breaker ë¡œì§ì€ ë‚˜ì¤‘ì— êµ¬í˜„
            pass
        
        # 3ë‹¨ê³„: ì›¹ ê²€ì¦ (ì‚¬ì‹¤ ì§ˆë¬¸ë§Œ) ë˜ëŠ” ë‹¤ìˆ˜ê²° (ì˜ê²¬ ì§ˆë¬¸) ë˜ëŠ” ì½”ë“œ í’ˆì§ˆ í‰ê°€ (ì½”ë“œ ì§ˆë¬¸)
        verified_facts = {}
        web_verification_used = False
        
        if question_type == "code":
            print(f"ğŸ’» ì½”ë“œ ì§ˆë¬¸ ê°ì§€ â†’ Wikipedia ê²€ì¦ ìƒëµ, ì½”ë“œ í’ˆì§ˆ í‰ê°€ ì‚¬ìš©")
            web_result = {"verified": False}
        elif question_type == "factual":
            print(f"ğŸŒ Wikipedia ì›¹ ê²€ì¦ ì‹œì‘... ì§ˆë¬¸: '{user_question}'")
            
            # ë²”ìš©ì  ì›¹ ê²€ì¦ - ì‚¬ì‹¤ ì§ˆë¬¸ì—ë§Œ ì ìš©
            web_result = quick_web_verify("general", {}, user_question)
        else:
            print(f"ğŸ—³ï¸ ì˜ê²¬ ì§ˆë¬¸ â†’ Wikipedia ê²€ì¦ ìƒëµ, ë‹¤ìˆ˜ê²° ë°©ì‹ ì‚¬ìš©")
            web_result = {"verified": False}
        
        if web_result.get("verified"):
            # ê²€ì¦ëœ ì •ë³´ë¥¼ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ì— ì €ì¥
            if web_result.get('extracted_year'):
                verified_facts["dates"] = web_result
            if web_result.get('location'):
                if "locations" not in verified_facts:
                    verified_facts["locations"] = web_result
                else:
                    verified_facts["locations"].update(web_result)
            if not verified_facts:  # ì•„ë¬´ê²ƒë„ ì €ì¥ë˜ì§€ ì•Šì€ ê²½ìš°
                verified_facts["general_facts"] = web_result
                
            web_verification_used = True
            
            # ê²€ì¦ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥
            info_parts = []
            if web_result.get('extracted_year'):
                info_parts.append(f"ì—°ë„ {web_result.get('extracted_year')}ë…„")
            if web_result.get('location'):
                info_parts.append(f"ìœ„ì¹˜ {web_result.get('location')}")
            if web_result.get('type'):
                info_parts.append(f"ìœ í˜• {web_result.get('type')}")
            
            print(f"âœ… ì›¹ ê²€ì¦ ì„±ê³µ: {', '.join(info_parts)}")
        else:
            print(f"âš ï¸ ì›¹ ê²€ì¦ ì‹¤íŒ¨: {web_result.get('error')}")
        
        # ìƒí˜¸ëª¨ìˆœ ê¸°ë°˜ ê²€ì¦ (ì›¹ ê²€ì¦ ì„±ê³µ/ì‹¤íŒ¨ì™€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰)
        if conflicts:
            print("âš¡ ìƒí˜¸ëª¨ìˆœ ë°œê²¬! ìƒí˜¸ëª¨ìˆœ ê¸°ë°˜ ê²€ì¦ ì‹œì‘...")
            print(f"ğŸ” ì²˜ë¦¬í•  ìƒí˜¸ëª¨ìˆœ: {conflicts}")
            
            for conflict_type, conflict_values in conflicts.items():
                # ì›¹ ê²€ì¦ì´ ì´ë¯¸ ì„±ê³µí•œ í•­ëª©ì€ ë®ì–´ì“°ì§€ ì•ŠìŒ
                if conflict_type not in verified_facts or not verified_facts[conflict_type].get("verified"):
                    verified_facts[conflict_type] = {
                        "verified": False,
                        "conflict_detected": True,
                        "conflict_values": list(conflict_values.keys()),
                        "conflict_details": dict(conflict_values)  # {ê°’: [AIëª©ë¡]}
                    }
                    print(f"âœ… ìƒí˜¸ëª¨ìˆœ ì²˜ë¦¬ë¨: {conflict_type} -> {verified_facts[conflict_type]}")
                else:
                    print(f"â„¹ï¸ {conflict_type}ëŠ” ì´ë¯¸ Wikipedia ê²€ì¦ ì™„ë£Œ, ìƒí˜¸ëª¨ìˆœ ì²˜ë¦¬ ê±´ë„ˆëœ€")
        else:
            print("â„¹ï¸ ìƒí˜¸ëª¨ìˆœ ì—†ìŒ")
        
        # 3ë‹¨ê³„: ì‹¬íŒ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì›¹ ê²€ì¦ ê²°ê³¼ í¬í•¨)
        model_sections = []
        verification_json_entries = []
        
        for model_name, response in llm_responses.items():
            model_sections.append(f"[{model_name} ë‹µë³€]\n{response}")
            verification_json_entries.append(f'    "{model_name}": {{"accuracy": "ì •í™•ì„±_íŒì •", "errors": "êµ¬ì²´ì _ì˜¤ë¥˜_ì„¤ëª…", "confidence": "ì‹ ë¢°ë„_0-100", "adopted_info": ["ì±„íƒëœ_ì •ë³´ë“¤"], "rejected_info": ["ì œì™¸ëœ_ì •ë³´ë“¤ê³¼_ì´ìœ "]}}')
        
        model_responses_text = "\n\n".join(model_sections)
        verification_json_format = ",\n".join(verification_json_entries)
        
        # ì›¹ ê²€ì¦ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ (ë²”ìš©ì )
        web_verification_text = ""
        if web_verification_used:
            # ëª¨ë“  ê²€ì¦ëœ ì‚¬ì‹¤ì— ëŒ€í•´ ë²”ìš©ì ìœ¼ë¡œ ì²˜ë¦¬
            verified_info_parts = []
            
            for fact_type, verification in verified_facts.items():
                if verification.get('verified'):
                    if verification.get('extracted_year'):
                        verified_info_parts.append(f"- **âœ… ê³µì‹ ì—°ë„**: {verification['extracted_year']}ë…„")
                    if verification.get('location'):
                        verified_info_parts.append(f"- **âœ… ê³µì‹ ìœ„ì¹˜**: {verification['location']}")
                    if verification.get('type'):
                        verified_info_parts.append(f"- **âœ… ê³µì‹ ìœ í˜•**: {verification['type']}")
                    if verification.get('abstract') and not any([verification.get('extracted_year'), verification.get('location'), verification.get('type')]):
                        # ê¸°íƒ€ ê²€ì¦ëœ ì •ë³´
                        verified_info_parts.append(f"- **âœ… ê²€ì¦ëœ ì •ë³´**: {verification['abstract'][:100]}...")
            
            if verified_info_parts:
                verified_info_text = '\n'.join(verified_info_parts)
                # ì²« ë²ˆì§¸ ê²€ì¦ ê²°ê³¼ì˜ ì‹ ë¢°ë„ ì‚¬ìš©
                first_verification = next(iter(verified_facts.values()))
                
                # Wikipedia ì›ë¬¸ í¬í•¨ (LLMì´ ì§ì ‘ ë¹„êµ ë¶„ì„ ê°€ëŠ¥)
                wikipedia_full_text = first_verification.get('full_text', '') or first_verification.get('abstract', '')
                wikipedia_excerpt = wikipedia_full_text[:500] if len(wikipedia_full_text) > 500 else wikipedia_full_text
                
                web_verification_text = f"""

**ğŸŒ Wikipedia ì›¹ ê²€ì¦ ê²°ê³¼ (ì‹ ë¢°ë„ {first_verification.get('confidence', 0.9)*100:.0f}%):**
{verified_info_text}
- **ì¶œì²˜**: {first_verification.get('source', 'Wikipedia')}
- **í˜ì´ì§€**: {first_verification.get('page_title', 'í™•ì¸ë¨')}

**ğŸ“– Wikipedia ì›ë¬¸:**
{wikipedia_excerpt}

ğŸš¨ **ì ˆëŒ€ ì¤€ìˆ˜ ê·œì¹™**: ìœ„ Wikipedia ì›ë¬¸ì€ ê³µì‹ ê²€ì¦ëœ ì •ë³´ì…ë‹ˆë‹¤.

**ğŸ“‹ Wikipedia ê²€ì¦ ê¸°ì¤€:**
1. **ì¼ì¹˜í•˜ëŠ” ì •ë³´ = ì±„íƒ**: LLMì´ Wikipediaì™€ ë™ì¼í•œ ì •ë³´ë¥¼ ë§í–ˆë‹¤ë©´ â†’ **ë°˜ë“œì‹œ adopted_infoì— í¬í•¨**
2. **ë¶ˆì¼ì¹˜í•˜ëŠ” ì •ë³´ = ì œì™¸**: LLMì´ Wikipediaì™€ ë‹¤ë¥¸ ì •ë³´ë¥¼ ë§í–ˆë‹¤ë©´ â†’ rejected_infoì— í¬í•¨

**âœ… ì˜¬ë°”ë¥¸ ì²˜ë¦¬ ì˜ˆì‹œ:**
- Wikipedia: "1951ë…„ ì„¤ë¦½"
- LLM A: "1951ë…„ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤" â†’ âœ… **ì¼ì¹˜** â†’ **adopted_infoì— í¬í•¨**
- LLM B: "1946ë…„ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤" â†’ âŒ **ë¶ˆì¼ì¹˜** â†’ rejected_infoì— í¬í•¨

**âŒ ì˜ëª»ëœ ì²˜ë¦¬ (ì ˆëŒ€ ê¸ˆì§€):**
- Wikipedia: "1951ë…„ ì„¤ë¦½"
- LLM A: "1951ë…„ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤" â†’ âŒ "ë¶ˆì¼ì¹˜"ë¼ê³  í‘œì‹œí•˜ë©´ ì•ˆë¨!

**ê° LLM ë‹µë³€ì„ Wikipedia ì›ë¬¸ê³¼ ì§ì ‘ ë¹„êµí•˜ì—¬:**
- ì¼ì¹˜í•˜ëŠ” ë‚´ìš©ì€ **ë°˜ë“œì‹œ ì±„íƒ** (adopted_info)
- ë¶ˆì¼ì¹˜í•˜ëŠ” ë‚´ìš©ë§Œ **ì œì™¸** (rejected_info)
"""
        # ìƒí˜¸ëª¨ìˆœì´ ê°ì§€ëœ ê²½ìš° (ì›¹ ê²€ì¦ ì‹¤íŒ¨ ì‹œ)
        elif any(fact.get("conflict_detected") for fact in verified_facts.values()):
            # ëª¨ë“  ìƒí˜¸ëª¨ìˆœ ìœ í˜•ì— ëŒ€í•´ ë²”ìš©ì ìœ¼ë¡œ ì²˜ë¦¬
            conflict_summaries = []
            conflict_ai_details = []
            
            for conflict_type, conflict_data in verified_facts.items():
                if conflict_data.get("conflict_detected"):
                    conflict_values = conflict_data.get("conflict_values", [])
                    conflict_details = conflict_data.get("conflict_details", {})
                    
                    # ìœ í˜•ë³„ í•œêµ­ì–´ ë¼ë²¨ ë§¤í•‘
                    type_labels = {
                        "dates": "ë‚ ì§œ/ì—°ë„",
                        "locations": "ìœ„ì¹˜",
                        "numbers": "ìˆ˜ì¹˜",
                        "general_facts": "ì¼ë°˜ ì‚¬ì‹¤"
                    }
                    type_label = type_labels.get(conflict_type, conflict_type)
                    
                    conflict_summaries.append(f"- **{type_label} ë¶ˆì¼ì¹˜**: {', '.join(conflict_values)}")
                    
                    # ê° AIë³„ ìƒí˜¸ëª¨ìˆœ ìƒì„¸ ì •ë³´ ìƒì„±
                    for value, ai_list in conflict_details.items():
                        ai_names = ', '.join(ai_list)
                        conflict_ai_details.append(f"- {value} ({type_label}): {ai_names}")
            
            conflict_summary_text = '\n'.join(conflict_summaries)
            conflict_ai_text = '\n'.join(conflict_ai_details)
            
            web_verification_text = f"""

**âš ï¸ ìƒí˜¸ëª¨ìˆœ ê°ì§€ë¨ (ì›¹ ê²€ì¦ ì‹¤íŒ¨):**
{conflict_summary_text}
- **ì¡°ì¹˜**: í™•ì‹ í•  ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” ìµœì  ë‹µë³€ì—ì„œ ìƒëµí•˜ì„¸ìš”

**ğŸš¨ ê° AIë³„ ìƒí˜¸ëª¨ìˆœ ìƒì„¸:**
{conflict_ai_text}

**ğŸš¨ ê° AIë³„ ì˜¤ë¥˜ ì²˜ë¦¬ ê·œì¹™ (í•„ìˆ˜ ì¤€ìˆ˜):**
- ìœ„ì—ì„œ ìƒí˜¸ëª¨ìˆœì— ì°¸ì—¬í•œ ëª¨ë“  AIëŠ” ë°˜ë“œì‹œ "í‹€ë¦° ì •ë³´"ì— "ì •ë³´ ë¶ˆí™•ì‹¤ (ë‹¤ë¥¸ AIì™€ ìƒì¶©)"ì„ ê¸°ë¡í•˜ì„¸ìš”
- ìƒí˜¸ëª¨ìˆœì´ ìˆëŠ” ì •ë³´ëŠ” ì ˆëŒ€ "í‹€ë¦° ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ë©´ ì•ˆë©ë‹ˆë‹¤
- ì˜ˆì‹œ: GPT-4o Miniê°€ 1946ë…„ì´ë¼ê³  í–ˆê³ , Geminiê°€ 1951ë…„ì´ë¼ê³  í–ˆë‹¤ë©´ â†’ ë‘˜ ë‹¤ "í‹€ë¦° ì •ë³´"ì— "ì„¤ë¦½ì—°ë„ ë¶ˆí™•ì‹¤ (ë‹¤ë¥¸ AIì™€ ìƒì¶©)"ì„ ê¸°ë¡
"""
        
        # ìƒí˜¸ëª¨ìˆœ ì •ë³´ê°€ ìˆìœ¼ë©´ ë” ê°•ë ¥í•œ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        contradiction_warning = ""
        has_conflicts = any(fact.get("conflict_detected") for fact in verified_facts.values())
        print(f"ğŸ” ìƒí˜¸ëª¨ìˆœ ê²½ê³  ìƒì„± ì—¬ë¶€: {has_conflicts}")
        print(f"ğŸ” verified_facts: {verified_facts}")
        
        if has_conflicts:
            contradiction_warning = f"""

**ğŸš¨ ìƒí˜¸ëª¨ìˆœ ê°ì§€ë¨ - í•„ìˆ˜ ì²˜ë¦¬ ê·œì¹™:**
{web_verification_text}

**âš ï¸ ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- ìƒí˜¸ëª¨ìˆœì— ì°¸ì—¬í•œ AIì—ê²Œ "í‹€ë¦° ì •ë³´ ì—†ìŒ"ì´ë¼ê³  í•˜ë©´ ì•ˆë©ë‹ˆë‹¤
- ìƒí˜¸ëª¨ìˆœì— ì°¸ì—¬í•œ AIì—ê²Œ "ì •í™•í•œ ì •ë³´ ì œê³µ"ì´ë¼ê³  í•˜ë©´ ì•ˆë©ë‹ˆë‹¤
- ë°˜ë“œì‹œ "í‹€ë¦° ì •ë³´"ì— êµ¬ì²´ì ì¸ ìƒí˜¸ëª¨ìˆœ ë‚´ìš©ì„ ê¸°ë¡í•˜ì„¸ìš”

**âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:**
- GPT-4o Mini: "í‹€ë¦° ì •ë³´: ì„¤ë¦½ì—°ë„ ë¶ˆí™•ì‹¤ (ë‹¤ë¥¸ AIì™€ ìƒì¶©)"
- Gemini 2.0 Flash Lite: "í‹€ë¦° ì •ë³´: ì„¤ë¦½ì—°ë„ ë¶ˆí™•ì‹¤ (ë‹¤ë¥¸ AIì™€ ìƒì¶©)"
- Claude 3.5 Haiku: "í‹€ë¦° ì •ë³´: ì„¤ë¦½ì—°ë„ ë¶ˆí™•ì‹¤ (ë‹¤ë¥¸ AIì™€ ìƒì¶©)"
"""

        # ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ì§€ì‹œì‚¬í•­
        if question_type == "code":
            # ì½”ë“œ ì§ˆë¬¸ ì „ìš© ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (í† í° ì ˆì•½)
            question_type_instruction = """
**ğŸ’» ì´ ì§ˆë¬¸ì€ ì½”ë“œ/í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸ì…ë‹ˆë‹¤:**
- Wikipedia ê²€ì¦ ë¶ˆí•„ìš” - ì½”ë“œ í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”
- ì½”ë“œì˜ ì •í™•ì„±, ì™„ì „ì„±, ê°€ë…ì„±, ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ì„¸ìš”
- ì—¬ëŸ¬ AIì˜ ì½”ë“œë¥¼ ë¹„êµí•˜ì—¬ ê°€ì¥ ì¢‹ì€ ì½”ë“œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì¡°í•©í•˜ì„¸ìš”
- ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í˜•ì‹(```python ... ```)ì„ ìœ ì§€í•˜ì„¸ìš”
"""
            
            # ì½”ë“œ ì§ˆë¬¸ ì „ìš© ê°„ë‹¨í•œ Judge í”„ë¡¬í”„íŠ¸ (í† í° ì ˆì•½)
            judge_prompt = f"""
ì§ˆë¬¸: {user_question}

**ì œê³µëœ AI ì½”ë“œ ë‹µë³€ë“¤:**
{model_responses_text}

**ìµœì  ë‹µë³€ ìƒì„± ê·œì¹™:**
1. ì—¬ëŸ¬ AIì˜ ì½”ë“œë¥¼ ë¹„êµí•˜ì—¬ **ê°€ì¥ ì •í™•í•˜ê³  ì™„ì „í•œ ì½”ë“œ**ë¥¼ ì„ íƒí•˜ì„¸ìš”
2. ì½”ë“œê°€ **ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  ì™„ì „í•œì§€** í™•ì¸í•˜ì„¸ìš”
3. **ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í˜•ì‹**ì„ ìœ ì§€í•˜ì„¸ìš” (```python ... ```)
4. ì—¬ëŸ¬ ì½”ë“œì˜ ì¥ì ì„ ì¡°í•©í•˜ì—¬ ë” ë‚˜ì€ ì½”ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤

**ê° AI ì½”ë“œ í‰ê°€ ê¸°ì¤€:**
- **ì •í™•ì„±**: ìš”êµ¬ì‚¬í•­ ë§Œì¡± ì—¬ë¶€
- **ì™„ì „ì„±**: ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€
- **ê°€ë…ì„±**: ì½”ë“œ ê°€ë…ì„±
- **ìµœì ì„±**: íš¨ìœ¨ì„±ê³¼ ê°„ê²°ì„±

**ğŸš¨ ì¤‘ìš”: verification_results ì‘ì„± ê·œì¹™:**
ê° AIì˜ ì½”ë“œ ë‹µë³€ì—ì„œ:
- **adopted_info**: í•´ë‹¹ AIê°€ ì œê³µí•œ ì½”ë“œ ì¤‘ **ìœ ìš©í•˜ê³  ì •í™•í•œ ë¶€ë¶„**ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬ (ì˜ˆ: "```python\\n...\\n```" í˜•ì‹ì˜ ì½”ë“œ ë¸”ë¡)
- **rejected_info**: í•´ë‹¹ AIê°€ ì œê³µí•œ ì½”ë“œ ì¤‘ **ì˜¤ë¥˜ê°€ ìˆê±°ë‚˜ ë¶ˆì™„ì „í•œ ë¶€ë¶„**ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ [])
- **ë°˜ë“œì‹œ ê° AIì˜ ì›ë³¸ ë‹µë³€ì—ì„œ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬**í•˜ì—¬ adopted_info/rejected_infoì— í¬í•¨í•˜ì„¸ìš”
- **ì ˆëŒ€ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì§€ ë§ˆì„¸ìš”!** ê° AIê°€ ì œê³µí•œ ì½”ë“œê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ adopted_infoì— í¬í•¨í•˜ì„¸ìš”

**ğŸ¨ optimal_answer í¬ë§·íŒ… ê·œì¹™ (í•„ìˆ˜!):**
- **ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡** í˜•ì‹ í•„ìˆ˜: ```python\nì½”ë“œ\n```
- ì½”ë“œ ì„¤ëª…ì€ **ê°„ë‹¨í•œ ë¬¸ë‹¨**ìœ¼ë¡œ ì‘ì„± (ì½”ë“œ ì „í›„)
- ì—¬ëŸ¬ ì˜ˆì œê°€ ìˆìœ¼ë©´ **## ì œëª©**ìœ¼ë¡œ êµ¬ë¶„

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "optimal_answer": "ê°€ì¥ ì¢‹ì€ ì½”ë“œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í¬í•¨)",
  "verification_results": {{
    {verification_json_format}
  }},
  "confidence_score": "ì½”ë“œ í’ˆì§ˆ ì‹ ë¢°ë„ (0-100)",
  "contradictions_detected": [],
  "fact_verification": {{}},
  "analysis_rationale": "ì–´ë–¤ ì½”ë“œë¥¼ ì„ íƒí–ˆëŠ”ì§€ì™€ ê·¸ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…"
}}
"""
        elif question_type == "opinion":
            judge_prompt = f"""
ì§ˆë¬¸: {user_question}

**ğŸ“Š ì˜ê²¬/ì¶”ì²œ ì§ˆë¬¸ - ë‹¤ìˆ˜ê²° ë°©ì‹ ì‚¬ìš©**
- ì—¬ëŸ¬ AIê°€ ê³µí†µì ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” í•­ëª©ì— ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
- ì†Œìˆ˜ ì˜ê²¬ë„ í¬í•¨í•˜ë˜ ë‹¤ìˆ˜ ì˜ê²¬ ìš°ì„  ë°°ì¹˜

**ì œê³µëœ AI ë‹µë³€ë“¤:**
{model_responses_text}
{web_verification_text}
{contradiction_warning}

**í•µì‹¬ ê·œì¹™:**
1. **ì›ë³¸ ë¬¸ì¥ë§Œ ì‚¬ìš©** - ìƒˆë¡œìš´ ë¬¸ì¥ ì‘ì„±/ìš”ì•½/ì¬êµ¬ì„± ê¸ˆì§€
2. **ì—¬ëŸ¬ AI ë‹µë³€ ì¡°í•©** - ë‹¨ì¼ ëª¨ë¸ ì„ íƒ ê¸ˆì§€
3. **í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€** - LLMì´ ì–¸ê¸‰í•˜ì§€ ì•Šì€ ë‚´ìš© í¬í•¨ ê¸ˆì§€
4. **ê° AIì˜ ì›ë³¸ ë‹µë³€ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬**í•˜ì—¬ adopted_info/rejected_info ì‘ì„±
5. **ê° AIë§ˆë‹¤ ë°˜ë“œì‹œ adopted_info ë˜ëŠ” rejected_info ì¤‘ í•˜ë‚˜ì—ëŠ” ë‚´ìš© í¬í•¨** (ë‘˜ ë‹¤ ë¹ˆ ë°°ì—´ ê¸ˆì§€)

**adopted_info/rejected_info ì‘ì„±:**
- adopted_info: ìœ ìš©í•œ ì›ë³¸ ë¬¸ì¥ ê·¸ëŒ€ë¡œ ë³µì‚¬
- rejected_info: Wikipedia ë¶ˆì¼ì¹˜ ë˜ëŠ” ìƒì¶© ì •ë³´ë§Œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³µì‚¬
- **ìƒí˜¸ ë°°íƒ€ì ** - ê°™ì€ ë¬¸ì¥ì´ ì–‘ìª½ì— ë™ì‹œ ì¡´ì¬ ê¸ˆì§€

**ë§ˆí¬ë‹¤ìš´ í¬ë§·:**
- ë¦¬ìŠ¤íŠ¸: `- í•­ëª©`
- ì œëª©: `## ì£¼ì œ`
- ê°•ì¡°: `**êµµê²Œ**`

JSON ì‘ë‹µ:ë°ã…•ã…“ã„´íˆ ã„´
{{
  "optimal_answer": "ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìµœì  ë‹µë³€",
  "verification_results": {{
    {verification_json_format}
  }},
  "confidence_score": "0-100",
  "contradictions_detected": ["ìƒí˜¸ëª¨ìˆœ ì‚¬í•­"],
  "fact_verification": {{"dates": [], "locations": [], "facts": []}},
  "analysis_rationale": "ì–´ë–¤ AIì˜ ì–´ë–¤ ì •ë³´ë¥¼ ì±„íƒ/ì œì™¸í–ˆëŠ”ì§€ ìƒì„¸íˆ ì„¤ëª…"
}}
"""
        else:
            # ì¼ë°˜/ì‚¬ì‹¤ ì§ˆë¬¸ (factual, general, document, image, creative ë“±)
            judge_prompt = f"""
ì§ˆë¬¸: {user_question}

**ğŸ” ì‚¬ì‹¤ í™•ì¸ ì§ˆë¬¸ - Wikipedia ê²€ì¦ ê¸°ì¤€ ì‚¬ìš©**
- Wikipediaì™€ **ëª…í™•íˆ ëª¨ìˆœ**ë˜ëŠ” ì •ë³´ë§Œ ì œì™¸
- Wikipediaì— ì—†ì§€ë§Œ **ëª¨ìˆœë˜ì§€ ì•ŠëŠ”** ìœ ìš©í•œ ì •ë³´ëŠ” í¬í•¨ (í•™ê³¼, íŠ¹ì§•, ì—­ì‚¬ ë“±)
- ì—¬ëŸ¬ AI ë‹µë³€ ì¢…í•©í•˜ì—¬ **í’ë¶€í•œ ìµœì  ë‹µë³€** ìƒì„±

**ì œê³µëœ AI ë‹µë³€ë“¤:**
{model_responses_text}
{web_verification_text}
{contradiction_warning}

**í•µì‹¬ ê·œì¹™:**
1. **ì›ë³¸ ë¬¸ì¥ë§Œ ì‚¬ìš©** - ìƒˆë¡œìš´ ë¬¸ì¥ ì‘ì„±/ìš”ì•½/ì¬êµ¬ì„± ê¸ˆì§€
2. **ì—¬ëŸ¬ AI ë‹µë³€ ì¡°í•©** - ë‹¨ì¼ ëª¨ë¸ ì„ íƒ ê¸ˆì§€
3. **í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€** - LLMì´ ì–¸ê¸‰í•˜ì§€ ì•Šì€ ë‚´ìš© í¬í•¨ ê¸ˆì§€

**ì •ë³´ ì±„íƒ ê¸°ì¤€:**
- âœ… **adopted_info**: Wikipedia ì¼ì¹˜ ì •ë³´ + ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ìœ ìš©í•œ ì •ë³´
- âŒ **rejected_info**: Wikipedia ëª…í™•íˆ ëª¨ìˆœë˜ëŠ” ì •ë³´ë§Œ
- **ê° AIë§ˆë‹¤ ë°˜ë“œì‹œ adopted_info ë˜ëŠ” rejected_info ì¤‘ í•˜ë‚˜ì—ëŠ” ë‚´ìš© í¬í•¨** (ë‘˜ ë‹¤ ë¹ˆ ë°°ì—´ ê¸ˆì§€)
- **ìƒí˜¸ ë°°íƒ€ì ** - ê°™ì€ ë¬¸ì¥ì´ ì–‘ìª½ì— ë™ì‹œ ì¡´ì¬ ê¸ˆì§€

**ë§ˆí¬ë‹¤ìš´ í¬ë§·:**
- ì œëª©: `## ì£¼ì œ`, `### ì†Œì£¼ì œ`
- ë¦¬ìŠ¤íŠ¸: `- í•­ëª©`
- ê°•ì¡°: `**êµµê²Œ**`
- ë¬¸ë‹¨: 2-3ë¬¸ì¥, ë¹ˆ ì¤„ë¡œ êµ¬ë¶„

JSON ì‘ë‹µ:
{{
  "optimal_answer": "ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìµœì  ë‹µë³€",
  "verification_results": {{
    {verification_json_format}
  }},
  "confidence_score": "0-100",
  "contradictions_detected": ["ìƒí˜¸ëª¨ìˆœ ì‚¬í•­"],
  "fact_verification": {{"dates": [], "locations": [], "facts": []}},
  "analysis_rationale": "ì–´ë–¤ AIì˜ ì–´ë–¤ ì •ë³´ë¥¼ ì±„íƒ/ì œì™¸í–ˆëŠ”ì§€, Wikipedia ê²€ì¦ ê²°ê³¼ ë°˜ì˜ ë°©ë²• ìƒì„¸ ì„¤ëª…"
}}

"""

        # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì²´í¬
        prompt_length = len(judge_prompt)
        print(f"ğŸ“ ì‹¬íŒ ëª¨ë¸ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {prompt_length}ì ({prompt_length // 1000}Kì)")
        
        # í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½ (ê° LLM ì‘ë‹µì„ ìš”ì•½)
        if prompt_length > 50000:  # 50Kì ì´ìƒì´ë©´
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({prompt_length}ì). LLM ì‘ë‹µì„ ìš”ì•½í•©ë‹ˆë‹¤...")
            # ê° LLM ì‘ë‹µì„ ìš”ì•½ (ì²˜ìŒ 4000ì + ë 500ìë§Œ ìœ ì§€)
            summarized_responses = {}
            for model_name, response in llm_responses.items():
                if len(response) > 5000:
                    summarized_responses[model_name] = response[:4000] + "\n\n... (ì¤‘ëµ) ...\n\n" + response[-500:]
                    print(f"  - {model_name}: {len(response)}ì â†’ {len(summarized_responses[model_name])}ìë¡œ ìš”ì•½")
                else:
                    summarized_responses[model_name] = response
            
            llm_responses = summarized_responses
            
            # í”„ë¡¬í”„íŠ¸ ì¬êµ¬ì„±
            model_sections = []
            for model_name, response in llm_responses.items():
                model_sections.append(f"[{model_name} ë‹µë³€]\n{response}")
            model_responses_text = "\n\n".join(model_sections)
            
            # í”„ë¡¬í”„íŠ¸ ì „ì²´ ì¬êµ¬ì„± (model_responses_text ë¶€ë¶„ë§Œ êµì²´)
            judge_prompt = judge_prompt.replace(
                judge_prompt.split(model_responses_text)[0] + model_responses_text,
                judge_prompt.split(model_responses_text)[0] + model_responses_text
            )
            # ì‹¤ì œë¡œëŠ” ìœ„ ë°©ì‹ì´ ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•˜ê²Œ ì¬êµ¬ì„±
            judge_prompt = f"""
ì§ˆë¬¸: {user_question}
{question_type_instruction}

{model_responses_text}
{web_verification_text}
{contradiction_warning}

**ğŸš¨ ì ˆëŒ€ ì¤€ìˆ˜ ì‚¬í•­ (ë§¤ìš° ì¤‘ìš”!):**
1. **ë°˜ë“œì‹œ ìœ„ì— ì œê³µëœ LLM ë‹µë³€ë“¤ì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”**
2. **ì ˆëŒ€ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”**
3. **LLMì´ ì–¸ê¸‰í•˜ì§€ ì•Šì€ ë§›ì§‘, ì¹´í˜, ì¥ì†Œ, ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”**
4. **í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€!** - ìœ„ ë‹µë³€ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„± ê¸ˆì§€
5. **ìœ„ì— ì œê³µëœ LLM ë‹µë³€ì˜ ê°œìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”** - 1ê°œë§Œ ìˆìœ¼ë©´ "ë‹¤ë¥¸ AI"ë¼ëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
6. **ìµœì  ë‹µë³€ì˜ ëª¨ë“  ë¬¸ì¥ì€ ìœ„ LLM ë‹µë³€ì—ì„œ ì§ì ‘ ì¶”ì¶œí•œ ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤**

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "optimal_answer": "ê²€ì¦ëœ ì •í™•í•œ ì •ë³´ë§Œìœ¼ë¡œ ì‘ì„±í•œ ìµœì ì˜ ë‹µë³€",
  "verification_results": {{
    {verification_json_format}
  }},
  "confidence_score": "ì „ì²´ ì‘ë‹µì— ëŒ€í•œ ì‹ ë¢°ë„ (0-100)",
  "contradictions_detected": ["ë°œê²¬ëœ ìƒí˜¸ëª¨ìˆœ ì‚¬í•­ë“¤"],
  "fact_verification": {{
    "dates": ["ê²€ì¦ëœ ì—°ë„ ì •ë³´ë“¤"],
    "locations": ["ê²€ì¦ëœ ìœ„ì¹˜ ì •ë³´ë“¤"],
    "facts": ["ê²€ì¦ëœ ê¸°íƒ€ ì‚¬ì‹¤ë“¤"]
  }},
  "analysis_rationale": "ìµœì  ë‹µë³€ ìƒì„± ê·¼ê±° - ê° AIì˜ ë‹µë³€ì—ì„œ ì–´ë–¤ ì •ë³´ë¥¼ ì±„íƒí–ˆëŠ”ì§€, ì–´ë–¤ ì •ë³´ê°€ í‹€ë ¸ê±°ë‚˜ ìƒë°˜ë˜ì–´ì„œ ì œì™¸í–ˆëŠ”ì§€, Wikipedia ê²€ì¦ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ ë°˜ì˜í–ˆëŠ”ì§€ ìƒì„¸íˆ ì„¤ëª…"
}}
"""
            print(f"ğŸ“ ìš”ì•½ í›„ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(judge_prompt)}ì")
        
        # ì‹¬íŒ ëª¨ë¸ í˜¸ì¶œ
        print(f"ğŸ“ ì‹¬íŒ ëª¨ë¸({judge_model}) í˜¸ì¶œ ì‹œì‘... (í”„ë¡¬í”„íŠ¸: {len(judge_prompt)}ì)")
        try:
            judge_response = call_judge_model(judge_model, judge_prompt)
            print(f"âœ… ì‹¬íŒ ëª¨ë¸ ì‘ë‹µ ë°›ìŒ: {len(judge_response) if judge_response else 0}ì")
            if judge_response:
                print(f"ğŸ“„ ì‹¬íŒ ëª¨ë¸ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {judge_response[:300]}...")
            else:
                print(f"âŒ ì‹¬íŒ ëª¨ë¸ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            import traceback
            print(f"âŒ ì‹¬íŒ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            print(f"âŒ ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
            raise
        
        # ê²°ê³¼ íŒŒì‹±
        print(f"ğŸ“ ì‹¬íŒ ëª¨ë¸ ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
        print(f"ğŸ“„ ì‹¬íŒ ëª¨ë¸ ì „ì²´ ì‘ë‹µ (ì²˜ìŒ 2000ì): {judge_response[:2000]}...")
        print(f"ğŸ“„ ì‹¬íŒ ëª¨ë¸ ì „ì²´ ì‘ë‹µ (ë 500ì): ...{judge_response[-500:]}")
        parsed_result = parse_judge_response(judge_response, judge_model, llm_responses)
        print(f"âœ… íŒŒì‹± ì™„ë£Œ: {list(parsed_result.keys()) if isinstance(parsed_result, dict) else 'N/A'}")
        print(f"ğŸ“„ íŒŒì‹±ëœ ìµœì ì˜_ë‹µë³€: {parsed_result.get('ìµœì ì˜_ë‹µë³€', '')[:300]}...")
        
        # ì›¹ ê²€ì¦ ì •ë³´ ì¶”ê°€
        parsed_result["ì›¹_ê²€ì¦_ì‚¬ìš©"] = web_verification_used
        if verified_facts:
            parsed_result["ì›¹_ê²€ì¦_ê²°ê³¼"] = verified_facts
            parsed_result["ê²€ì¦_ì„±ëŠ¥"] = {
                "ìƒí˜¸ëª¨ìˆœ_ê°ì§€": len(conflicts),
                "ì›¹_ê²€ì¦_ì„±ê³µ": len(verified_facts),
                "ë¹„ìš©": "$0.003" if web_verification_used else "$0.000"
            }
        
        # Wikipedia ê²€ì¦ ì—°ë„ë¡œ í›„ì²˜ë¦¬ (ì˜ëª»ëœ ì—°ë„ ì œê±°)
        if web_verification_used and verified_facts:
            verified_year = None
            for fact_type, verification in verified_facts.items():
                if verification.get('verified') and verification.get('extracted_year'):
                    verified_year = verification['extracted_year']
                    break
            
            if verified_year and parsed_result.get("ìµœì ì˜_ë‹µë³€"):
                import re
                optimal_answer = parsed_result["ìµœì ì˜_ë‹µë³€"]
                
                # ìµœì  ë‹µë³€ì—ì„œ ë‹¤ë¥¸ ì—°ë„ë¥¼ ì°¾ìŒ
                years_in_answer = re.findall(r'(\d{4})ë…„', optimal_answer)
                wrong_years = [y for y in years_in_answer if y != verified_year and 1900 <= int(y) <= 2024]
                
                # ì˜ëª»ëœ ì—°ë„ê°€ ìˆìœ¼ë©´ ì œê±°
                if wrong_years:
                    print(f"âš ï¸ Wikipedia ê²€ì¦ ì—°ë„ {verified_year}ì™€ ë‹¤ë¥¸ ì—°ë„ ë°œê²¬: {wrong_years}")
                    for wrong_year in wrong_years:
                        # í•´ë‹¹ ì—°ë„ë¥¼ í¬í•¨í•œ ë¬¸ì¥ íŒ¨í„´ ì°¾ê¸°
                        patterns_to_remove = [
                            rf'{wrong_year}ë…„.*?ì„¤ë¦½.*?[.!ê°€-í£]',
                            rf'{wrong_year}ë…„.*?ê°œêµ.*?[.!ê°€-í£]',
                            rf'{wrong_year}ë…„.*?ì°½ë¦½.*?[.!ê°€-í£]',
                            rf'{wrong_year}ë…„ì—.*?[.!ê°€-í£]{0,50}',
                        ]
                        
                        for pattern in patterns_to_remove:
                            optimal_answer = re.sub(pattern, '', optimal_answer, flags=re.DOTALL)
                    
                    # ì •ë¦¬
                    optimal_answer = re.sub(r'\s+', ' ', optimal_answer).strip()
                    
                    # ìµœì¢… ë‹µë³€ì´ ë¹„ì—ˆìœ¼ë©´ ê²€ì¦ëœ ì—°ë„ë¡œ ì¬êµ¬ì„±
                    if not optimal_answer or len(optimal_answer) < 50:
                        # ì›ë˜ LLM ë‹µë³€ì—ì„œ ê²€ì¦ëœ ì—°ë„ë¥¼ í¬í•¨í•œ ë¬¸ì¥ ì°¾ê¸°
                        if llm_responses:
                            for model, response in llm_responses.items():
                                if verified_year in response:
                                    # ê²€ì¦ëœ ì—°ë„ê°€ í¬í•¨ëœ ë¬¸ì¥ ì¶”ì¶œ
                                    sentences = re.split(r'[.!]\s+', response)
                                    matching_sentences = [s for s in sentences if verified_year in s and 150 <= len(s) <= 400]
                                    if matching_sentences:
                                        optimal_answer = matching_sentences[0]
                                        break
                        
                        # ì—¬ì „íˆ ë¹„ì—ˆìœ¼ë©´ ìƒì„±
                        if not optimal_answer:
                            optimal_answer = f"Wikipedia ê²€ì¦ ê²°ê³¼ì— ë”°ë¥´ë©´ ì¶©ë¶ëŒ€í•™êµëŠ” {verified_year}ë…„ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤."
                    
                    parsed_result["ìµœì ì˜_ë‹µë³€"] = optimal_answer
                    print(f"âœ… Wikipedia í›„ì²˜ë¦¬ ì™„ë£Œ: {verified_year}ë…„ ìœ ì§€, {wrong_years}ë…„ ì œê±°")
        
        print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¦ ì™„ë£Œ: ì›¹ê²€ì¦={web_verification_used}, ìƒí˜¸ëª¨ìˆœ={len(conflicts)}")
        
        return parsed_result
        
    except Exception as e:
        print(f"âŒ ì‹¬íŒ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
        # í´ë°±: ê°€ì¥ ê¸´ ì‘ë‹µì„ ìµœì  ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©
        if llm_responses:
            longest_response = max(llm_responses.values(), key=len)
            return {
                "ìµœì ì˜_ë‹µë³€": longest_response,
                "llm_ê²€ì¦_ê²°ê³¼": {
                    model: {
                        "ì •í™•ì„±": "âŒ",
                        "ì˜¤ë¥˜": "ê²€ì¦ ì‹¤íŒ¨ - Judge ëª¨ë¸ ì˜¤ë¥˜",
                        "ì‹ ë¢°ë„": "0",
                        "ì±„íƒëœ_ì •ë³´": [],
                        "ì œì™¸ëœ_ì •ë³´": []
                    }
                    for model in llm_responses.keys()
                },
                "ì‹¬íŒëª¨ë¸": judge_model,
                "ìƒíƒœ": "ê²€ì¦ ì‹¤íŒ¨"
            }
        return {
            "ìµœì ì˜_ë‹µë³€": "ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "llm_ê²€ì¦_ê²°ê³¼": {},
            "ì‹¬íŒëª¨ë¸": judge_model,
            "ìƒíƒœ": "ì˜¤ë¥˜"
        }

def call_judge_model(model_name, prompt):
    """ì‹¬íŒ ëª¨ë¸ í˜¸ì¶œ"""
    try:
        if model_name in ['GPT-5', 'GPT-3.5-turbo', 'GPT-4', 'GPT-4o', 'GPT-4o-mini']:
            # OpenAI ëª¨ë¸ ì‚¬ìš©
            import openai
            openai_api_key = os.getenv('OPENAI_API_KEY')
            if not openai_api_key:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
            client = openai.OpenAI(api_key=openai_api_key)
            
            # ëª¨ë¸ëª…ì„ OpenAI API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            openai_model_name = model_name.lower().replace('-', '-')
            if model_name == 'GPT-5':
                # GPT-5ëŠ” ì‹¤ì œë¡œ o1, o3 ë“±ì˜ ìµœì‹  ëª¨ë¸ì¼ ìˆ˜ ìˆìŒ
                # ì‚¬ìš©ìê°€ ì§€ì •í•œ ëª¨ë¸ëª…ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (o1, o3 ë“±)
                openai_model_name = 'gpt-5'  # ì‹¤ì œ ëª¨ë¸ëª… ì‚¬ìš© ì‹œë„
                print(f"ğŸ” GPT-5 ëª¨ë¸ëª…: {openai_model_name} (API í˜¸ì¶œ ì‹œë„)")
            elif model_name == 'GPT-4':
                openai_model_name = 'gpt-4'
            elif model_name == 'GPT-4o':
                openai_model_name = 'gpt-4o'
            elif model_name == 'GPT-4o-mini':
                openai_model_name = 'gpt-4o-mini'
            elif model_name == 'GPT-3.5-turbo':
                openai_model_name = 'gpt-3.5-turbo'
            
            # ìµœì‹  OpenAI ëª¨ë¸(o1, o3 ë“±)ì€ max_completion_tokens ì‚¬ìš© ë° temperature ë¯¸ì§€ì›
            # ê¸°ì¡´ ëª¨ë¸ì€ max_tokens ì‚¬ìš©
            is_latest_model = any(model in openai_model_name.lower() for model in ['o1', 'o3', 'gpt-5'])
            
            api_params = {
                "model": openai_model_name,
                "messages": [
                    {"role": "system", "content": """ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì—­í• ì€ ê° AIì˜ ë‹µë³€ì„ **ìˆëŠ” ê·¸ëŒ€ë¡œ ë¶„ì„**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸš¨ ì ˆëŒ€ ê·œì¹™:
1. ê° AIê°€ **ì‹¤ì œë¡œ ë§í•œ ë‚´ìš©ë§Œ** adopted_info/rejected_infoì— ë³µì‚¬
2. ê° AIì˜ ë‹µë³€ì€ **ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤** - ëª¨ë“  AIê°€ ë˜‘ê°™ì€ ë¬¸ì¥ì„ ë§í•  í•„ìš”ëŠ” ì—†ìŒ
3. AIê°€ íŠ¹ì • ì •ë³´(ì—°ë„, ìœ„ì¹˜, ì´ë¦„ ë“±)ë¥¼ ë§í–ˆë‹¤ë©´ â†’ ê·¸ëŒ€ë¡œ ë³µì‚¬ (ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”!)
4. ì ˆëŒ€ ìƒˆë¡œìš´ ë¬¸ì¥ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
5. ê° AIê°€ ì‹¤ì œë¡œ ë§í•˜ì§€ ì•Šì€ ë‚´ìš©ì„ ë§Œë“¤ì–´ë‚´ë©´ ì•ˆë¨ (í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€!)
6. **íŠ¹íˆ ì£¼ì˜**: AIê°€ "1946ë…„"ì´ë¼ê³  ë§í–ˆë‹¤ë©´, ì ˆëŒ€ "1951ë…„"ìœ¼ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”!
7. adopted_info/rejected_infoì—ëŠ” ê° AIì˜ ì›ë³¸ ë‹µë³€ì—ì„œ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì•¼ í•©ë‹ˆë‹¤

âœ… ì˜¬ë°”ë¥¸ ë¶„ì„:
- ê° AIì˜ ì›ë³¸ ë‹µë³€ì—ì„œ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì—¬ adopted_info/rejected_infoì— í¬í•¨
- ê° AIë§ˆë‹¤ ë‹¤ë¥¸ ë‚´ìš©ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŒ (ì´ê²ƒì´ ì •ìƒ)
- Wikipedia ê²€ì¦ ê²°ê³¼ê°€ ìˆë‹¤ë©´, ê° AIì˜ ì›ë³¸ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ì¼ì¹˜/ë¶ˆì¼ì¹˜ íŒë‹¨

âŒ ì˜ëª»ëœ ë¶„ì„ (í• ë£¨ì‹œë„¤ì´ì…˜):
- ëª¨ë“  AIê°€ ë˜‘ê°™ì€ ë¬¸ì¥ì„ ê°€ì§„ adopted_info (ì´ëŠ” ë¶ˆê°€ëŠ¥í•¨)
- ì›ë³¸ ë‹µë³€ì— ì—†ëŠ” ì •ë³´ë¥¼ ìƒˆë¡œ ë§Œë“¤ì–´ë‚´ê¸° (ì˜ˆ: AIê°€ 1946ë…„ì´ë¼ê³  í–ˆëŠ”ë° 1951ë…„ìœ¼ë¡œ ë°”ê¾¸ê¸°)
- ìµœì  ë‹µë³€ì˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ê° AIì˜ ë‹µë³€ì„ ë°”ê¾¸ê¸°

**ë‹¹ì‹ ì€ ê° AIì˜ ì›ë³¸ ë‹µë³€ì„ ì½ê³ , ê° AIê°€ ë­ë¼ê³  í–ˆëŠ”ì§€ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”.**

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""},
                    {"role": "user", "content": prompt}
                ],
            }
            
            # ìµœì‹  ëª¨ë¸ì€ temperatureë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
            if not is_latest_model:
                api_params["temperature"] = 0.0  # ë” ì¼ê´€ëœ ì¶œë ¥ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
            
            # ìµœì‹  ëª¨ë¸ì€ max_completion_tokens, ê¸°ì¡´ ëª¨ë¸ì€ max_tokens ì‚¬ìš©
            if is_latest_model:
                # GPT-5 ë“± ìµœì‹  ëª¨ë¸ì€ ë” í° í† í° ì œí•œ ì„¤ì • (ìµœëŒ€ 16384)
                api_params["max_completion_tokens"] = 16384
            else:
                api_params["max_tokens"] = 16384
                api_params["response_format"] = {"type": "json_object"}  # JSON í˜•ì‹ ê°•ì œ
            
            response = client.chat.completions.create(**api_params)
            
            response_content = response.choices[0].message.content.strip()
            
            # ì‘ë‹µì´ ì˜ë ¸ëŠ”ì§€ í™•ì¸
            if response.choices[0].finish_reason == 'length':
                print(f"âš ï¸ {model_name} ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤ (finish_reason: length)")
                response_content += "\n\n[ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì¸í•´ ì˜ë ¸ìŠµë‹ˆë‹¤. ë” ê¸´ ë‹µë³€ì´ í•„ìš”í•˜ì‹œë©´ ì§ˆë¬¸ì„ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”.]"
            elif response.choices[0].finish_reason:
                print(f"ğŸ“ {model_name} ì‘ë‹µ ì™„ë£Œ (finish_reason: {response.choices[0].finish_reason})")
            
            print(f"ğŸ“ {model_name} ì‘ë‹µ ê¸¸ì´: {len(response_content)}ì")
            
            return response_content
            
        elif model_name == 'Claude-3.5-haiku':
            # Claude ëª¨ë¸ ì‚¬ìš© (ëŒ€ì•ˆ)
            import anthropic
            anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
            if not anthropic_api_key:
                raise ValueError("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
            client = anthropic.Anthropic(api_key=anthropic_api_key)
            response = client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=1500,
                temperature=0.1,
                messages=[{"role": "user", "content": prompt}]
            )
            
            return response.content[0].text
            
        elif model_name == 'LLaMA 3.1 8B':
            # LLaMA ëª¨ë¸ ì‚¬ìš© (Groq API)
            import groq
            groq_api_key = os.getenv('GROQ_API_KEY')
            if not groq_api_key:
                raise ValueError("Groq API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
            client = groq.Groq(api_key=groq_api_key)
            response = client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ì‹¤ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•œ ì •ë³´ë§Œ ì œê³µí•˜ê³  í‹€ë¦° ì •ë³´ë¥¼ ëª…í™•íˆ ì§€ì í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.1
            )
            
            return response.choices[0].message.content.strip()
            
        else:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ GPT-5 ì‚¬ìš©
            return call_judge_model('GPT-5', prompt)
            
    except Exception as e:
        print(f"âŒ ì‹¬íŒ ëª¨ë¸ {model_name} í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
        # í´ë°±: ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„ (GPT-5 -> GPT-4o -> GPT-4o-mini -> GPT-3.5-turbo)
        fallback_models = {
            'GPT-5': 'GPT-4o',
            'GPT-4o': 'GPT-4o-mini',
            'GPT-4o-mini': 'GPT-3.5-turbo',
            'GPT-3.5-turbo': None
        }
        
        fallback_model = fallback_models.get(model_name)
        if fallback_model:
            print(f"ğŸ”„ {model_name} ì‹¤íŒ¨, {fallback_model}ë¡œ í´ë°± ì‹œë„...")
            try:
                return call_judge_model(fallback_model, prompt)
            except Exception as fallback_error:
                print(f"âŒ í´ë°± ëª¨ë¸ {fallback_model}ë„ ì‹¤íŒ¨: {fallback_error}")
                raise e
        else:
            raise e

def parse_judge_response(judge_response, judge_model, llm_responses=None):
    """ì‹¬íŒ ëª¨ë¸ JSON ì‘ë‹µ íŒŒì‹±"""
    try:
        import json
        import re
        
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_match = re.search(r'\{.*\}', judge_response, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            print(f"ğŸ“‹ ì¶”ì¶œëœ JSON ë¬¸ìì—´ (ì²˜ìŒ 500ì): {json_str[:500]}...")
            print(f"ğŸ“‹ ì¶”ì¶œëœ JSON ë¬¸ìì—´ (ë 500ì): ...{json_str[-500:]}")
            try:
                parsed_data = json.loads(json_str)
                print(f"âœ… JSON íŒŒì‹± ì„±ê³µ!")
            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                print(f"âŒ JSON ë¬¸ìì—´ ìœ„ì¹˜: {e.pos}")
                print(f"âŒ JSON ë¬¸ìì—´ (ì˜¤ë¥˜ ìœ„ì¹˜ ì£¼ë³€): {json_str[max(0, e.pos-100):e.pos+100]}")
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±
                return create_fallback_result(judge_model, llm_responses)
            
            result = {
                "ìµœì ì˜_ë‹µë³€": parsed_data.get("optimal_answer", ""),
                "llm_ê²€ì¦_ê²°ê³¼": {},
                "ì‹¬íŒëª¨ë¸": judge_model,
                "ìƒíƒœ": "ì„±ê³µ",
                "ì‹ ë¢°ë„": parsed_data.get("confidence_score", "50"),
                "ìƒí˜¸ëª¨ìˆœ": parsed_data.get("contradictions_detected", []),
                "ì‚¬ì‹¤ê²€ì¦": parsed_data.get("fact_verification", {}),
                "ë¶„ì„_ê·¼ê±°": parsed_data.get("analysis_rationale", "")
            }
            
            # ê²€ì¦ ê²°ê³¼ íŒŒì‹± (ìƒí˜¸ëª¨ìˆœ ìš°ì„  ì²˜ë¦¬)
            verification_results = parsed_data.get("verification_results", {})
            contradictions = parsed_data.get("contradictions_detected", [])
            
            for model_name, verification in verification_results.items():
                errors_text = verification.get("errors", "ì˜¤ë¥˜ ì—†ìŒ")
                
                # ìƒí˜¸ëª¨ìˆœì´ ê°ì§€ëœ ê²½ìš° ê°•ì œë¡œ ì˜¤ë¥˜ ì²˜ë¦¬
                has_contradiction = any(
                    model_name.lower() in str(contradiction).lower() or 
                    "ìƒì¶©" in errors_text or 
                    "ë¶ˆí™•ì‹¤" in errors_text or
                    "ë‹¤ë¥¸ AI" in errors_text
                    for contradiction in contradictions
                )
                
                # ê¸°ë³¸ ì •í™•ì„± íŒë‹¨
                is_accurate_by_default = (
                    verification.get("accuracy") == "ì •í™•" or
                    errors_text.lower() in ["ì—†ìŒ", "ì˜¤ë¥˜ ì—†ìŒ", "ì •í™•í•œ ì •ë³´ ì œê³µ", "ì •í™•í•œ ì •ë³´"] or
                    "ì •í™•í•œ ì •ë³´" in errors_text
                )
                
                # ìƒí˜¸ëª¨ìˆœì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
                is_accurate = is_accurate_by_default and not has_contradiction
                
                # adopted_infoì™€ rejected_info ì¶”ì¶œ
                adopted_info = verification.get("adopted_info", [])
                rejected_info = verification.get("rejected_info", [])
                
                # adopted_infoê°€ ë¹„ì–´ìˆê³  rejected_infoë„ ë¹„ì–´ìˆìœ¼ë©´, ì›ë³¸ LLM ì‘ë‹µì—ì„œ ì¶”ì¶œ
                if (not adopted_info or len(adopted_info) == 0) and (not rejected_info or len(rejected_info) == 0):
                    print(f"âš ï¸ {model_name}: adopted_infoì™€ rejected_infoê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ. ì›ë³¸ ì‘ë‹µì—ì„œ ì¶”ì¶œ ì‹œë„...")
                    if llm_responses and model_name in llm_responses:
                        original_response = llm_responses[model_name]
                        # ì›ë³¸ ì‘ë‹µì´ ìˆìœ¼ë©´ adopted_infoì— í¬í•¨ (ì¼ë‹¨ ì±„íƒ)
                        if original_response and len(original_response.strip()) > 0:
                            # ì‘ë‹µì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ìµœëŒ€ 3ê°œ ë¬¸ì¥)
                            import re
                            sentences = re.split(r'[.!?]\s+', original_response.strip())
                            adopted_info = [s.strip() + '.' for s in sentences[:3] if len(s.strip()) > 10]
                            print(f"âœ… {model_name}: ì›ë³¸ ì‘ë‹µì—ì„œ {len(adopted_info)}ê°œ ë¬¸ì¥ ì¶”ì¶œ")
                
                # rejected_infoì—ì„œ "(Wikipedia ...ê³¼ ë¶ˆì¼ì¹˜)" í…ìŠ¤íŠ¸ ì œê±°
                cleaned_rejected_info = []
                for item in rejected_info:
                    # "(Wikipedia ...ê³¼ ë¶ˆì¼ì¹˜)" íŒ¨í„´ ì œê±°
                    import re
                    cleaned_item = re.sub(r'\s*\(Wikipedia[^)]*ë¶ˆì¼ì¹˜[^)]*\)', '', str(item))
                    cleaned_item = re.sub(r'\s*\(Wikipedia.*?\)', '', cleaned_item)  # ê¸°íƒ€ Wikipedia ê´„í˜¸ ì œê±°
                    cleaned_item = cleaned_item.strip()
                    if cleaned_item:
                        cleaned_rejected_info.append(cleaned_item)
                
                # adopted_infoë„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”
                cleaned_adopted_info = []
                for item in adopted_info:
                    if isinstance(item, str) and item.strip():
                        cleaned_adopted_info.append(item.strip())
                
                print(f"ğŸ“Š {model_name}: adopted_info={len(cleaned_adopted_info)}ê°œ, rejected_info={len(cleaned_rejected_info)}ê°œ")
                
                result["llm_ê²€ì¦_ê²°ê³¼"][model_name] = {
                    "ì •í™•ì„±": "âœ…" if is_accurate else "âŒ",
                    "ì˜¤ë¥˜": errors_text if not is_accurate else "ì •í™•í•œ ì •ë³´ ì œê³µ",
                    "ì‹ ë¢°ë„": verification.get("confidence", "50"),
                    "ì±„íƒëœ_ì •ë³´": cleaned_adopted_info,
                    "ì œì™¸ëœ_ì •ë³´": cleaned_rejected_info
                }
            
            return result
        else:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±
            return create_fallback_result(judge_model, llm_responses)
            
    except Exception as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return create_fallback_result(judge_model, llm_responses)

def create_fallback_result(judge_model, llm_responses=None):
    """í´ë°± ê²°ê³¼ ìƒì„±"""
    if llm_responses:
        actual_models = list(llm_responses.keys())
    else:
        actual_models = ["GPT-4-Turbo", "GPT-4o", "GPT-3.5-Turbo", "GPT-4o-mini", 
                        "Gemini-Pro-1.5", "Gemini-Pro-1.0",
                        "Claude-3-Opus", "Claude-3-Sonnet", "Claude-3-Haiku",
                        "Clova-HCX-003", "Clova-HCX-DASH-001"]
    
    result = {
        "ìµœì ì˜_ë‹µë³€": "ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "llm_ê²€ì¦_ê²°ê³¼": {},
        "ì‹¬íŒëª¨ë¸": judge_model,
        "ìƒíƒœ": "íŒŒì‹± ì‹¤íŒ¨",
        "ì‹ ë¢°ë„": "0",
        "ìƒí˜¸ëª¨ìˆœ": [],
        "ì‚¬ì‹¤ê²€ì¦": {}
    }
    
    for model in actual_models:
        # ì›ë³¸ LLM ì‘ë‹µì—ì„œ ì§ì ‘ ì¶”ì¶œ
        adopted_info = []
        if llm_responses and model in llm_responses:
            original_response = llm_responses[model]
            if original_response and len(original_response.strip()) > 0:
                # ì‘ë‹µì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ìµœëŒ€ 3ê°œ ë¬¸ì¥)
                import re
                sentences = re.split(r'[.!?]\s+', original_response.strip())
                adopted_info = [s.strip() + '.' for s in sentences[:3] if len(s.strip()) > 10]
        
        result["llm_ê²€ì¦_ê²°ê³¼"][model] = {
            "ì •í™•ì„±": "âŒ", 
            "ì˜¤ë¥˜": "ê²€ì¦ ì‹¤íŒ¨ - Judge ëª¨ë¸ ì˜¤ë¥˜", 
            "ì‹ ë¢°ë„": "0",
            "ì±„íƒëœ_ì •ë³´": adopted_info,
            "ì œì™¸ëœ_ì •ë³´": []
        }
    
    return result

def format_optimal_response(final_result):
    """ìµœì  ë‹µë³€ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
    try:
        print(f"ğŸ” format_optimal_response ì‹œì‘...")
        print(f"ğŸ” final_result íƒ€ì…: {type(final_result)}")
        print(f"ğŸ” final_result í‚¤: {list(final_result.keys()) if isinstance(final_result, dict) else 'N/A'}")
        
        optimal_answer = final_result.get("ìµœì ì˜_ë‹µë³€", "")
        print(f"ğŸ” optimal_answer ê¸¸ì´: {len(optimal_answer) if optimal_answer else 0}ì")
        print(f"ğŸ” optimal_answer ë‚´ìš©: {optimal_answer[:200] if optimal_answer else 'None'}...")
        
        verification_results = final_result.get("llm_ê²€ì¦_ê²°ê³¼", {})
        print(f"ğŸ” verification_results í‚¤ ê°œìˆ˜: {len(verification_results)}ê°œ")
        print(f"ğŸ” verification_results ëª¨ë¸: {list(verification_results.keys())}")
        
        judge_model = final_result.get("ì‹¬íŒëª¨ë¸", "GPT-5")
        status = final_result.get("ìƒíƒœ", "ì„±ê³µ")
        
        # ìƒˆë¡œìš´ JSON í˜•ì‹ ì§€ì›
        confidence = final_result.get("ì‹ ë¢°ë„", "50")
        contradictions = final_result.get("ìƒí˜¸ëª¨ìˆœ", [])
        
        # ë¶„ì„ ê·¼ê±° ì¶”ì¶œ
        analysis_rationale = final_result.get("ë¶„ì„_ê·¼ê±°", "")
        print(f"ğŸ” analysis_rationale ê¸¸ì´: {len(analysis_rationale) if analysis_rationale else 0}ì")
        
        # ìµœì  ë‹µë³€ì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²´í¬
        if not optimal_answer or len(optimal_answer.strip()) == 0:
            print(f"âš ï¸ ìµœì  ë‹µë³€ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! í´ë°± ë©”ì‹œì§€ ìƒì„±...")
            optimal_answer = "ìµœì  ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê° AI ëª¨ë¸ì˜ ê°œë³„ ì‘ë‹µì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        # ë©”ì¸ ë‹µë³€ êµ¬ì„±
        formatted_response = f"""**ìµœì ì˜ ë‹µë³€:**

{optimal_answer}

*({judge_model} ê²€ì¦ ì™„ë£Œ - ì‹ ë¢°ë„: {confidence}%)*
"""
        
        # ë¶„ì„ ê·¼ê±° ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if analysis_rationale:
            formatted_response += f"""
**ğŸ“Š ë‹µë³€ ìƒì„± ê·¼ê±°:**

{analysis_rationale}
"""
        
        formatted_response += """
**ê° LLM ê²€ì¦ ê²°ê³¼:**
"""
        
        # ê° LLM ê²€ì¦ ê²°ê³¼ ì¶”ê°€ (ì‹¤ì œ ì‘ë‹µí•œ ëª¨ë¸ë“¤ë§Œ)
        model_names = {
            # GPT ëª¨ë¸ë“¤ (ìµœì‹  ì¶”ê°€)
            "GPT-5": "GPT-5",
            "GPT-5-Mini": "GPT-5 Mini",
            "GPT-4.1": "GPT-4.1",
            "GPT-4.1-Mini": "GPT-4.1 Mini",
            "GPT-4o": "GPT-4o",
            "GPT-4o-Mini": "GPT-4o Mini",
            "GPT-4-Turbo": "GPT-4 Turbo",
            "GPT-3.5-Turbo": "GPT-3.5 Turbo",
            
            # Gemini ëª¨ë¸ë“¤ (ìµœì‹  ì¶”ê°€)
            "Gemini-2.5-Pro": "Gemini 2.5 Pro",
            "Gemini-2.5-Flash": "Gemini 2.5 Flash",
            "Gemini-2.0-Flash-Exp": "Gemini 2.0 Flash Exp",
            "Gemini-2.0-Flash-Lite": "Gemini 2.0 Flash Lite",
            
            # Claude ëª¨ë¸ë“¤ (ìµœì‹  ì¶”ê°€)
            "Claude-4-Opus": "Claude 4 Opus",
            "Claude-3.7-Sonnet": "Claude 3.7 Sonnet",
            "Claude-3.5-Sonnet": "Claude 3.5 Sonnet",
            "Claude-3.5-Haiku": "Claude 3.5 Haiku",
            "Claude-3-Opus": "Claude 3 Opus",
            
            # HyperCLOVA X ëª¨ë¸ë“¤
            "HCX-003": "HyperCLOVA X HCX-003",
            "HCX-DASH-001": "HyperCLOVA X HCX-DASH-001",
        }
        
        for model_key, model_display_name in model_names.items():
            if model_key in verification_results:
                verification = verification_results[model_key]
                accuracy = verification.get("ì •í™•ì„±", "âœ…")
                error = verification.get("ì˜¤ë¥˜", "ì˜¤ë¥˜ ì—†ìŒ")
                model_confidence = verification.get("ì‹ ë¢°ë„", "50")
                adopted = verification.get("ì±„íƒëœ_ì •ë³´", [])
                rejected = verification.get("ì œì™¸ëœ_ì •ë³´", [])
                
                formatted_response += f"""
**{model_display_name}:**
{accuracy} ì •í™•ì„±: {accuracy}
âŒ ì˜¤ë¥˜: {error}
ğŸ“Š ì‹ ë¢°ë„: {model_confidence}%
"""
                
                # ì±„íƒëœ ì •ë³´ ì¶”ê°€ (ê° í•­ëª©ì„ ê°œë³„ ë¼ì¸ìœ¼ë¡œ)
                if adopted and len(adopted) > 0:
                    for item in adopted:
                        formatted_response += f"âœ… ì±„íƒëœ ì •ë³´: {item}\n"
                
                # ì œì™¸ëœ ì •ë³´ ì¶”ê°€ (ê° í•­ëª©ì„ ê°œë³„ ë¼ì¸ìœ¼ë¡œ)
                if rejected and len(rejected) > 0:
                    for item in rejected:
                        formatted_response += f"âŒ ì œì™¸ëœ ì •ë³´: {item}\n"
        
        # ìƒí˜¸ëª¨ìˆœ ì •ë³´ ì¶”ê°€ (ê° AI ë¶„ì„ ì™¸ë¶€ì— í‘œì‹œ)
        if contradictions:
            contradiction_text = chr(10).join(f"- {contradiction}" for contradiction in contradictions)
            formatted_response += f"""

**âš ï¸ ë°œê²¬ëœ ìƒí˜¸ëª¨ìˆœ:**
{contradiction_text}
"""
        
        # ìƒíƒœ ì •ë³´ ì¶”ê°€
        if status != "ì„±ê³µ":
            formatted_response += f"\n*ìƒíƒœ: {status}*"
        
        return formatted_response
        
    except Exception as e:
        print(f"âŒ ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
        return f"""**ìµœì ì˜ ë‹µë³€:**

{final_result.get('ìµœì ì˜_ë‹µë³€', 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨')}

*í¬ë§·íŒ… ì˜¤ë¥˜ ë°œìƒ*
"""

def generate_unique_username(email, name=None):
    """ì´ë©”ì¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ ì‚¬ìš©ìëª… ìƒì„±"""
    base_username = email.split('@')[0]
    username = base_username
    counter = 1
    
    while User.objects.filter(username=username).exists():
        username = f"{base_username}_{counter}"
        counter += 1
    
    return username

@api_view(['GET'])
@authentication_classes([TokenAuthentication])
@permission_classes([AllowAny])
def google_callback(request):
    try:
        # ì•¡ì„¸ìŠ¤ í† í° ì¶”ì¶œ
        auth_header = request.headers.get('Authorization', '')
        if not auth_header.startswith('Bearer '):
            return Response(
                {'error': 'ì˜ëª»ëœ ì¸ì¦ í—¤ë”'}, 
                status=status.HTTP_401_UNAUTHORIZED
            )
        
        access_token = auth_header.split(' ')[1]

        # Google APIë¡œ ì‚¬ìš©ì ì •ë³´ ìš”ì²­
        user_info_response = requests.get(
            'https://www.googleapis.com/oauth2/v3/userinfo',
            headers={'Authorization': f'Bearer {access_token}'}
        )

        if user_info_response.status_code != 200:
            return Response(
                {'error': 'Googleì—ì„œ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )

        user_info = user_info_response.json()
        email = user_info.get('email')
        name = user_info.get('name')
        
        if not email:
            return Response(
                {'error': 'ì´ë©”ì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            # ê¸°ì¡´ ì‚¬ìš©ì ê²€ìƒ‰
            user = User.objects.get(email=email)
            # ê¸°ì¡´ ì‚¬ìš©ìì˜ ì´ë¦„ì´ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
            if name and (not user.first_name and not user.last_name):
                if ' ' in name:
                    first_name, last_name = name.split(' ', 1)
                    user.first_name = first_name
                    user.last_name = last_name
                else:
                    user.first_name = name
                user.save()
        except User.DoesNotExist:
            # ìƒˆë¡œìš´ ì‚¬ìš©ì ìƒì„±
            username = generate_unique_username(email, name)
            user = User.objects.create(
                username=username,
                email=email,
                is_active=True
            )
            
            # ì´ë¦„ ì„¤ì •
            if name:
                if ' ' in name:
                    first_name, last_name = name.split(' ', 1)
                    user.first_name = first_name
                    user.last_name = last_name
                else:
                    user.first_name = name
            
            # ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ì„ íƒì )
            random_password = uuid.uuid4().hex
            user.set_password(random_password)
            user.save()

        # ì†Œì…œ ê³„ì • ì •ë³´ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        social_account, created = SocialAccount.objects.get_or_create(
            email=email,
            provider='google',
            defaults={'user': user}
        )

        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()

        # ì‚¬ìš©ì ì •ë³´ ì§ë ¬í™”
        serializer = UserSerializer(user)
        
        return Response({
            'message': 'êµ¬ê¸€ ë¡œê·¸ì¸ ì„±ê³µ',
            'user': serializer.data
        })
        
    except Exception as e:
        return Response(
            {'error': str(e)}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


@api_view(['POST'])
@authentication_classes([TokenAuthentication])
@permission_classes([AllowAny])
def kakao_callback(request):
    """ì¹´ì¹´ì˜¤ ë¡œê·¸ì¸ ì½œë°±"""
    try:
        data = request.data
        access_token = data.get('access_token')
        
        if not access_token:
            return Response(
                {'error': 'ì•¡ì„¸ìŠ¤ í† í°ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        # ì¹´ì¹´ì˜¤ APIë¡œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        user_info_response = requests.get(
            'https://kapi.kakao.com/v2/user/me',
            headers={'Authorization': f'Bearer {access_token}'}
        )
        
        if user_info_response.status_code != 200:
            return Response(
                {'error': 'ì¹´ì¹´ì˜¤ì—ì„œ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        user_info = user_info_response.json()
        kakao_account = user_info.get('kakao_account', {})
        profile = kakao_account.get('profile', {})
        
        email = kakao_account.get('email')
        name = profile.get('nickname')
        
        if not email:
            return Response(
                {'error': 'ì´ë©”ì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            # ê¸°ì¡´ ì‚¬ìš©ì ê²€ìƒ‰
            user = User.objects.get(email=email)
            # ê¸°ì¡´ ì‚¬ìš©ìì˜ ì´ë¦„ì´ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
            if name and (not user.first_name and not user.last_name):
                user.first_name = name
                user.save()
        except User.DoesNotExist:
            # ìƒˆë¡œìš´ ì‚¬ìš©ì ìƒì„±
            username = generate_unique_username(email, name)
            user = User.objects.create(
                username=username,
                email=email,
                is_active=True
            )
            
            # ì´ë¦„ ì„¤ì •
            if name:
                user.first_name = name
            
            # ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ì„ íƒì )
            random_password = uuid.uuid4().hex
            user.set_password(random_password)
            user.save()
        
        # ì†Œì…œ ê³„ì • ì •ë³´ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        social_account, created = SocialAccount.objects.get_or_create(
            email=email,
            provider='kakao',
            defaults={'user': user}
        )
        
        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()
        
        serializer = UserSerializer(user)
        return Response({
            'message': 'ì¹´ì¹´ì˜¤ ë¡œê·¸ì¸ ì„±ê³µ',
            'user': serializer.data
        })
        
    except Exception as e:
        return Response(
            {'error': str(e)}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


@api_view(['POST'])
@authentication_classes([TokenAuthentication])
@permission_classes([AllowAny])
def naver_callback(request):
    """ë„¤ì´ë²„ ë¡œê·¸ì¸ ì½œë°±"""
    try:
        data = request.data
        access_token = data.get('access_token')
        
        if not access_token:
            return Response(
                {'error': 'ì•¡ì„¸ìŠ¤ í† í°ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        # ë„¤ì´ë²„ APIë¡œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        user_info_response = requests.get(
            'https://openapi.naver.com/v1/nid/me',
            headers={'Authorization': f'Bearer {access_token}'}
        )
        
        if user_info_response.status_code != 200:
            return Response(
                {'error': 'ë„¤ì´ë²„ì—ì„œ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        user_info = user_info_response.json()
        response_data = user_info.get('response', {})
        
        email = response_data.get('email')
        name = response_data.get('name')
        nickname = response_data.get('nickname')
        
        if not email:
            return Response(
                {'error': 'ì´ë©”ì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        # ì´ë¦„ì´ ì—†ìœ¼ë©´ ë‹‰ë„¤ì„ ì‚¬ìš©
        display_name = name or nickname
        
        try:
            # ê¸°ì¡´ ì‚¬ìš©ì ê²€ìƒ‰
            user = User.objects.get(email=email)
            # ê¸°ì¡´ ì‚¬ìš©ìì˜ ì´ë¦„ì´ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
            if display_name and (not user.first_name and not user.last_name):
                user.first_name = display_name
                user.save()
        except User.DoesNotExist:
            # ìƒˆë¡œìš´ ì‚¬ìš©ì ìƒì„±
            username = generate_unique_username(email, display_name)
            user = User.objects.create(
                username=username,
                email=email,
                is_active=True
            )
            
            # ì´ë¦„ ì„¤ì •
            if display_name:
                user.first_name = display_name
            
            # ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ì„ íƒì )
            random_password = uuid.uuid4().hex
            user.set_password(random_password)
            user.save()
        
        # ì†Œì…œ ê³„ì • ì •ë³´ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        social_account, created = SocialAccount.objects.get_or_create(
            email=email,
            provider='naver',
            defaults={'user': user}
        )
        
        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()
        
        serializer = UserSerializer(user)
        return Response({
            'message': 'ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ',
            'user': serializer.data
        })
        
    except Exception as e:
        return Response(
            {'error': str(e)}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

class VideoUploadView(APIView):
    """ì˜ìƒ ì—…ë¡œë“œ ë·° - ë…ë¦½ì ì¸ ì˜ìƒ ì²˜ë¦¬"""
    permission_classes = [AllowAny]  # ì„ì‹œë¡œ AllowAnyë¡œ ë³€ê²½
    parser_classes = (MultiPartParser, FormParser)
    
    def post(self, request):
        try:
            import os
            import uuid
            import time
            from django.core.files.storage import default_storage
            from django.conf import settings
            
            # ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸ (backend_videochat ë°©ì‹)
            if 'video' not in request.FILES:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video_file = request.FILES['video']
            
            # íŒŒì¼ í™•ì¥ì ê²€ì¦ (backend_videochat ë°©ì‹)
            if not video_file.name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
                return Response({
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. MP4, AVI, MOV, MKV, WEBM í˜•ì‹ë§Œ ì§€ì›ë©ë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŒŒì¼ í¬ê¸° ê²€ì¦ (50MB ì œí•œ)
            max_size = 50 * 1024 * 1024  # 50MB
            if video_file.size > max_size:
                return Response({
                    'error': f'íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 50MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í˜„ì¬: {video_file.size / (1024*1024):.1f}MB)'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŒŒì¼ëª… ê¸¸ì´ ê²€ì¦
            if len(video_file.name) > 200:
                return Response({
                    'error': 'íŒŒì¼ëª…ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 200ì ì´í•˜ë¡œ ì œí•œë©ë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„± (backend_videochat ë°©ì‹)
            timestamp = int(time.time())
            filename = f"upload_{timestamp}_{video_file.name}"
            
            # íŒŒì¼ ì €ì¥ (backend_videochat ë°©ì‹)
            from django.core.files.base import ContentFile
            file_path = default_storage.save(
                f'uploads/{filename}',
                ContentFile(video_file.read())
            )
            full_path = os.path.join(settings.MEDIA_ROOT, file_path)
            
            # íŒŒì¼ ì €ì¥ ê²€ì¦
            if not os.path.exists(full_path):
                return Response({
                    'error': 'íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # íŒŒì¼ í¬ê¸° ì¬ê²€ì¦ (ì‹¤ì œ ì €ì¥ëœ íŒŒì¼)
            actual_size = os.path.getsize(full_path)
            if actual_size == 0:
                return Response({
                    'error': 'ë¹ˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì˜ìƒ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # Create Video model instance (backend_videochat ë°©ì‹)
            video = Video.objects.create(
                filename=filename,
                original_name=video_file.name,
                file_path=file_path,
                file_size=video_file.size,
                file=file_path,  # file í•„ë“œë„ ì €ì¥
                analysis_status='pending'
            )
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜ìƒ ë¶„ì„ ì‹œì‘
            def analyze_video_background():
                try:
                    print(f"ğŸ¬ ë°±ê·¸ë¼ìš´ë“œ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video.id}")
                    
                    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì¬í™•ì¸
                    if not os.path.exists(full_path):
                        print(f"âŒ ì˜ìƒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {full_path}")
                        video.analysis_status = 'failed'
                        video.analysis_message = 'ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                        video.save()
                        return
                    
                    analysis_result = video_analysis_service.analyze_video(file_path, video.id)
                    if analysis_result and analysis_result is not True:
                        # ë¶„ì„ ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (ì˜¤ë¥˜ ì •ë³´ í¬í•¨)
                        if isinstance(analysis_result, dict) and not analysis_result.get('success', True):
                            print(f"âŒ ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {video.id} - {analysis_result.get('error_message', 'Unknown error')}")
                            video.analysis_status = 'failed'
                            video.analysis_message = analysis_result.get('error_message', 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
                        else:
                            print(f"âœ… ì˜ìƒ ë¶„ì„ ì™„ë£Œ: {video.id}")
                            video.analysis_status = 'completed'
                            video.is_analyzed = True
                    else:
                        print(f"âŒ ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {video.id}")
                        video.analysis_status = 'failed'
                        video.analysis_message = 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
                    
                    video.save()
                except Exception as e:
                    print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
                    video.analysis_status = 'failed'
                    video.analysis_message = f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                    video.save()
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
            analysis_thread = threading.Thread(target=analyze_video_background)
            analysis_thread.daemon = True
            analysis_thread.start()
            
            return Response({
                'success': True,
                'video_id': video.id,
                'filename': filename,
                'message': f'ë¹„ë””ì˜¤ "{video_file.name}"ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
                
        except Exception as e:
            return Response({
                'error': f'ì˜ìƒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class VideoListView(APIView):
    """ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ - backend_videochat ë°©ì‹"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            videos = Video.objects.all()
            video_list = []
            
            for video in videos:
                # ìƒíƒœ ë™ê¸°í™” ìˆ˜í–‰ (íŒŒì¼ê³¼ DB ìƒíƒœ ì¼ì¹˜ í™•ì¸)
                video_analysis_service.sync_video_status_with_files(video.id)
                
                # ë™ê¸°í™” í›„ ìµœì‹  ìƒíƒœë¡œ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
                video.refresh_from_db()
                
                # ë¶„ì„ ìƒíƒœ ê²°ì • (ë” ì •í™•í•œ íŒë‹¨)
                actual_analysis_status = video.analysis_status
                if video.analysis_status == 'completed' and not video.analysis_json_path:
                    actual_analysis_status = 'failed'
                    print(f"âš ï¸ ì˜ìƒ {video.id}: analysis_statusëŠ” completedì´ì§€ë§Œ analysis_json_pathê°€ ì—†ìŒ")
                
                video_data = {
                    'id': video.id,
                    'filename': video.filename,
                    'original_name': video.original_name,
                    'duration': video.duration,
                    'is_analyzed': video.is_analyzed,
                    'analysis_status': actual_analysis_status,  # ì‹¤ì œ ìƒíƒœ ì‚¬ìš©
                    'uploaded_at': video.uploaded_at,
                    'file_size': video.file_size,
                    'analysis_progress': video.analysis_progress,  # ì§„í–‰ë¥  ì •ë³´ ì¶”ê°€
                    'analysis_message': video.analysis_message or ''  # ë¶„ì„ ë©”ì‹œì§€ ì¶”ê°€
                }
                video_list.append(video_data)
            
            return Response({
                'videos': video_list,
                'count': len(video_list)
            })
            
        except Exception as e:
            return Response({
                'error': f'ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class VideoDeleteView(APIView):
    """ì˜ìƒ ì‚­ì œ API"""
    permission_classes = [AllowAny]
    
    def delete(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            # íŒŒì¼ ì‚­ì œ
            if video.file and os.path.exists(video.file.path):
                try:
                    os.remove(video.file.path)
                    logger.info(f"âœ… ì˜ìƒ íŒŒì¼ ì‚­ì œ: {video.file.path}")
                except Exception as e:
                    logger.warning(f"ì˜ìƒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì‚­ì œ
            if video.analysis_json_path:
                json_path = os.path.join(settings.MEDIA_ROOT, video.analysis_json_path)
                if os.path.exists(json_path):
                    try:
                        os.remove(json_path)
                        logger.info(f"âœ… ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì‚­ì œ: {json_path}")
                    except Exception as e:
                        logger.warning(f"ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            # í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
            if video.frame_images_path:
                frame_paths = video.frame_images_path.split(',')
                for path in frame_paths:
                    full_path = os.path.join(settings.MEDIA_ROOT, path.strip())
                    if os.path.exists(full_path):
                        try:
                            os.remove(full_path)
                        except Exception as e:
                            logger.warning(f"í”„ë ˆì„ ì´ë¯¸ì§€ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            # DBì—ì„œ ì‚­ì œ
            video_name = video.original_name
            video.delete()
            
            logger.info(f"âœ… ì˜ìƒ ì‚­ì œ ì™„ë£Œ: {video_name} (ID: {video_id})")
            
            return Response({
                'message': f'ì˜ìƒ "{video_name}"ì´(ê°€) ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'video_id': video_id
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ì‚­ì œ ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ì˜ìƒ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class VideoRenameView(APIView):
    """ì˜ìƒ ì´ë¦„ ë³€ê²½ API"""
    permission_classes = [AllowAny]
    
    def post(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            new_name = request.data.get('original_name', '').strip()
            
            if not new_name:
                return Response({
                    'error': 'ìƒˆ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            old_name = video.original_name
            video.original_name = new_name
            video.save()
            
            logger.info(f"âœ… ì˜ìƒ ì´ë¦„ ë³€ê²½: {old_name} â†’ {new_name} (ID: {video_id})")
            
            return Response({
                'message': f'ì˜ìƒ ì´ë¦„ì´ "{new_name}"(ìœ¼)ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'video_id': video_id,
                'new_name': new_name
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ì´ë¦„ ë³€ê²½ ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ì˜ìƒ ì´ë¦„ ë³€ê²½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class VideoAnalysisView(APIView):
    """ì˜ìƒ ë¶„ì„ ìƒíƒœ í™•ì¸ ë° ì‹œì‘ - backend_videochat ë°©ì‹"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            # ìƒíƒœ ë™ê¸°í™” ìˆ˜í–‰ (íŒŒì¼ê³¼ DB ìƒíƒœ ì¼ì¹˜ í™•ì¸)
            video_analysis_service.sync_video_status_with_files(video_id)
            
            # ë™ê¸°í™” í›„ ìµœì‹  ìƒíƒœë¡œ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
            video.refresh_from_db()
            
            # ì§„í–‰ë¥  ì •ë³´ ì¶”ì¶œ
            progress_info = {
                'analysis_progress': video.analysis_progress,
                'analysis_message': video.analysis_message or ''
            }
            
            # ë¶„ì„ ìƒíƒœ ê²°ì • (ë” ì •í™•í•œ íŒë‹¨)
            actual_analysis_status = video.analysis_status
            if video.analysis_status == 'completed' and not video.analysis_json_path:
                actual_analysis_status = 'failed'
                print(f"âš ï¸ ì˜ìƒ {video_id}: analysis_statusëŠ” completedì´ì§€ë§Œ analysis_json_pathê°€ ì—†ìŒ")
            
            return Response({
                'video_id': video.id,
                'filename': video.filename,
                'original_name': video.original_name,
                'analysis_status': actual_analysis_status,  # ì‹¤ì œ ìƒíƒœ ì‚¬ìš©
                'is_analyzed': video.is_analyzed,
                'duration': video.duration,
                'progress': progress_info,  # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°ë¡œ ë³€ê²½
                'uploaded_at': video.uploaded_at,
                'file_size': video.file_size,
                'analysis_json_path': video.analysis_json_path,
                'frame_images_path': video.frame_images_path
            })
        except Video.DoesNotExist:
            return Response({
                'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ì˜ìƒ ë¶„ì„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def post(self, request, video_id):
        """ì˜ìƒ ë¶„ì„ ì‹œì‘"""
        try:
            video = Video.objects.get(id=video_id)
            
            # ì´ë¯¸ ë¶„ì„ ì¤‘ì´ê±°ë‚˜ ì™„ë£Œëœ ê²½ìš°
            if video.analysis_status == 'pending':
                return Response({
                    'message': 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.',
                    'status': 'pending'
                })
            elif video.analysis_status == 'completed':
                return Response({
                    'message': 'ì´ë¯¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                    'status': 'completed'
                })
            
            # ë¶„ì„ ìƒíƒœë¥¼ pendingìœ¼ë¡œ ë³€ê²½
            video.analysis_status = 'pending'
            video.save()
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜ìƒ ë¶„ì„ ì‹œì‘
            def analyze_video_background():
                try:
                    print(f"ğŸ¬ ë°±ê·¸ë¼ìš´ë“œ ì˜ìƒ ë¶„ì„ ì‹œì‘: {video.id}")
                    analysis_result = video_analysis_service.analyze_video(video.file_path, video.id)
                    if analysis_result:
                        print(f"âœ… ì˜ìƒ ë¶„ì„ ì™„ë£Œ: {video.id}")
                        # Video ëª¨ë¸ ì—…ë°ì´íŠ¸
                        video.analysis_status = 'completed'
                        video.is_analyzed = True
                        video.save()
                    else:
                        print(f"âŒ ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {video.id}")
                        video.analysis_status = 'failed'
                        video.save()
                except Exception as e:
                    print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
                    video.analysis_status = 'failed'
                    video.save()
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
            analysis_thread = threading.Thread(target=analyze_video_background)
            analysis_thread.daemon = True
            analysis_thread.start()
            
            return Response({
                'message': 'ì˜ìƒ ë¶„ì„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.',
                'status': 'pending'
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ì˜ìƒ ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class VideoChatView(APIView):
    """ì˜ìƒ ì±„íŒ… ë·° - ë‹¤ì¤‘ AI ì‘ë‹µ ë° í†µí•©"""
    permission_classes = [AllowAny]  # ì„ì‹œë¡œ AllowAnyë¡œ ë³€ê²½
    
    def get(self, request, video_id=None):
        """ì±„íŒ… ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
        try:
            print(f"ğŸ” VideoChatView GET ìš”ì²­ - video_id: {video_id}")
            
            # ì‚¬ìš©ì ì •ë³´ ì²˜ë¦¬ (ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‚¬ìš©ì ì‚¬ìš©)
            user = None
            if hasattr(request, 'user') and request.user.is_authenticated:
                user = request.user
            else:
                # ê¸°ë³¸ ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                from chat.models import User
                user, created = User.objects.get_or_create(
                    username='anonymous',
                    defaults={'email': 'anonymous@example.com'}
                )
                print(f"âœ… ê¸°ë³¸ ì‚¬ìš©ì ìƒì„±/ê°€ì ¸ì˜¤ê¸°: {user.username}")
            
            if video_id:
                # íŠ¹ì • ì˜ìƒì˜ ì±„íŒ… ì„¸ì…˜ ì¡°íšŒ
                sessions = VideoChatSession.objects.filter(
                    user=user, 
                    video_id=video_id,
                    is_active=True
                ).order_by('-created_at')
            else:
                # ì‚¬ìš©ìì˜ ëª¨ë“  ì±„íŒ… ì„¸ì…˜ ì¡°íšŒ
                sessions = VideoChatSession.objects.filter(
                    user=user,
                    is_active=True
                ).order_by('-created_at')
            
            serializer = VideoChatSessionSerializer(sessions, many=True)
            return Response({
                'sessions': serializer.data,
                'total_count': sessions.count()
            })
            
        except Exception as e:
            return Response({
                'error': f'ì±„íŒ… ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def post(self, request, video_id):
        """ì˜ìƒ ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡"""
        try:
            print(f"ğŸ” VideoChatView POST ìš”ì²­ - video_id: {video_id}")
            # Django WSGIRequestì—ì„œ JSON ë°ì´í„° íŒŒì‹±
            import json
            if hasattr(request, 'data'):
                message = request.data.get('message')
            else:
                body = request.body.decode('utf-8')
                data = json.loads(body)
                message = data.get('message')
            print(f"ğŸ“ ë©”ì‹œì§€: {message}")
            
            if not message:
                return Response({
                    'error': 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ì˜ìƒ ë¶„ì„ ìƒíƒœ í™•ì¸ (Video ëª¨ë¸ì—ì„œ ì§ì ‘ í™•ì¸)
            try:
                video = Video.objects.get(id=video_id)
                if video.analysis_status == 'pending':
                    return Response({
                        'error': 'ì˜ìƒ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
                        'status': 'analyzing'
                    }, status=status.HTTP_202_ACCEPTED)
                elif video.analysis_status == 'failed':
                    return Response({
                        'error': 'ì˜ìƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.',
                        'status': 'failed'
                    }, status=status.HTTP_400_BAD_REQUEST)
            except Video.DoesNotExist:
                return Response({
                    'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ì‚¬ìš©ì ì •ë³´ ì²˜ë¦¬ (ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‚¬ìš©ì ì‚¬ìš©)
            user = request.user if request.user.is_authenticated else None
            if not user:
                # ê¸°ë³¸ ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                from chat.models import User
                user, created = User.objects.get_or_create(
                    username='anonymous',
                    defaults={'email': 'anonymous@example.com'}
                )
            
            # ì±„íŒ… ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            session, created = VideoChatSession.objects.get_or_create(
                user=user,
                video_id=video_id,
                is_active=True,
                defaults={
                    'video_title': f"Video {video_id}",
                    'video_analysis_data': {}
                }
            )
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            user_message = VideoChatMessage.objects.create(
                session=session,
                message_type='user',
                content=message
            )
            
            # ğŸ¯ ê°œì„ ëœ í•¸ë“¤ëŸ¬ ì‚¬ìš©
            print(f"ğŸ” ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ ì‚¬ìš©: '{message}'")
            handler = get_video_chat_handler(video_id, video)
            chat_result = handler.process_message(message)
            
            # AI ê°œë³„ ì‘ë‹µ ì €ì¥
            individual_messages = []
            if chat_result.get('individual_responses'):
                for ai_name, ai_content in chat_result['individual_responses'].items():
                    ai_message = VideoChatMessage.objects.create(
                        session=session,
                        message_type='ai',
                        content=ai_content,
                        ai_model=ai_name,
                        parent_message=user_message
                    )
                    individual_messages.append(ai_message)
            
            # í†µí•© ì‘ë‹µ ì €ì¥
            optimal_response = chat_result.get('answer', '')
            optimal_message = None
            if optimal_response:
                optimal_message = VideoChatMessage.objects.create(
                    session=session,
                    message_type='ai_optimal',
                    content=optimal_response,
                    ai_model='optimal',
                    parent_message=user_message
                )
            
            # í”„ë ˆì„ ì •ë³´ êµ¬ì„±
            relevant_frames = []
            if chat_result.get('frames'):
                # ë©”íƒ€ DBì—ì„œ ì „ì²´ í”„ë ˆì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                meta_db_path = f"/Users/seon/AIOFAI_F/AI_of_AI/chatbot_backend/media/upload_1758464088_upload_1758158306_upload_1758153730_upload_1758152157_test2.mp4-meta_db.json"
                all_frames = []
                try:
                    with open(meta_db_path, 'r', encoding='utf-8') as f:
                        meta_data = json.load(f)
                        all_frames = meta_data.get('frame', [])
                except:
                    pass
                
                for idx, frame in enumerate(chat_result['frames']):
                    # ì‹¤ì œ í”„ë ˆì„ ì¸ë±ìŠ¤ ì°¾ê¸° (timestampë¡œ ë§¤ì¹­)
                    actual_frame_index = -1
                    for i, meta_frame in enumerate(all_frames):
                        if abs(meta_frame.get('timestamp', 0) - frame.get('timestamp', 0)) < 0.1:
                            actual_frame_index = i
                            break
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ìƒì„± (ì‹¤ì œ í”„ë ˆì„ ì¸ë±ìŠ¤ + 1)
                    if actual_frame_index >= 0:
                        frame_image_path = f"images/video{video_id}_frame{actual_frame_index + 1}.jpg"
                    else:
                        frame_image_path = f"images/video{video_id}_frame{idx + 1}.jpg"
                    
                    frame_info = {
                        'image_id': frame.get('image_id', idx + 1),
                        'timestamp': frame.get('timestamp', 0),
                        'image_url': f"/media/{frame_image_path}",  # /media/ ê²½ë¡œ ì¶”ê°€
                        'caption': frame.get('caption', ''),
                        'relevance_score': frame.get('match_score', 1.0),  # match_scoreë¥¼ relevance_scoreë¡œ ë³€í™˜
                        'persons': frame.get('objects', [])[:3],  # ìµœëŒ€ 3ëª…ë§Œ
                        'objects': [],
                        'scene_attributes': {
                            'scene_type': 'unknown',
                            'lighting': 'unknown',
                            'activity_level': 'unknown'
                        }
                    }
                    relevant_frames.append(frame_info)
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„± (í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ì— ë§ì¶¤)
            response_data = {
                'session_id': str(session.id),
                'user_message': {
                    'id': str(user_message.id),
                    'content': message,
                    'created_at': user_message.created_at.isoformat()
                },
                'ai_responses': {
                    'individual': [
                        {
                            'id': str(msg.id),
                            'model': msg.ai_model,
                            'content': msg.content,
                            'created_at': msg.created_at.isoformat()
                        } for msg in individual_messages
                    ],
                    'optimal': {
                        'id': str(optimal_message.id) if optimal_message else None,
                        'model': 'optimal',
                        'content': optimal_response,
                        'created_at': optimal_message.created_at.isoformat() if optimal_message else None
                    } if optimal_response else None
                },
                'relevant_frames': relevant_frames,
                'is_video_related': chat_result.get('is_video_related', True)
            }
            
            print(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ:")
            print(f"   - ê°œë³„ AI: {len(individual_messages)}ê°œ")
            print(f"   - í†µí•© ì‘ë‹µ: {'ìˆìŒ' if optimal_response else 'ì—†ìŒ'}")
            print(f"   - ê´€ë ¨ í”„ë ˆì„: {len(relevant_frames)}ê°œ")
            
            return Response(response_data)
            
        except Exception as e:
            import traceback
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"âŒ ìƒì„¸: {traceback.format_exc()}")
            return Response({
                'error': f'ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ì˜ìƒ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Video ëª¨ë¸ì—ì„œ ì§ì ‘)
            analysis_data = {
                'original_name': video.original_name,
                'file_size': video.file_size,
                'uploaded_at': video.uploaded_at.isoformat(),
                'analysis_status': video.analysis_status,
                'duration': video.duration,
                'is_analyzed': video.is_analyzed
            }
            
            # JSON ë¶„ì„ ê²°ê³¼ ë¡œë“œ (ê¸°ì¡´ + TeletoVision_AI ìŠ¤íƒ€ì¼)
            analysis_json_data = None
            teleto_vision_data = {}
            
            # 1. ê¸°ì¡´ ë¶„ì„ JSON ë¡œë“œ
            if video.analysis_json_path:
                try:
                    from django.conf import settings
                    json_path = os.path.join(settings.MEDIA_ROOT, video.analysis_json_path)
                    print(f"ğŸ” ê¸°ì¡´ JSON íŒŒì¼ ê²½ë¡œ: {json_path}")
                    print(f"ğŸ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(json_path)}")
                    
                    with open(json_path, 'r', encoding='utf-8') as f:
                        analysis_json_data = json.load(f)
                    print(f"âœ… ê¸°ì¡´ JSON ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì„±ê³µ: {json_path}")
                    print(f"ğŸ“Š ê¸°ì¡´ JSON ë°ì´í„° í‚¤: {list(analysis_json_data.keys())}")
                    if 'frame_results' in analysis_json_data:
                        print(f"ğŸ“Š frame_results ê°œìˆ˜: {len(analysis_json_data['frame_results'])}")
                        if analysis_json_data['frame_results']:
                            print(f"ğŸ“Š ì²« ë²ˆì§¸ í”„ë ˆì„: {analysis_json_data['frame_results'][0]}")
                except Exception as e:
                    print(f"âŒ ê¸°ì¡´ JSON ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    import traceback
                    print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            else:
                print("âŒ analysis_json_pathê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. TeletoVision_AI ìŠ¤íƒ€ì¼ JSON ë¡œë“œ
            try:
                from django.conf import settings
                video_name = video.original_name or video.filename
                detection_db_path = os.path.join(settings.MEDIA_ROOT, f"{video_name}-detection_db.json")
                meta_db_path = os.path.join(settings.MEDIA_ROOT, f"{video_name}-meta_db.json")
                
                print(f"ğŸ” TeletoVision detection_db ê²½ë¡œ: {detection_db_path}")
                print(f"ğŸ” TeletoVision meta_db ê²½ë¡œ: {meta_db_path}")
                
                # detection_db.json ë¡œë“œ
                if os.path.exists(detection_db_path):
                    with open(detection_db_path, 'r', encoding='utf-8') as f:
                        teleto_vision_data['detection_db'] = json.load(f)
                    print(f"âœ… TeletoVision detection_db ë¡œë“œ ì„±ê³µ: {len(teleto_vision_data['detection_db'])}ê°œ í”„ë ˆì„")
                else:
                    print(f"âŒ TeletoVision detection_db íŒŒì¼ ì—†ìŒ: {detection_db_path}")
                
                # meta_db.json ë¡œë“œ
                if os.path.exists(meta_db_path):
                    with open(meta_db_path, 'r', encoding='utf-8') as f:
                        teleto_vision_data['meta_db'] = json.load(f)
                    print(f"âœ… TeletoVision meta_db ë¡œë“œ ì„±ê³µ: {len(teleto_vision_data['meta_db'].get('frame', []))}ê°œ í”„ë ˆì„")
                    if teleto_vision_data['meta_db'].get('frame'):
                        first_frame = teleto_vision_data['meta_db']['frame'][0]
                        print(f"ğŸ“Š ì²« ë²ˆì§¸ meta í”„ë ˆì„ í‚¤: {list(first_frame.keys())}")
                else:
                    print(f"âŒ TeletoVision meta_db íŒŒì¼ ì—†ìŒ: {meta_db_path}")
                    
            except Exception as e:
                print(f"âŒ TeletoVision JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
                import traceback
                print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                teleto_vision_data = {}
                print(f"âŒ video.analysis_json_path: {video.analysis_json_path}")
            
            # í”„ë ˆì„ ê²€ìƒ‰ ë° ì´ë¯¸ì§€ URL ìƒì„±
            print(f"ğŸ” í”„ë ˆì„ ê²€ìƒ‰ ì‹œì‘ - analysis_json_data: {analysis_json_data is not None}")
            if analysis_json_data:
                print(f"ğŸ“Š frame_results ì¡´ì¬: {'frame_results' in analysis_json_data}")
                if 'frame_results' in analysis_json_data:
                    print(f"ğŸ“Š frame_results ê°œìˆ˜: {len(analysis_json_data['frame_results'])}")
            else:
                print("âŒ analysis_json_dataê°€ Noneì…ë‹ˆë‹¤!")
                print(f"âŒ video.analysis_json_path: {video.analysis_json_path}")
                print(f"âŒ video.analysis_status: {video.analysis_status}")
                print(f"âŒ video.is_analyzed: {video.is_analyzed}")
            
            # ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
            session_id = f"video_{video_id}_user_{user.id}"
            context_prompt = conversation_memory.generate_context_prompt(session_id, message)
            
            # í”„ë ˆì„ ê²€ìƒ‰ (ì˜ë„ ê¸°ë°˜)
            relevant_frames = self._find_relevant_frames(message, analysis_json_data, video_id)
            print(f"ğŸ” ê²€ìƒ‰ëœ í”„ë ˆì„ ìˆ˜: {len(relevant_frames)}")
            if relevant_frames:
                print(f"ğŸ“¸ ì²« ë²ˆì§¸ í”„ë ˆì„: {relevant_frames[0]}")
                print(f"ğŸ“¸ ëª¨ë“  í”„ë ˆì„ ì •ë³´:")
                for i, frame in enumerate(relevant_frames):
                    print(f"  í”„ë ˆì„ {i+1}: {frame}")
            else:
                print("âŒ ê²€ìƒ‰ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤!")
                print(f"âŒ analysis_json_data keys: {list(analysis_json_data.keys()) if analysis_json_data else 'None'}")
                if analysis_json_data and 'frame_results' in analysis_json_data:
                    print(f"âŒ frame_results ê°œìˆ˜: {len(analysis_json_data['frame_results'])}")
                    if analysis_json_data['frame_results']:
                        print(f"âŒ ì²« ë²ˆì§¸ frame_result: {analysis_json_data['frame_results'][0]}")
            
            # ë‹¤ì¤‘ AI ì‘ë‹µ ìƒì„±
            ai_responses = {}
            individual_messages = []
            
            # ê¸°ë³¸ ì±„íŒ… ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ AI ëª¨ë¸ ì´ˆê¸°í™”
            try:
                # ì „ì—­ chatbots ë³€ìˆ˜ ì‚¬ìš© (ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŒ)
                print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸: {list(chatbots.keys())}")
            except Exception as e:
                print(f"âš ï¸ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # ì „ì—­ chatbots ë³€ìˆ˜ëŠ” ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë®ì–´ì“°ì§€ ì•ŠìŒ
            
            # AI ëª¨ë¸ í™•ì¸
            print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸: {list(chatbots.keys()) if chatbots else 'None'}")
            
            # AI ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì‘ë‹µ (í”„ë ˆì„ ì •ë³´ í¬í•¨)
            if not chatbots:
                print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
                
                # í”„ë ˆì„ ì •ë³´ë¥¼ í¬í•¨í•œ ë” ë‚˜ì€ ì‘ë‹µ ìƒì„±
                if relevant_frames:
                    frame_count = len(relevant_frames)
                    default_response = f"ì˜ìƒì—ì„œ '{message}'ì™€ ê´€ë ¨ëœ {frame_count}ê°œì˜ í”„ë ˆì„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n\n"
                    
                    for i, frame in enumerate(relevant_frames, 1):
                        default_response += f"ğŸ“¸ í”„ë ˆì„ {i}:\n"
                        default_response += f"   â° ì‹œê°„: {frame['timestamp']:.1f}ì´ˆ\n"
                        default_response += f"   ğŸ¯ ê´€ë ¨ë„: {frame['relevance_score']}ì \n"
                        
                        if frame['persons'] and len(frame['persons']) > 0:
                            default_response += f"   ğŸ‘¤ ì‚¬ëŒ {len(frame['persons'])}ëª… ê°ì§€\n"
                        
                        if frame['objects'] and len(frame['objects']) > 0:
                            default_response += f"   ğŸ“¦ ê°ì²´ {len(frame['objects'])}ê°œ ê°ì§€\n"
                        
                        scene_attrs = frame.get('scene_attributes', {})
                        if scene_attrs:
                            scene_type = scene_attrs.get('scene_type', 'unknown')
                            lighting = scene_attrs.get('lighting', 'unknown')
                            activity = scene_attrs.get('activity_level', 'unknown')
                            default_response += f"   ğŸï¸ ì¥ë©´: {scene_type}, ì¡°ëª…: {lighting}, í™œë™: {activity}\n"
                        
                        default_response += "\n"
                    
                    default_response += "ğŸ’¡ AI ëª¨ë¸ì´ í™œì„±í™”ë˜ë©´ ë” ìì„¸í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                else:
                    default_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì™€ ê´€ë ¨ëœ í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                    default_response += "ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”:\n"
                    default_response += "â€¢ ì‚¬ëŒ, ìë™ì°¨, ë™ë¬¼, ìŒì‹, ì˜·, ê±´ë¬¼, ìì—°, ë¬¼ì²´"
                
                ai_responses = {
                    'default': default_response
                }
            else:
                # ê° AI ëª¨ë¸ì— ì§ˆë¬¸ ì „ì†¡
                for bot_name, chatbot in chatbots.items():
                    if bot_name == 'optimal':
                        continue  # optimalì€ ë‚˜ì¤‘ì— ì²˜ë¦¬
                    
                    try:
                        # ìƒ‰ìƒ ê²€ìƒ‰ ëª¨ë“œ í™•ì¸
                        is_color_search = any(keyword in message.lower() for keyword in ['ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ë³´ë¼ìƒ‰', 'ë¶„í™ìƒ‰', 'ê²€ì€ìƒ‰', 'í°ìƒ‰', 'íšŒìƒ‰', 'ì£¼í™©ìƒ‰', 'ê°ˆìƒ‰', 'ì˜·'])
                        
                        # ê°„ì†Œí™”ëœ ì˜ìƒ ì •ë³´ í”„ë¡¬í”„íŠ¸ ìƒì„±
                        video_context = f"""
ì˜ìƒ: {analysis_data.get('original_name', 'Unknown')} ({analysis_data.get('file_size', 0) / (1024*1024):.1f}MB)
ë¶„ì„: {len(analysis_json_data.get('frame_results', []))}ê°œ í”„ë ˆì„, {analysis_json_data.get('video_summary', {}).get('total_detections', 0)}ê°œ ê°ì²´
í’ˆì§ˆ: {analysis_json_data.get('video_summary', {}).get('quality_assessment', {}).get('overall_score', 0):.2f}
"""
                        
                        # ê°„ì†Œí™”ëœ í”„ë ˆì„ ì •ë³´
                        frame_context = ""
                        if relevant_frames:
                            frame_context = f"\nê´€ë ¨ í”„ë ˆì„ {len(relevant_frames)}ê°œ:\n"
                            for i, frame in enumerate(relevant_frames[:2], 1):  # ìµœëŒ€ 2ê°œë§Œ
                                frame_context += f"í”„ë ˆì„ {i}: {frame['timestamp']:.1f}ì´ˆ, ì‚¬ëŒ {len(frame.get('persons', []))}ëª…\n"
                        else:
                            frame_context = "\nê´€ë ¨ í”„ë ˆì„ ì—†ìŒ\n"
                        
                        enhanced_message = f"""{video_context}{frame_context}

ì‚¬ìš©ì ì§ˆë¬¸: "{message}"

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                        
                        # ê°„ì†Œí™”ëœ AI í”„ë¡¬í”„íŠ¸
                        ai_prompt = enhanced_message
                        
                        # AIë³„ íŠ¹ì„±í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±
                        ai_response = chatbot.chat(ai_prompt)
                        ai_responses[bot_name] = ai_response
                        
                        # ê°œë³„ AI ì‘ë‹µ ì €ì¥
                        ai_message = VideoChatMessage.objects.create(
                            session=session,
                            message_type='ai',
                            content=ai_response,
                            ai_model=bot_name,
                            parent_message=user_message
                        )
                        individual_messages.append(ai_message)
                        
                    except Exception as e:
                        print(f"AI {bot_name} ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        continue
            
            # í†µí•© ì‘ë‹µ ìƒì„± (ê¸°ë³¸ ì±„íŒ… ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë°©ì‹)
            optimal_response = ""
            if ai_responses and len(ai_responses) > 1:
                try:
                    # ê¸°ë³¸ ì±„íŒ… ì‹œìŠ¤í…œì˜ generate_optimal_response ì‚¬ìš©
                    optimal_response = generate_optimal_response(ai_responses, message, os.getenv('OPENAI_API_KEY'))
                    
                    # í”„ë ˆì„ ì •ë³´ ì¶”ê°€ (ë” ìì„¸í•œ ì •ë³´ í¬í•¨)
                    if relevant_frames:
                        frame_summary = f"\n\nğŸ“¸ ê´€ë ¨ í”„ë ˆì„ {len(relevant_frames)}ê°œ ë°œê²¬:\n"
                        for i, frame in enumerate(relevant_frames, 1):
                            frame_summary += f"â€¢ í”„ë ˆì„ {i}: {frame['timestamp']:.1f}ì´ˆ (ê´€ë ¨ë„ {frame['relevance_score']:.2f}ì )\n"
                            
                            # í”„ë ˆì„ë³„ ì„¸ë¶€ ì •ë³´ ì¶”ê°€
                            if frame.get('persons'):
                                frame_summary += f"  ğŸ‘¤ ì‚¬ëŒ {len(frame['persons'])}ëª… ê°ì§€ë¨!\n"
                                # ê° ì‚¬ëŒì˜ ìƒì„¸ ì •ë³´ ì¶”ê°€
                                for j, person in enumerate(frame['persons'], 1):
                                    confidence = person.get('confidence', 0)
                                    frame_summary += f"    ì‚¬ëŒ {j}: ì‹ ë¢°ë„ {confidence:.2f}\n"
                                    # ì†ì„± ì •ë³´ ì¶”ê°€
                                    attrs = person.get('attributes', {})
                                    if 'gender' in attrs:
                                        gender_info = attrs['gender']
                                        frame_summary += f"      ì„±ë³„: {gender_info.get('value', 'unknown')}\n"
                                    if 'age' in attrs:
                                        age_info = attrs['age']
                                        frame_summary += f"      ë‚˜ì´: {age_info.get('value', 'unknown')}\n"
                            if frame.get('objects'):
                                frame_summary += f"  ğŸ“¦ ê°ì²´ {len(frame['objects'])}ê°œ ê°ì§€\n"
                            
                            scene_attrs = frame.get('scene_attributes', {})
                            if scene_attrs:
                                scene_type = scene_attrs.get('scene_type', 'unknown')
                                lighting = scene_attrs.get('lighting', 'unknown')
                                frame_summary += f"  ğŸï¸ ì¥ë©´: {scene_type}, ì¡°ëª…: {lighting}\n"
                        
                        frame_summary += "\nğŸ’¡ ìœ„ í”„ë ˆì„ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì˜ìƒì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•´ë³´ì„¸ìš”."
                        optimal_response += frame_summary
                    
                    # í†µí•© ì‘ë‹µ ì €ì¥
                    optimal_message = VideoChatMessage.objects.create(
                        session=session,
                        message_type='ai_optimal',
                        content=optimal_response,
                        ai_model='optimal',
                        parent_message=user_message
                    )
                    
                except Exception as e:
                    print(f"í†µí•© ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    optimal_response = f"í†µí•© ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            elif ai_responses and len(ai_responses) == 1:
                # AI ì‘ë‹µì´ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš°
                optimal_response = list(ai_responses.values())[0]
            
            # ì‘ë‹µ í’ˆì§ˆ í‰ê°€
            evaluation_results = {}
            if ai_responses and len(ai_responses) > 1:
                try:
                    evaluation_results = evaluation_metrics.evaluate_summary_quality(
                        ai_responses, reference=optimal_response
                    )
                    print(f"âœ… ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: {len(evaluation_results)}ê°œ AI")
                except Exception as e:
                    print(f"âŒ ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            
            # ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸
            try:
                conversation_memory.add_context(
                    session_id=session_id,
                    user_message=message,
                    ai_responses=ai_responses,
                    video_context={
                        'video_id': video_id,
                        'video_name': video.original_name,
                        'relevant_frames_count': len(relevant_frames)
                    }
                )
                print(f"âœ… ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            response_data = {
                'session_id': str(session.id),
                'user_message': {
                    'id': str(user_message.id),
                    'content': message,
                    'created_at': user_message.created_at
                },
                'ai_responses': {
                    'individual': [
                        {
                            'id': str(msg.id),
                            'model': msg.ai_model,
                            'content': msg.content,
                            'created_at': msg.created_at
                        } for msg in individual_messages
                    ],
                    'optimal': {
                        'content': optimal_response,
                        'created_at': individual_messages[0].created_at if individual_messages else None
                    } if optimal_response else None
                },
                'relevant_frames': relevant_frames,  # ê´€ë ¨ í”„ë ˆì„ ì •ë³´ ì¶”ê°€
                'evaluation_results': evaluation_results,  # í’ˆì§ˆ í‰ê°€ ê²°ê³¼
                'context_info': {
                    'session_id': session_id,
                    'context_length': len(conversation_memory.get_context(session_id).get('conversations', []))
                }
            }
            
            # ë””ë²„ê¹…: relevant_frames í™•ì¸
            print(f"ğŸ” ì‘ë‹µ ìƒì„± ì‹œ relevant_frames: {len(relevant_frames)}")
            if relevant_frames:
                print(f"ğŸ“¸ ì²« ë²ˆì§¸ í”„ë ˆì„: {relevant_frames[0]}")
            else:
                print("âŒ relevant_framesê°€ ë¹„ì–´ìˆìŒ!")
            
            print(f"ğŸ“¤ ì‘ë‹µì— í¬í•¨ë  í”„ë ˆì„ ìˆ˜: {len(relevant_frames)}")
            if relevant_frames:
                print(f"ğŸ“¸ ì²« ë²ˆì§¸ í”„ë ˆì„: {relevant_frames[0]}")
            
            return Response(response_data)
            
        except Exception as e:
            import traceback
            print(f"âŒ VideoChatView POST ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            return Response({
                'error': f'ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'traceback': traceback.format_exc()
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _classify_intent(self, message):
        """ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜"""
        try:
            message_lower = message.lower()
            
            # ì˜ë„ë³„ í‚¤ì›Œë“œ ì •ì˜
            intent_keywords = {
                'video_summary': ['ìš”ì•½', 'summary', 'ê°„ë‹¨', 'ìƒì„¸', 'í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì •ë¦¬'],
                'video_search': ['ì°¾ì•„', 'ê²€ìƒ‰', 'search', 'ë³´ì—¬', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„ê°€'],
                'person_search': ['ì‚¬ëŒ', 'person', 'people', 'human', 'ë‚¨ì„±', 'ì—¬ì„±', 'ì„±ë³„'],
                'color_search': ['ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ë³´ë¼ìƒ‰', 'ë¶„í™ìƒ‰', 'ê²€ì€ìƒ‰', 'í°ìƒ‰', 'íšŒìƒ‰', 'ì£¼í™©ìƒ‰', 'ê°ˆìƒ‰', 'ìƒ‰ê¹”', 'ìƒ‰ìƒ', 'ì˜·', 'ì…ì€', 'ì°©ìš©'],
                'temporal_analysis': ['ì‹œê°„', 'ë¶„', 'ì´ˆ', 'ì–¸ì œ', 'ëª‡ì‹œ', 'ì„±ë¹„', 'ì¸ì›', 'í†µê³„'],
                'inter_video_search': ['ë¹„ì˜¤ëŠ”', 'ë°¤', 'ë‚®', 'ë‚ ì”¨', 'ì¡°ëª…', 'ì˜ìƒê°„', 'ë‹¤ë¥¸ì˜ìƒ'],
                'general_chat': ['ì•ˆë…•', 'hello', 'hi', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'ë„ì›€', 'ì§ˆë¬¸']
            }
            
            # ì˜ë„ ì ìˆ˜ ê³„ì‚°
            intent_scores = {}
            for intent, keywords in intent_keywords.items():
                score = sum(1 for keyword in keywords if keyword in message_lower)
                if score > 0:
                    intent_scores[intent] = score
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ì„ íƒ
            if intent_scores:
                detected_intent = max(intent_scores, key=intent_scores.get)
                confidence = intent_scores[detected_intent] / len(message_lower.split())
                print(f"ğŸ¯ ì˜ë„ ë¶„ë¥˜: {detected_intent} (ì‹ ë¢°ë„: {confidence:.2f})")
                return detected_intent, confidence
            else:
                print("ğŸ¯ ì˜ë„ ë¶„ë¥˜: general_chat (ê¸°ë³¸ê°’)")
                return 'general_chat', 0.0
                
        except Exception as e:
            print(f"âŒ ì˜ë„ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return 'general_chat', 0.0

    def _parse_time_range(self, message):
        """ë©”ì‹œì§€ì—ì„œ ì‹œê°„ ë²”ìœ„ë¥¼ íŒŒì‹±"""
        try:
            import re
            
            # ì‹œê°„ íŒ¨í„´ ë§¤ì¹­ (ì˜ˆ: "3:00~5:00", "3ë¶„~5ë¶„", "180ì´ˆ~300ì´ˆ")
            time_patterns = [
                r'(\d+):(\d+)~(\d+):(\d+)',  # 3:00~5:00
                r'(\d+)ë¶„~(\d+)ë¶„',          # 3ë¶„~5ë¶„
                r'(\d+)ì´ˆ~(\d+)ì´ˆ',          # 180ì´ˆ~300ì´ˆ
            ]
            
            for pattern in time_patterns:
                match = re.search(pattern, message)
                if match:
                    groups = match.groups()
                    if len(groups) == 4:  # 3:00~5:00 í˜•ì‹
                        start_min, start_sec, end_min, end_sec = map(int, groups)
                        start_time = start_min * 60 + start_sec
                        end_time = end_min * 60 + end_sec
                        return start_time, end_time
                    elif len(groups) == 2:  # ë¶„ ë˜ëŠ” ì´ˆ í˜•ì‹
                        start_val, end_val = map(int, groups)
                        if 'ë¶„' in message:
                            start_time = start_val * 60
                            end_time = end_val * 60
                        else:  # ì´ˆ
                            start_time = start_val
                            end_time = end_val
                        return start_time, end_time
            
            return None
            
        except Exception as e:
            print(f"âŒ ì‹œê°„ ë²”ìœ„ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _find_relevant_frames(self, message, analysis_json_data, video_id):
        """ì‚¬ìš©ì ë©”ì‹œì§€ì— ë”°ë¼ ê´€ë ¨ í”„ë ˆì„ì„ ì°¾ì•„ì„œ ì´ë¯¸ì§€ URLê³¼ í•¨ê»˜ ë°˜í™˜ (ì˜ë„ ê¸°ë°˜)"""
        try:
            if not analysis_json_data or 'frame_results' not in analysis_json_data:
                print("âŒ ë¶„ì„ ë°ì´í„° ë˜ëŠ” í”„ë ˆì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            relevant_frames = []
            message_lower = message.lower()
            
            # í”„ë ˆì„ ê²°ê³¼ì—ì„œ ë§¤ì¹­ë˜ëŠ” í”„ë ˆì„ ì°¾ê¸°
            frame_results = analysis_json_data.get('frame_results', [])
            print(f"ğŸ” ê²€ìƒ‰í•  í”„ë ˆì„ ìˆ˜: {len(frame_results)}")
            
            # ì˜ë„ ë¶„ë¥˜
            intent, confidence = self._classify_intent(message)
            print(f"ğŸ¯ ê²€ìƒ‰ ì˜ë„: {intent}")
            
            # ìƒ‰ìƒ ê¸°ë°˜ ê²€ìƒ‰
            color_keywords = {
                'ë¹¨ê°„ìƒ‰': ['red', 'ë¹¨ê°•', 'ë¹¨ê°„ìƒ‰'],
                'íŒŒë€ìƒ‰': ['blue', 'íŒŒë‘', 'íŒŒë€ìƒ‰'],
                'ë…¸ë€ìƒ‰': ['yellow', 'ë…¸ë‘', 'ë…¸ë€ìƒ‰'],
                'ì´ˆë¡ìƒ‰': ['green', 'ë…¹ìƒ‰', 'ì´ˆë¡ìƒ‰'],
                'ë³´ë¼ìƒ‰': ['purple', 'ìì£¼ìƒ‰', 'ë³´ë¼ìƒ‰'],
                'ë¶„í™ìƒ‰': ['pink', 'í•‘í¬', 'ë¶„í™ìƒ‰'],
                'ê²€ì€ìƒ‰': ['black', 'ê²€ì •', 'ê²€ì€ìƒ‰'],
                'í°ìƒ‰': ['white', 'í•˜ì–‘', 'í°ìƒ‰'],
                'íšŒìƒ‰': ['gray', 'grey', 'íšŒìƒ‰'],
                'ì£¼í™©ìƒ‰': ['orange', 'ì˜¤ë Œì§€', 'ì£¼í™©ìƒ‰'],
                'ê°ˆìƒ‰': ['brown', 'ë¸Œë¼ìš´', 'ê°ˆìƒ‰'],
                'ì˜·': ['clothing', 'clothes', 'dress', 'shirt', 'pants', 'jacket']
            }
            
            # ì˜ë„ ê¸°ë°˜ í”„ë ˆì„ ê²€ìƒ‰
            if intent == 'color_search':
                print("ğŸ¨ ìƒ‰ìƒ ê²€ìƒ‰ ëª¨ë“œ")
                detected_colors = []
                for color_korean, color_terms in color_keywords.items():
                    if any(term in message_lower for term in color_terms):
                        detected_colors.append(color_korean)
                        print(f"ğŸ¨ ìƒ‰ìƒ ê²€ìƒ‰ ê°ì§€: {color_korean}")
                
                if detected_colors:
                    print(f"ğŸ¨ ìƒ‰ìƒ ê²€ìƒ‰ ëª¨ë“œ: {detected_colors}")
                    print(f"ğŸ” ê²€ìƒ‰í•  í”„ë ˆì„ ìˆ˜: {len(frame_results)}")
                    for frame in frame_results:
                        persons = frame.get('persons', [])
                        
                        # ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼ í™•ì¸
                        dominant_colors = frame.get('dominant_colors', [])
                        color_match_found = False
                        
                        # ìš”ì²­ëœ ìƒ‰ìƒê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸ (ë” ìœ ì—°í•œ ë§¤ì¹­)
                        for detected_color in detected_colors:
                            for color_info in dominant_colors:
                                color_name = color_info.get('color', '').lower()
                                detected_color_lower = detected_color.lower()
                                
                                # ìƒ‰ìƒ í‚¤ì›Œë“œ ë§¤í•‘ì„ í†µí•œ ë§¤ì¹­
                                color_mapping = {
                                    'ë¶„í™ìƒ‰': 'pink', 'í•‘í¬': 'pink',
                                    'ë¹¨ê°„ìƒ‰': 'red', 'ë¹¨ê°•': 'red',
                                    'íŒŒë€ìƒ‰': 'blue', 'íŒŒë‘': 'blue',
                                    'ë…¸ë€ìƒ‰': 'yellow', 'ë…¸ë‘': 'yellow',
                                    'ì´ˆë¡ìƒ‰': 'green', 'ë…¹ìƒ‰': 'green',
                                    'ë³´ë¼ìƒ‰': 'purple', 'ìì£¼ìƒ‰': 'purple',
                                    'ê²€ì€ìƒ‰': 'black', 'ê²€ì •': 'black',
                                    'í°ìƒ‰': 'white', 'í•˜ì–‘': 'white',
                                    'íšŒìƒ‰': 'gray', 'grey': 'gray',
                                    'ì£¼í™©ìƒ‰': 'orange', 'ì˜¤ë Œì§€': 'orange',
                                    'ê°ˆìƒ‰': 'brown', 'ë¸Œë¼ìš´': 'brown'
                                }
                                
                                # ë§¤í•‘ëœ ìƒ‰ìƒìœ¼ë¡œ ë¹„êµ
                                mapped_color = color_mapping.get(detected_color_lower, detected_color_lower)
                                
                                # ë” ìœ ì—°í•œ ìƒ‰ìƒ ë§¤ì¹­ (ìƒ‰ìƒì´ ì—†ì–´ë„ ì¼ë‹¨ í¬í•¨)
                                if (mapped_color == color_name or 
                                    detected_color_lower == color_name or 
                                    detected_color_lower in color_name or 
                                    color_name in detected_color_lower or
                                    len(dominant_colors) == 0):  # ìƒ‰ìƒ ì •ë³´ê°€ ì—†ì–´ë„ í¬í•¨
                                    color_match_found = True
                                    print(f"âœ… ìƒ‰ìƒ ë§¤ì¹­ ë°œê²¬: {detected_color} -> {color_info}")
                                    break
                            if color_match_found:
                                break
                        
                        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
                        print(f"ğŸ” í”„ë ˆì„ {frame.get('image_id', 0)} ìƒ‰ìƒ ë¶„ì„:")
                        print(f"  - ìš”ì²­ëœ ìƒ‰ìƒ: {detected_colors}")
                        print(f"  - ê°ì§€ëœ ìƒ‰ìƒ: {[c.get('color', '') for c in dominant_colors]}")
                        print(f"  - ë§¤ì¹­ ê²°ê³¼: {color_match_found}")
                        
                        # ìƒ‰ìƒ ê²€ìƒ‰ì˜ ê²½ìš° ìƒ‰ìƒ ë§¤ì¹­ì´ ëœ í”„ë ˆì„ë§Œ í¬í•¨
                        if color_match_found:
                            frame_image_path = frame.get('frame_image_path', '')
                            actual_image_path = None
                            if frame_image_path:
                                # ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œ ìƒì„±
                                import os
                                from django.conf import settings
                                actual_image_path = os.path.join(settings.MEDIA_ROOT, frame_image_path)
                                if os.path.exists(actual_image_path):
                                    print(f"âœ… ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬: {actual_image_path}")
                                else:
                                    print(f"âŒ ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {actual_image_path}")
                            
                            frame_info = {
                                'image_id': frame.get('image_id', 0),
                                'timestamp': frame.get('timestamp', 0),
                                'frame_image_path': frame_image_path,
                                'image_url': f'/media/{frame_image_path}',
                                'actual_image_path': actual_image_path,  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
                                'persons': persons,
                                'objects': frame.get('objects', []),
                                'scene_attributes': frame.get('scene_attributes', {}),
                                'dominant_colors': dominant_colors,  # ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                                'relevance_score': 2,  # ìƒ‰ìƒ ë§¤ì¹­ ì‹œ ë†’ì€ ì ìˆ˜
                                'color_search_info': {
                                    'requested_colors': detected_colors,
                                    'color_info_available': len(dominant_colors) > 0,
                                    'color_match_found': color_match_found,
                                    'actual_image_available': actual_image_path is not None,
                                    'message': f"ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼: {dominant_colors} | ìš”ì²­í•˜ì‹  ìƒ‰ìƒ: {', '.join(detected_colors)}"
                                }
                            }
                            relevant_frames.append(frame_info)
                            print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ìƒ‰ìƒ ë§¤ì¹­ ì„±ê³µ)")
                        else:
                            print(f"âŒ í”„ë ˆì„ {frame.get('image_id', 0)}: ìƒ‰ìƒ ë§¤ì¹­ ì‹¤íŒ¨ - {detected_colors} vs {dominant_colors}")
                
                else:
                    print("ğŸ¨ ìƒ‰ìƒ í‚¤ì›Œë“œ ê°ì§€ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                    # ìƒ‰ìƒ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  í”„ë ˆì„ í¬í•¨
                    for frame in frame_results:
                        persons = frame.get('persons', [])
                        if persons:  # ì‚¬ëŒì´ ìˆëŠ” í”„ë ˆì„ë§Œ
                            frame_info = {
                                'image_id': frame.get('image_id', 0),
                                'timestamp': frame.get('timestamp', 0),
                                'frame_image_path': frame.get('frame_image_path', ''),
                                'image_url': f'/media/{frame.get("frame_image_path", "")}',
                                'persons': persons,
                                'objects': frame.get('objects', []),
                                'scene_attributes': frame.get('scene_attributes', {}),
                                'relevance_score': len(persons)
                            }
                            relevant_frames.append(frame_info)
                            print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì¼ë°˜ ê²€ìƒ‰, ì‚¬ëŒ {len(persons)}ëª…)")
            
            elif intent == 'person_search':
                print("ğŸ‘¤ ì‚¬ëŒ ê²€ìƒ‰ ëª¨ë“œ")
                print(f"ğŸ” ê²€ìƒ‰í•  í”„ë ˆì„ ìˆ˜: {len(frame_results)}")
                for frame in frame_results:
                    persons = frame.get('persons', [])
                    print(f"ğŸ” í”„ë ˆì„ {frame.get('image_id', 0)}: persons = {persons}")
                    # ì‚¬ëŒì´ ê°ì§€ëœ í”„ë ˆì„ë§Œ í¬í•¨
                    if persons and len(persons) > 0:
                        frame_info = {
                            'image_id': frame.get('image_id', 0),
                            'timestamp': frame.get('timestamp', 0),
                            'frame_image_path': frame.get('frame_image_path', ''),
                            'image_url': f'/media/{frame.get("frame_image_path", "")}',
                            'persons': persons,
                            'objects': frame.get('objects', []),
                            'scene_attributes': frame.get('scene_attributes', {}),
                            'relevance_score': len(persons) * 2  # ì‚¬ëŒ ìˆ˜ì— ë¹„ë¡€í•œ ì ìˆ˜
                        }
                        relevant_frames.append(frame_info)
                        print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì‚¬ëŒ {len(persons)}ëª… ê°ì§€)")
                        print(f"âœ… í”„ë ˆì„ ìƒì„¸ ì •ë³´: {frame_info}")
                    else:
                        print(f"âŒ í”„ë ˆì„ {frame.get('image_id', 0)}: ì‚¬ëŒ ê°ì§€ ì•ˆë¨")
            
            elif intent == 'video_summary':
                print("ğŸ“‹ ìš”ì•½ ëª¨ë“œ - ì£¼ìš” í”„ë ˆì„ ì„ íƒ")
                # í™œë™ ìˆ˜ì¤€ì´ ë†’ì€ í”„ë ˆì„ ìš°ì„  ì„ íƒ
                frame_scores = []
                for frame in frame_results:
                    scene_attrs = frame.get('scene_attributes', {})
                    activity_level = scene_attrs.get('activity_level', 'low')
                    person_count = len(frame.get('persons', []))
                    
                    score = 0
                    if activity_level == 'high':
                        score += 3
                    elif activity_level == 'medium':
                        score += 2
                    else:
                        score += 1
                    
                    score += min(person_count, 3)  # ì‚¬ëŒ ìˆ˜ì— ë”°ë¥¸ ì ìˆ˜
                    frame_scores.append((frame, score))
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í”„ë ˆì„ ì„ íƒ
                frame_scores.sort(key=lambda x: x[1], reverse=True)
                for frame, score in frame_scores[:3]:
                    frame_info = {
                        'image_id': frame.get('image_id', 0),
                        'timestamp': frame.get('timestamp', 0),
                        'frame_image_path': frame.get('frame_image_path', ''),
                        'image_url': f'/media/{frame.get("frame_image_path", "")}',
                        'persons': frame.get('persons', []),
                        'objects': frame.get('objects', []),
                        'scene_attributes': frame.get('scene_attributes', {}),
                        'relevance_score': score
                    }
                    relevant_frames.append(frame_info)
                    print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ìš”ì•½ìš©, ì ìˆ˜: {score})")
            
            elif intent == 'temporal_analysis':
                print("â° ì‹œê°„ëŒ€ ë¶„ì„ ëª¨ë“œ")
                # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
                time_range = self._parse_time_range(message)
                if time_range:
                    start_time, end_time = time_range
                    print(f"â° ì‹œê°„ ë²”ìœ„: {start_time}ì´ˆ ~ {end_time}ì´ˆ")
                    for frame in frame_results:
                        timestamp = frame.get('timestamp', 0)
                        if start_time <= timestamp <= end_time:
                            frame_info = {
                                'image_id': frame.get('image_id', 0),
                                'timestamp': frame.get('timestamp', 0),
                                'frame_image_path': frame.get('frame_image_path', ''),
                                'image_url': f'/media/{frame.get("frame_image_path", "")}',
                                'persons': frame.get('persons', []),
                                'objects': frame.get('objects', []),
                                'scene_attributes': frame.get('scene_attributes', {}),
                                'relevance_score': 1
                            }
                            relevant_frames.append(frame_info)
                            print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì‹œê°„ëŒ€: {timestamp}ì´ˆ)")
                else:
                    # ì‹œê°„ ë²”ìœ„ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì „ì²´ í”„ë ˆì„
                    relevant_frames = [{
                        'image_id': frame.get('image_id', 0),
                        'timestamp': frame.get('timestamp', 0),
                        'frame_image_path': frame.get('frame_image_path', ''),
                        'image_url': f'/media/{frame.get("frame_image_path", "")}',
                        'persons': frame.get('persons', []),
                        'objects': frame.get('objects', []),
                        'scene_attributes': frame.get('scene_attributes', {}),
                        'relevance_score': 1
                    } for frame in frame_results]
                    print(f"âœ… ì‹œê°„ ë²”ìœ„ íŒŒì‹± ì‹¤íŒ¨ - ì „ì²´ í”„ë ˆì„ {len(relevant_frames)}ê°œ ì„ íƒ")
            
            else:
                print("ğŸ“‹ ì¼ë°˜ ê²€ìƒ‰ ëª¨ë“œ")
                # ì²˜ìŒ 2ê°œ í”„ë ˆì„ ì„ íƒ
                for frame in frame_results[:2]:
                    frame_info = {
                        'image_id': frame.get('image_id', 0),
                        'timestamp': frame.get('timestamp', 0),
                        'frame_image_path': frame.get('frame_image_path', ''),
                        'image_url': f'/media/{frame.get("frame_image_path", "")}',
                        'persons': frame.get('persons', []),
                        'objects': frame.get('objects', []),
                        'scene_attributes': frame.get('scene_attributes', {}),
                        'relevance_score': 1
                    }
                    relevant_frames.append(frame_info)
                    print(f"âœ… í”„ë ˆì„ {frame_info['image_id']} ì¶”ê°€ (ì¼ë°˜ ê²€ìƒ‰)")
            
            # ê´€ë ¨ë„ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
            relevant_frames.sort(key=lambda x: x['relevance_score'], reverse=True)
            result = relevant_frames[:3]
            print(f"ğŸ¯ ìµœì¢… ì„ íƒëœ í”„ë ˆì„ ìˆ˜: {len(result)}")
            print(f"ğŸ¯ ìµœì¢… í”„ë ˆì„ ìƒì„¸: {result}")
            return result
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _handle_special_commands(self, message, video_id):
        """íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬ (ìš”ì•½, í•˜ì´ë¼ì´íŠ¸)"""
        try:
            message_lower = message.lower().strip()
            
            # ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´
            if any(keyword in message_lower for keyword in ['ìš”ì•½', 'summary', 'ì˜ìƒ ìš”ì•½', 'ì˜ìƒ ìš”ì•½í•´ì¤˜', 'ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ì•Œë ¤ì¤˜']):
                return self._handle_video_summary_command(message_lower, video_id)
            
            # ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì£¼ìš” ì¥ë©´', 'ì¤‘ìš”í•œ ì¥ë©´']):
                return self._handle_video_highlight_command(message_lower, video_id)
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def _handle_video_summary_command(self, message, video_id):
        """ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        try:
            # ìš”ì•½ íƒ€ì… ê²°ì •
            summary_type = 'comprehensive'
            if 'ê°„ë‹¨' in message or 'brief' in message:
                summary_type = 'brief'
            elif 'ìƒì„¸' in message or 'detailed' in message:
                summary_type = 'detailed'
            
            # VideoSummaryView ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ìš”ì•½ ìƒì„±
            summary_view = VideoSummaryView()
            summary_result = summary_view._generate_video_summary(
                Video.objects.get(id=video_id), 
                summary_type
            )
            
            if summary_result and summary_result.get('summary'):
                return f"ğŸ“ **ì˜ìƒ ìš”ì•½** ({summary_type})\n\n{summary_result['summary']}"
            else:
                return "âŒ ì˜ìƒ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜ìƒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _handle_video_highlight_command(self, message, video_id):
        """ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        try:
            # í•˜ì´ë¼ì´íŠ¸ ê¸°ì¤€ ì„¤ì •
            criteria = {
                'min_score': 2.0,
                'max_highlights': 5
            }
            
            if 'ë§ì´' in message or 'more' in message:
                criteria['max_highlights'] = 10
            elif 'ì ê²Œ' in message or 'few' in message:
                criteria['max_highlights'] = 3
            
            # VideoHighlightView ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
            highlight_view = VideoHighlightView()
            highlights = highlight_view._extract_highlights(
                Video.objects.get(id=video_id), 
                criteria
            )
            
            if highlights:
                highlight_text = "ğŸ¬ **ì˜ìƒ í•˜ì´ë¼ì´íŠ¸**\n\n"
                for i, highlight in enumerate(highlights, 1):
                    highlight_text += f"{i}. **{highlight['timestamp']:.1f}ì´ˆ** - {highlight['description']}\n"
                    highlight_text += f"   - ì¤‘ìš”ë„: {highlight['significance']} (ì ìˆ˜: {highlight['score']:.1f})\n"
                    highlight_text += f"   - ì¸ì›: {highlight['person_count']}ëª…, ì¥ë©´: {highlight['scene_type']}\n\n"
                
                return highlight_text
            else:
                return "âŒ í•˜ì´ë¼ì´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

class FrameImageView(APIView):
    """í”„ë ˆì„ ì´ë¯¸ì§€ ì„œë¹™"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            from django.conf import settings
            # í”„ë ˆì„ ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„±
            frame_filename = f"video{video_id}_frame{frame_number}.jpg"
            frame_path = os.path.join(settings.MEDIA_ROOT, 'images', frame_filename)
            
            # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if not os.path.exists(frame_path):
                raise Http404("í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
            with open(frame_path, 'rb') as f:
                image_data = f.read()
            
            # HTTP ì‘ë‹µìœ¼ë¡œ ì´ë¯¸ì§€ ë°˜í™˜
            response = HttpResponse(image_data, content_type='image/jpeg')
            response['Content-Disposition'] = f'inline; filename="{frame_filename}"'
            return response
            
        except Exception as e:
            return Response({
                'error': f'í”„ë ˆì„ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_404_NOT_FOUND)


class VideoSummaryView(APIView):
    """ì˜ìƒ ìš”ì•½ ê¸°ëŠ¥"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            summary_type = request.data.get('summary_type', 'comprehensive')  # comprehensive, brief, detailed
            
            logger.info(f"ğŸ“ ì˜ìƒ ìš”ì•½ ìš”ì²­: ë¹„ë””ì˜¤={video_id}, íƒ€ì…={summary_type}")
            
            if not video_id:
                return Response({'error': 'ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}, status=400)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
            
            # ì˜ìƒ ìš”ì•½ ìƒì„±
            summary_result = self._generate_video_summary(video, summary_type)
            
            return Response({
                'video_id': video_id,
                'video_name': video.original_name,
                'summary_type': summary_type,
                'summary_result': summary_result,
                'analysis_type': 'video_summary'
            })
            
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _generate_video_summary(self, video, summary_type):
        """ì˜ìƒ ìš”ì•½ ìƒì„±"""
        try:
            # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ì½ê¸°
            if not video.analysis_json_path:
                return {
                    'summary': 'ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.',
                    'key_events': [],
                    'statistics': {},
                    'duration': video.duration,
                    'frame_count': 0
                }
            
            json_path = os.path.join(settings.MEDIA_ROOT, video.analysis_json_path)
            if not os.path.exists(json_path):
                return {
                    'summary': 'ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'key_events': [],
                    'statistics': {},
                    'duration': video.duration,
                    'frame_count': 0
                }
            
            with open(json_path, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            # ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘
            statistics = self._collect_video_statistics(video, analysis_data)
            
            # í‚¤ ì´ë²¤íŠ¸ ì¶”ì¶œ
            key_events = self._extract_key_events(analysis_data)
            
            # ìš”ì•½ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            if summary_type == 'brief':
                summary_text = self._generate_brief_summary(statistics, key_events)
            elif summary_type == 'detailed':
                summary_text = self._generate_detailed_summary(statistics, key_events, analysis_data)
            else:  # comprehensive
                summary_text = self._generate_comprehensive_summary(statistics, key_events, analysis_data)
            
            return {
                'summary': summary_text,
                'key_events': key_events,
                'statistics': statistics,
                'duration': video.duration,
                'frame_count': len(analysis_data.get('frame_results', [])),
                'summary_type': summary_type
            }
            
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'summary': f'ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
                'key_events': [],
                'statistics': {},
                'duration': video.duration,
                'frame_count': 0
            }
    
    def _collect_video_statistics(self, video, analysis_data):
        """ì˜ìƒ í†µê³„ ìˆ˜ì§‘ - ğŸ’¡í•µì‹¬ ì¸ì‚¬ì´íŠ¸ í¬í•¨"""
        try:
            video_summary = analysis_data.get('video_summary', {})
            frame_results = analysis_data.get('frame_results', [])
            
            # ê¸°ë³¸ í†µê³„
            stats = {
                'total_duration': video.duration,
                'total_frames': len(frame_results),
                'total_detections': video_summary.get('total_detections', 0),
                'unique_persons': video_summary.get('unique_persons', 0),
                'quality_score': video_summary.get('quality_assessment', {}).get('overall_score', 0),
                'scene_diversity': video_summary.get('scene_diversity', {}).get('diversity_score', 0)
            }
            
            # ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„ì„
            temporal_analysis = video_summary.get('temporal_analysis', {})
            stats.update({
                'peak_time': temporal_analysis.get('peak_time_seconds', 0),
                'peak_person_count': temporal_analysis.get('peak_person_count', 0),
                'average_person_count': temporal_analysis.get('average_person_count', 0)
            })
            
            # ì¥ë©´ íŠ¹ì„± ë¶„ì„
            scene_distribution = video_summary.get('scene_diversity', {})
            stats.update({
                'scene_types': scene_distribution.get('scene_type_distribution', {}),
                'activity_levels': scene_distribution.get('activity_level_distribution', {}),
                'lighting_types': scene_distribution.get('lighting_distribution', {})
            })
            
            # ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            stats['key_insights'] = self._generate_key_insights_for_summary(stats, frame_results)
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def _generate_key_insights_for_summary(self, stats, frame_results):
        """ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± (ì˜ìƒ ìš”ì•½ìš©)"""
        insights = []
        
        try:
            # 1. ì¸ì› êµ¬ì„± ì¸ì‚¬ì´íŠ¸
            person_count = stats.get('unique_persons', 0)
            peak_count = stats.get('peak_person_count', 0)
            
            if person_count > 0:
                if peak_count > 5:
                    insights.append(f"ë‹¤ìˆ˜ ì¸ì› ë“±ì¥ (ìµœëŒ€ {peak_count}ëª… ë™ì‹œ ë“±ì¥)")
                elif peak_count > 2:
                    insights.append(f"ì†Œê·œëª¨ ê·¸ë£¹ í™œë™ ({peak_count}ëª…)")
                else:
                    insights.append(f"ì†Œìˆ˜ ì¸ì› ì˜ìƒ ({person_count}ëª…)")
            
            # 2. ì˜ìƒ ê¸¸ì´ ì¸ì‚¬ì´íŠ¸
            duration = stats.get('total_duration', 0)
            if duration > 300:  # 5ë¶„ ì´ìƒ
                insights.append(f"ê¸´ ì˜ìƒ ({duration/60:.1f}ë¶„)")
            elif duration > 60:
                insights.append(f"ì¤‘ê°„ ê¸¸ì´ ì˜ìƒ ({duration/60:.1f}ë¶„)")
            else:
                insights.append(f"ì§§ì€ ì˜ìƒ ({duration:.0f}ì´ˆ)")
            
            # 3. í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸
            quality_score = stats.get('quality_score', 0)
            if quality_score > 0.8:
                insights.append(f"ë†’ì€ í’ˆì§ˆ (ì ìˆ˜: {quality_score:.2f})")
            elif quality_score > 0.6:
                insights.append(f"ì–‘í˜¸í•œ í’ˆì§ˆ (ì ìˆ˜: {quality_score:.2f})")
            elif quality_score > 0:
                insights.append(f"ë³´í†µ í’ˆì§ˆ (ì ìˆ˜: {quality_score:.2f})")
            
            # 4. ì¥ë©´ ë‹¤ì–‘ì„± ì¸ì‚¬ì´íŠ¸
            scene_types = stats.get('scene_types', {})
            if len(scene_types) > 3:
                insights.append(f"ë‹¤ì–‘í•œ ì¥ë©´ í¬í•¨ ({len(scene_types)}ê°€ì§€ ì¥ì†Œ)")
            elif len(scene_types) > 0:
                main_scenes = list(scene_types.keys())[:2]
                insights.append(f"ì£¼ìš” ì¥ì†Œ: {', '.join(main_scenes)}")
            
            # 5. í™œë™ ìˆ˜ì¤€ ì¸ì‚¬ì´íŠ¸
            activity_levels = stats.get('activity_levels', {})
            if 'high' in activity_levels:
                insights.append(f"í™œë°œí•œ í™œë™ ê°ì§€")
            elif 'medium' in activity_levels:
                insights.append(f"ì¤‘ê°„ ìˆ˜ì¤€ í™œë™")
            
            return insights[:5]  # ìµœëŒ€ 5ê°œ ì¸ì‚¬ì´íŠ¸
            
        except Exception as e:
            logger.error(f"âŒ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return ["ì˜ìƒ ë¶„ì„ ì™„ë£Œ"]
    
    def _extract_key_events(self, analysis_data):
        """í‚¤ ì´ë²¤íŠ¸ ì¶”ì¶œ"""
        try:
            key_events = []
            frame_results = analysis_data.get('frame_results', [])
            
            # ì‚¬ëŒ ìˆ˜ê°€ ë§ì€ ì¥ë©´ë“¤ì„ í‚¤ ì´ë²¤íŠ¸ë¡œ ì„ ì •
            for frame in frame_results:
                person_count = len(frame.get('persons', []))
                if person_count >= 2:  # 2ëª… ì´ìƒì´ ìˆëŠ” ì¥ë©´
                    key_events.append({
                        'timestamp': frame.get('timestamp', 0),
                        'description': f"{person_count}ëª…ì´ ê°ì§€ëœ ì¥ë©´",
                        'person_count': person_count,
                        'scene_type': frame.get('scene_attributes', {}).get('scene_type', 'unknown'),
                        'activity_level': frame.get('scene_attributes', {}).get('activity_level', 'medium')
                    })
            
            # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
            key_events.sort(key=lambda x: x['timestamp'])
            
            return key_events[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ ì´ë²¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _generate_brief_summary(self, statistics, key_events):
        """ê°„ë‹¨ ìš”ì•½ (1-2ë¬¸ì¥, ğŸ’¡í•µì‹¬ë§Œ ê°•ì¡°)"""
        try:
            duration = statistics.get('total_duration', 0)
            duration_min = duration / 60
            person_count = statistics.get('unique_persons', 0)
            key_insights = statistics.get('key_insights', [])
            
            # ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ 1ê°œ + ê¸°ë³¸ ì •ë³´
            main_insight = key_insights[0] if key_insights else "ì˜ìƒ ë¶„ì„ ì™„ë£Œ"
            
            return f"ğŸ’¡ {main_insight}. ì˜ìƒ ê¸¸ì´ {duration_min:.1f}ë¶„, ì´ {person_count}ëª… ë“±ì¥."
            
        except Exception as e:
            logger.error(f"âŒ ê°„ë‹¨ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_detailed_summary(self, statistics, key_events, analysis_data):
        """ìƒì„¸ ìš”ì•½ (ë¬¸ë‹¨ í˜•ì‹, ğŸ’¡í•µì‹¬ 3ê°œ + ì£¼ìš” ì´ë²¤íŠ¸)"""
        try:
            duration = statistics.get('total_duration', 0)
            duration_min = duration / 60
            person_count = statistics.get('unique_persons', 0)
            peak_count = statistics.get('peak_person_count', 0)
            key_insights = statistics.get('key_insights', [])
            
            parts = [
                f"ğŸ“¹ ì´ ì˜ìƒì€ {duration_min:.1f}ë¶„ ê¸¸ì´ë¡œ, ì´ {person_count}ëª…ì´ ë“±ì¥í•©ë‹ˆë‹¤.",
                "\nğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸:",
                *[f"  â€¢ {insight}" for insight in key_insights[:3]]
            ]
            
            # ì£¼ìš” ì´ë²¤íŠ¸ 3ê°œ
            if key_events:
                parts.append("\nâ±ï¸ ì£¼ìš” ì¥ë©´:")
                for i, event in enumerate(key_events[:3], 1):
                    timestamp = event.get('timestamp', 0)
                    time_str = f"{int(timestamp//60)}:{int(timestamp%60):02d}"
                    desc = event.get('description', 'ì¥ë©´')[:50]
                    parts.append(f"  {i}. [{time_str}] {desc}")
            
            # í’ˆì§ˆ ì •ë³´
            quality_score = statistics.get('quality_score', 0)
            if quality_score > 0:
                quality_status = "ìš°ìˆ˜" if quality_score > 0.8 else "ì–‘í˜¸" if quality_score > 0.6 else "ë³´í†µ"
                parts.append(f"\nğŸ¯ ì˜ìƒ í’ˆì§ˆ: {quality_status} ({quality_score:.2f}/1.0)")
            
            # ì¥ë©´ ìœ í˜•
            scene_types = statistics.get('scene_types', {})
            if scene_types:
                scene_list = [f"{k}({v})" for k, v in list(scene_types.items())[:3]]
                parts.append(f"\nğŸ¬ ì¥ë©´ ìœ í˜•: {', '.join(scene_list)}")
            
            return "\n".join(parts)
            
        except Exception as e:
            logger.error(f"âŒ ìƒì„¸ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ìƒì„¸ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_comprehensive_summary(self, statistics, key_events, analysis_data):
        """ì¢…í•© ìš”ì•½ (ì „ì²´ ë¶„ì„, ğŸ’¡í•µì‹¬ 5ê°œ + ëª¨ë“  ì´ë²¤íŠ¸ + í†µê³„)"""
        try:
            duration = statistics.get('total_duration', 0)
            duration_min = duration / 60
            person_count = statistics.get('unique_persons', 0)
            peak_count = statistics.get('peak_person_count', 0)
            key_insights = statistics.get('key_insights', [])
            
            parts = [
                f"ğŸ“¹ ì˜ìƒ ì •ë³´",
                f"  â€¢ ê¸¸ì´: {duration_min:.1f}ë¶„",
                f"  â€¢ ë“±ì¥ ì¸ì›: {person_count}ëª…",
                f"  â€¢ ë¶„ì„ í”„ë ˆì„: {statistics.get('total_frames', 0)}ê°œ",
                f"  â€¢ ì´ ê°ì§€ ê°ì²´: {statistics.get('total_detections', 0)}ê°œ",
                "\nğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ì „ì²´)"
            ]
            
            # ì „ì²´ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ìµœëŒ€ 5ê°œ)
            parts.extend([f"  â€¢ {insight}" for insight in key_insights[:5]])
            
            # ì£¼ìš” ì´ë²¤íŠ¸ ì „ì²´ (ìµœëŒ€ 8ê°œ)
            if key_events:
                parts.append("\nâ±ï¸ ì£¼ìš” ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸:")
                for i, event in enumerate(key_events[:8], 1):
                    timestamp = event.get('timestamp', 0)
                    time_str = f"{int(timestamp//60)}:{int(timestamp%60):02d}"
                    desc = event.get('description', 'ì¥ë©´')[:60]
                    person_cnt = event.get('person_count', 0)
                    activity = event.get('activity_level', 'medium')
                    emoji = "ğŸ”´" if activity == 'high' else "ğŸŸ¡" if activity == 'medium' else "ğŸŸ¢"
                    parts.append(f"  {emoji} {i}. [{time_str}] {desc} ({person_cnt}ëª…)")
            
            # ìƒì„¸ í†µê³„
            parts.append("\nğŸ“Š ìƒì„¸ í†µê³„:")
            parts.append(f"  â€¢ ìµœëŒ€ ë™ì‹œ ì¸ì›: {peak_count}ëª…")
            parts.append(f"  â€¢ í‰ê·  ë™ì‹œ ì¸ì›: {statistics.get('average_person_count', 0):.1f}ëª…")
            
            # í’ˆì§ˆ ì •ë³´
            quality_score = statistics.get('quality_score', 0)
            if quality_score > 0:
                quality_status = "ìš°ìˆ˜" if quality_score > 0.8 else "ì–‘í˜¸" if quality_score > 0.6 else "ë³´í†µ"
                parts.append(f"  â€¢ ì˜ìƒ í’ˆì§ˆ: {quality_status} ({quality_score:.2f}/1.0)")
            
            # ì¥ë©´ ë¶„ì„
            scene_types = statistics.get('scene_types', {})
            if scene_types:
                scene_list = ', '.join([f"{k}({v})" for k, v in list(scene_types.items())[:5]])
                parts.append(f"  â€¢ ì¥ë©´ ìœ í˜•: {scene_list}")
            
            activity_levels = statistics.get('activity_levels', {})
            if activity_levels:
                activity_list = ', '.join([f"{k}({v})" for k, v in activity_levels.items()])
                parts.append(f"  â€¢ í™œë™ ìˆ˜ì¤€: {activity_list}")
            
            lighting_types = statistics.get('lighting_types', {})
            if lighting_types:
                lighting_list = ', '.join([f"{k}({v})" for k, v in lighting_types.items()])
                parts.append(f"  â€¢ ì¡°ëª… ìƒíƒœ: {lighting_list}")
            
            # ë‹¤ì–‘ì„± ì ìˆ˜
            diversity = statistics.get('scene_diversity', 0)
            if diversity > 0:
                parts.append(f"  â€¢ ì¥ë©´ ë‹¤ì–‘ì„±: {diversity:.2f}/1.0")
            
            return "\n".join(parts)
            
        except Exception as e:
            logger.error(f"âŒ ì¢…í•© ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì¢…í•© ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


class VideoHighlightView(APIView):
    """ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ìë™ ì¶”ì¶œ"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            highlight_criteria = request.data.get('criteria', {})
            
            logger.info(f"ğŸ¬ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ ìš”ì²­: ë¹„ë””ì˜¤={video_id}, ê¸°ì¤€={highlight_criteria}")
            
            if not video_id:
                return Response({'error': 'ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}, status=400)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
            
            # í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
            highlights = self._extract_highlights(video, highlight_criteria)
            
            return Response({
                'video_id': video_id,
                'video_name': video.original_name,
                'highlights': highlights,
                'total_highlights': len(highlights),
                'analysis_type': 'video_highlights'
            })
            
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _extract_highlights(self, video, criteria):
        """í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ"""
        try:
            # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ì½ê¸°
            if not video.analysis_json_path:
                return []
            
            json_path = os.path.join(settings.MEDIA_ROOT, video.analysis_json_path)
            if not os.path.exists(json_path):
                return []
            
            with open(json_path, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            frame_results = analysis_data.get('frame_results', [])
            if not frame_results:
                return []
            
            # í”„ë ˆì„ë³„ ì ìˆ˜ ê³„ì‚°
            scored_frames = self._score_frames(frame_results, criteria)
            
            # í•˜ì´ë¼ì´íŠ¸ ìƒì„±
            highlights = self._create_highlights(scored_frames, criteria)
            
            return highlights
            
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _score_frames(self, frame_results, criteria):
        """í”„ë ˆì„ë³„ ì ìˆ˜ ê³„ì‚°"""
        try:
            scored_frames = []
            
            for frame in frame_results:
                score = 0.0
                
                # ì‚¬ëŒ ìˆ˜ ì ìˆ˜ (ë” ë§ì€ ì‚¬ëŒ = ë” ë†’ì€ ì ìˆ˜)
                person_count = len(frame.get('persons', []))
                if person_count > 0:
                    score += person_count * 0.5
                
                # í’ˆì§ˆ ì ìˆ˜
                quality_score = self._get_quality_score(frame)
                score += quality_score * 0.3
                
                # í™œë™ ìˆ˜ì¤€ ì ìˆ˜
                activity_level = frame.get('scene_attributes', {}).get('activity_level', 'medium')
                if activity_level == 'high':
                    score += 1.0
                elif activity_level == 'medium':
                    score += 0.5
                
                # ì¥ë©´ ë‹¤ì–‘ì„± ì ìˆ˜
                scene_type = frame.get('scene_attributes', {}).get('scene_type', 'unknown')
                if scene_type in ['detailed', 'complex']:
                    score += 0.3
                
                # ì‹ ë¢°ë„ ì ìˆ˜
                avg_confidence = self._get_average_confidence(frame)
                score += avg_confidence * 0.2
                
                scored_frames.append({
                    'frame': frame,
                    'frame_id': frame.get('image_id', 0),
                    'timestamp': frame.get('timestamp', 0),
                    'score': score
                })
            
            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            scored_frames.sort(key=lambda x: x['score'], reverse=True)
            
            return scored_frames
            
        except Exception as e:
            logger.error(f"âŒ í”„ë ˆì„ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []
    
    def _get_quality_score(self, frame):
        """í”„ë ˆì„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ê°€ëŠ¥)
            persons = frame.get('persons', [])
            if not persons:
                return 0.0
            
            # í‰ê·  ì‹ ë¢°ë„ ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜
            confidences = [person.get('confidence', 0) for person in persons]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            return avg_confidence
            
        except Exception as e:
            logger.error(f"âŒ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _get_average_confidence(self, frame):
        """í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            persons = frame.get('persons', [])
            if not persons:
                return 0.0
            
            confidences = [person.get('confidence', 0) for person in persons]
            return sum(confidences) / len(confidences) if confidences else 0
            
        except Exception as e:
            logger.error(f"âŒ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _create_highlights(self, scored_frames, criteria):
        """í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""
        try:
            highlights = []
            min_score = criteria.get('min_score', 2.0)  # ìµœì†Œ ì ìˆ˜
            max_highlights = criteria.get('max_highlights', 10)  # ìµœëŒ€ í•˜ì´ë¼ì´íŠ¸ ìˆ˜
            
            # ì ìˆ˜ ê¸°ì¤€ í•„í„°ë§
            filtered_frames = [f for f in scored_frames if f['score'] >= min_score]
            
            # ì‹œê°„ ê°„ê²©ì„ ê³ ë ¤í•œ í•˜ì´ë¼ì´íŠ¸ ì„ íƒ
            selected_highlights = []
            last_timestamp = -10  # ìµœì†Œ 10ì´ˆ ê°„ê²©
            
            for frame_data in filtered_frames[:max_highlights * 2]:  # ì—¬ìœ ë¶„ì„ ë‘ê³  ì„ íƒ
                if frame_data['timestamp'] - last_timestamp >= 10:  # 10ì´ˆ ì´ìƒ ê°„ê²©
                    selected_highlights.append(frame_data)
                    last_timestamp = frame_data['timestamp']
                    
                    if len(selected_highlights) >= max_highlights:
                        break
            
            # í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ìƒì„±
            for i, frame_data in enumerate(selected_highlights):
                frame = frame_data['frame']
                highlight = {
                    'id': i + 1,
                    'timestamp': frame_data['timestamp'],
                    'frame_id': frame_data['frame_id'],
                    'score': frame_data['score'],
                    'description': self._generate_highlight_description(frame),
                    'person_count': len(frame.get('persons', [])),
                    'thumbnail_url': f'/api/frame/{frame.get("video_id", 0)}/{frame_data["frame_id"]}/',
                    'significance': self._get_significance_level(frame_data['score']),
                    'scene_type': frame.get('scene_attributes', {}).get('scene_type', 'unknown'),
                    'activity_level': frame.get('scene_attributes', {}).get('activity_level', 'medium')
                }
                highlights.append(highlight)
            
            return highlights
            
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return []
    
    def _generate_highlight_description(self, frame):
        """í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„±"""
        try:
            persons = frame.get('persons', [])
            person_count = len(persons)
            
            if person_count == 0:
                return "ì£¼ìš” ì¥ë©´"
            elif person_count == 1:
                return "1ëª…ì´ ë“±ì¥í•˜ëŠ” ì¥ë©´"
            elif person_count <= 3:
                return f"{person_count}ëª…ì´ ë“±ì¥í•˜ëŠ” ì¥ë©´"
            else:
                return f"{person_count}ëª…ì´ ë“±ì¥í•˜ëŠ” í™œë°œí•œ ì¥ë©´"
                
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì£¼ìš” ì¥ë©´"
    
    def _get_significance_level(self, score):
        """ì¤‘ìš”ë„ ë ˆë²¨ ë°˜í™˜"""
        try:
            if score >= 4.0:
                return "ë§¤ìš° ë†’ìŒ"
            elif score >= 3.0:
                return "ë†’ìŒ"
            elif score >= 2.0:
                return "ë³´í†µ"
            else:
                return "ë‚®ìŒ"
                
        except Exception as e:
            logger.error(f"âŒ ì¤‘ìš”ë„ ë ˆë²¨ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return "ë³´í†µ"
    
    def _handle_special_commands(self, message, video_id):
        """íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬ (AIë³„ ê°œë³„ ë‹µë³€ ìƒì„±)"""
        try:
            message_lower = message.lower().strip()
            print(f"ğŸ” íŠ¹ë³„ ëª…ë ¹ì–´ ê²€ì‚¬: '{message_lower}'")
            
            # ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´
            if any(keyword in message_lower for keyword in ['ìš”ì•½', 'summary', 'ì˜ìƒ ìš”ì•½', 'ì˜ìƒ ìš”ì•½í•´ì¤˜', 'ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ì•Œë ¤ì¤˜', 'ê°„ë‹¨í•œ ìš”ì•½', 'ìƒì„¸í•œ ìš”ì•½']):
                print(f"âœ… ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ê°ì§€: '{message_lower}'")
                return self._handle_ai_generated_response(video_id, 'video_summary', message_lower)
            
            # ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì£¼ìš” ì¥ë©´', 'ì¤‘ìš”í•œ ì¥ë©´']):
                return self._handle_ai_generated_response(video_id, 'video_highlights', message_lower)
            
            # ì‚¬ëŒ ì°¾ê¸° ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['ì‚¬ëŒ ì°¾ì•„ì¤˜', 'ì‚¬ëŒ ì°¾ê¸°', 'ì¸ë¬¼ ê²€ìƒ‰', 'ì‚¬ëŒ ê²€ìƒ‰']):
                return self._handle_ai_generated_response(video_id, 'person_search', message_lower)
            
            # ì˜ìƒ ê°„ ê²€ìƒ‰ ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['ë¹„ê°€ì˜¤ëŠ” ë°¤', 'ë¹„ ì˜¤ëŠ” ë°¤', 'ë°¤ì— ì´¬ì˜', 'ì–´ë‘ìš´ ì˜ìƒ', 'ë¹„ ì˜¤ëŠ” ë‚ ']):
                return self._handle_ai_generated_response(video_id, 'inter_video_search', {'query': message_lower})
            
            # ì˜ìƒ ë‚´ ê²€ìƒ‰ ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['ì£¼í™©ìƒ‰ ìƒì˜', 'ì£¼í™© ì˜·', 'ì£¼í™©ìƒ‰ ì˜·', 'ì£¼í™© ìƒì˜', 'ì˜¤ë Œì§€ ì˜·']):
                return self._handle_ai_generated_response(video_id, 'intra_video_search', {'query': message_lower})
            
            # ì‹œê°„ëŒ€ë³„ ë¶„ì„ ëª…ë ¹ì–´
            elif any(keyword in message_lower for keyword in ['ì„±ë¹„ ë¶„í¬', 'ì„±ë³„ ë¶„í¬', 'ë‚¨ë…€ ë¹„ìœ¨', 'ì‹œê°„ëŒ€ë³„', '3ì‹œ', '5ì‹œ']):
                time_range = {'start': 180, 'end': 300}  # ê¸°ë³¸ê°’: 3ë¶„-5ë¶„
                return self._handle_ai_generated_response(video_id, 'temporal_analysis', {'time_range': time_range})
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def _handle_ai_generated_response(self, video_id, query_type, query_data=None):
        """AIë³„ ê°œë³„ ë‹µë³€ ìƒì„± ë° í†µí•©"""
        try:
            logger.info(f"ğŸ¤– AI ì‘ë‹µ ìƒì„± ì‹œì‘: video_id={video_id}, query_type={query_type}")
            
            # AI ì‘ë‹µ ìƒì„±
            ai_responses = ai_response_generator.generate_responses(video_id, query_type, query_data)
            
            if not ai_responses:
                return "âŒ AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            # ê°œë³„ AI ë‹µë³€ë“¤
            individual_responses = ai_responses.get('individual', {})
            optimal_response = ai_responses.get('optimal', '')
            
            # í†µí•© ì‘ë‹µ ìƒì„±
            response_text = f"## ğŸ¯ AI í†µí•© ë¶„ì„ ê²°ê³¼\n\n{optimal_response}\n\n"
            
            # ê° AIë³„ ë‹µë³€ ì¶”ê°€
            response_text += "## ğŸ“Š ê° AIë³„ ê°œë³„ ë¶„ì„\n\n"
            for ai_name, response in individual_responses.items():
                ai_display_name = {
                    'gpt': 'GPT-4o',
                    'claude': 'Claude-3.5-Sonnet', 
                    'mixtral': 'Mixtral-8x7B',
                    'gemini': 'Gemini-2.5-Flash'
                }.get(ai_name, ai_name.upper())
                
                response_text += f"### {ai_display_name}\n{response}\n\n"
            
            logger.info(f"âœ… AI ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response_text)}ì")
            return response_text
            
        except Exception as e:
            logger.error(f"âŒ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"âŒ AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _handle_video_summary_command(self, message, video_id):
        """ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        try:
            # ìš”ì•½ íƒ€ì… ê²°ì •
            summary_type = 'comprehensive'
            if 'ê°„ë‹¨' in message or 'brief' in message:
                summary_type = 'brief'
            elif 'ìƒì„¸' in message or 'detailed' in message:
                summary_type = 'detailed'
            
            # VideoSummaryView ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ìš”ì•½ ìƒì„±
            summary_view = VideoSummaryView()
            summary_result = summary_view._generate_video_summary(
                Video.objects.get(id=video_id), 
                summary_type
            )
            
            if summary_result and summary_result.get('summary'):
                return f"ğŸ“ **ì˜ìƒ ìš”ì•½** ({summary_type})\n\n{summary_result['summary']}"
            else:
                return "âŒ ì˜ìƒ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ ìš”ì•½ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜ìƒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _handle_video_highlight_command(self, message, video_id):
        """ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´ ì²˜ë¦¬"""
        try:
            # í•˜ì´ë¼ì´íŠ¸ ê¸°ì¤€ ì„¤ì •
            criteria = {
                'min_score': 2.0,
                'max_highlights': 5
            }
            
            if 'ë§ì´' in message or 'more' in message:
                criteria['max_highlights'] = 10
            elif 'ì ê²Œ' in message or 'few' in message:
                criteria['max_highlights'] = 3
            
            # VideoHighlightView ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
            highlight_view = VideoHighlightView()
            highlights = highlight_view._extract_highlights(
                Video.objects.get(id=video_id), 
                criteria
            )
            
            if highlights:
                highlight_text = "ğŸ¬ **ì˜ìƒ í•˜ì´ë¼ì´íŠ¸**\n\n"
                for i, highlight in enumerate(highlights, 1):
                    highlight_text += f"{i}. **{highlight['timestamp']:.1f}ì´ˆ** - {highlight['description']}\n"
                    highlight_text += f"   - ì¤‘ìš”ë„: {highlight['significance']} (ì ìˆ˜: {highlight['score']:.1f})\n"
                    highlight_text += f"   - ì¸ì›: {highlight['person_count']}ëª…, ì¥ë©´: {highlight['scene_type']}\n\n"
                
                return highlight_text
            else:
                return "âŒ í•˜ì´ë¼ì´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
        except Exception as e:
            logger.error(f"âŒ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ëª…ë ¹ì–´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
