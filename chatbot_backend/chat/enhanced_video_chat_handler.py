"""
ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ (ë²„ê·¸ ìˆ˜ì • ë²„ì „)
- Ollama ìº¡ì…˜ ê¸°ë°˜ ë‹µë³€
- ë‹¤ì¤‘ AI ëª¨ë¸ (GPT, Claude, Mixtral) í†µí•©
- ìƒ‰ìƒ 2ì¤‘ ê²€ì¦ (ìº¡ì…˜ + ì¶”ì¶œëœ ìƒ‰ìƒ)
- ì˜ìƒ/ì¼ë°˜ ì§ˆë¬¸ ìžë™ êµ¬ë¶„
- chatbots import ë¬¸ì œ í•´ê²°
- Ollama í•œêµ­ì–´ ì‘ë‹µ ê°•ì œ
"""

import os
import json
import logging
import re
import ollama
from django.conf import settings

logger = logging.getLogger(__name__)


def get_chatbots():
    """chatbots ì „ì—­ ë³€ìˆ˜ë¥¼ ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜ (lazy import)"""
    try:
        from .utils.chatbot import chatbots
        logger.info("âœ… chatbots import ì„±ê³µ")
        return chatbots
    except Exception as e:
        logger.warning(f"âš ï¸ chatbots import ì‹¤íŒ¨: {e}")
        return {}


class EnhancedVideoChatHandler:
    """ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬"""
    
    def __init__(self, video_id, video):
        self.video_id = video_id
        self.video = video
        self.meta_db = None
        self.detection_db = None
        self.frames = []
        self._load_analysis_data()
    
    def _load_analysis_data(self):
        """ì˜ìƒ ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            # Meta DB ë¡œë“œ (Ollama ìº¡ì…˜ í¬í•¨)
            # 1ìˆœìœ„: analysis_json_pathì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ
            meta_db_path = None
            media_dir = settings.MEDIA_ROOT
            
            if self.video.analysis_json_path:
                analysis_file = os.path.join(media_dir, self.video.analysis_json_path)
                if os.path.exists(analysis_file):
                    try:
                        with open(analysis_file, 'r', encoding='utf-8') as f:
                            analysis_data = json.load(f)
                            # video_summaryì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì°¾ê¸°
                            video_id_in_json = analysis_data.get('video_summary', {}).get('video_id')
                            if video_id_in_json:
                                test_path = os.path.join(media_dir, f"{video_id_in_json}-meta_db.json")
                                if os.path.exists(test_path):
                                    meta_db_path = test_path
                                    logger.info(f"âœ… analysis_jsonì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ì„±ê³µ: {video_id_in_json}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ analysis_json íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # 2ìˆœìœ„: filenameì—ì„œ íƒ€ìž„ìŠ¤íƒ¬í”„ ì œê±°í•˜ì—¬ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ
            if not meta_db_path and self.video.filename:
                # filename í˜•ì‹: upload_{timestamp}_{original_filename}
                # ì˜ˆ: upload_1762940209_upload_1758152157_test2.mp4
                filename_base = os.path.splitext(self.video.filename)[0]
                
                # upload_ë¡œ ì‹œìž‘í•˜ëŠ” ê²½ìš° íƒ€ìž„ìŠ¤íƒ¬í”„ ë¶€ë¶„ ì œê±° ì‹œë„
                if filename_base.startswith('upload_'):
                    # ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
                    # íŒ¨í„´ 1: upload_{timestamp}_upload_{original} -> upload_{original} (í™•ìž¥ìž í¬í•¨/ì œì™¸ ëª¨ë‘)
                    if '_upload_' in filename_base:
                        parts = filename_base.split('_upload_', 1)
                        if len(parts) == 2:
                            # í™•ìž¥ìž í¬í•¨ ë²„ì „ ë¨¼ì € ì‹œë„ (Meta DBëŠ” ì›ë³¸ íŒŒì¼ëª…ì— í™•ìž¥ìž í¬í•¨)
                            possible_original_with_ext = f"upload_{parts[1]}.mp4"
                            test_path = os.path.join(media_dir, f"{possible_original_with_ext}-meta_db.json")
                            if os.path.exists(test_path):
                                meta_db_path = test_path
                                logger.info(f"âœ… filenameì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ì„±ê³µ (íŒ¨í„´1-í™•ìž¥ìží¬í•¨): {possible_original_with_ext}")
                            
                            # í™•ìž¥ìž ì œì™¸ ë²„ì „
                            possible_original_no_ext = f"upload_{parts[1]}"
                            test_path = os.path.join(media_dir, f"{possible_original_no_ext}-meta_db.json")
                            if os.path.exists(test_path):
                                meta_db_path = test_path
                                logger.info(f"âœ… filenameì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ì„±ê³µ (íŒ¨í„´1-í™•ìž¥ìžì œì™¸): {possible_original_no_ext}")
                            
                            # í™•ìž¥ìž í¬í•¨ ë²„ì „ (ì›ë³¸ íŒŒì¼ëª…ì— .mp4ê°€ í¬í•¨ëœ ê²½ìš°)
                            if not meta_db_path:
                                possible_original_with_ext = f"upload_{parts[1]}.mp4"
                                test_path = os.path.join(media_dir, f"{possible_original_with_ext}-meta_db.json")
                                if os.path.exists(test_path):
                                    meta_db_path = test_path
                                    logger.info(f"âœ… filenameì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ì„±ê³µ (íŒ¨í„´1-í™•ìž¥ìží¬í•¨): {possible_original_with_ext}")
                    
                    # íŒ¨í„´ 2: upload_{timestamp}_{original} -> {original}
                    if not meta_db_path:
                        parts = filename_base.split('_', 2)  # ìµœëŒ€ 2ë²ˆë§Œ split
                        if len(parts) >= 3:
                            # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ì›ë³¸ íŒŒì¼ëª…ì¼ ê°€ëŠ¥ì„±
                            possible_original = parts[2]
                            # í™•ìž¥ìž ì œì™¸
                            test_path = os.path.join(media_dir, f"{possible_original}-meta_db.json")
                            if os.path.exists(test_path):
                                meta_db_path = test_path
                                logger.info(f"âœ… filenameì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ì„±ê³µ (íŒ¨í„´2-í™•ìž¥ìžì œì™¸): {possible_original}")
                            # í™•ìž¥ìž í¬í•¨
                            if not meta_db_path:
                                test_path = os.path.join(media_dir, f"{possible_original}.mp4-meta_db.json")
                                if os.path.exists(test_path):
                                    meta_db_path = test_path
                                    logger.info(f"âœ… filenameì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ ì„±ê³µ (íŒ¨í„´2-í™•ìž¥ìží¬í•¨): {possible_original}.mp4")
                
                # ì „ì²´ filenameë„ ì‹œë„ (í™•ìž¥ìž ì œì™¸/í¬í•¨)
                if not meta_db_path:
                    test_path = os.path.join(media_dir, f"{filename_base}-meta_db.json")
                    if os.path.exists(test_path):
                        meta_db_path = test_path
                        logger.info(f"âœ… filename ì „ì²´ë¡œ Meta DB ë°œê²¬ (í™•ìž¥ìžì œì™¸): {filename_base}")
                    else:
                        # í™•ìž¥ìž í¬í•¨
                        test_path = os.path.join(media_dir, f"{self.video.filename}-meta_db.json")
                        if os.path.exists(test_path):
                            meta_db_path = test_path
                            logger.info(f"âœ… filename ì „ì²´ë¡œ Meta DB ë°œê²¬ (í™•ìž¥ìží¬í•¨): {self.video.filename}")
            
            # 3ìˆœìœ„: original_name ì‹œë„ (ì´ë¦„ ë³€ê²½ ì „ ì›ë³¸ì¼ ìˆ˜ ìžˆìŒ)
            if not meta_db_path and self.video.original_name:
                original_base = os.path.splitext(self.video.original_name)[0]
                test_path = os.path.join(media_dir, f"{original_base}-meta_db.json")
                if os.path.exists(test_path):
                    meta_db_path = test_path
                    logger.info(f"âœ… original_nameìœ¼ë¡œ Meta DB ë°œê²¬: {original_base}")
            
            # 4ìˆœìœ„: media ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  meta_db íŒŒì¼ ê²€ìƒ‰ (video_id ê¸°ë°˜)
            if not meta_db_path:
                logger.warning(f"âš ï¸ ì¼ë°˜ ê²½ë¡œì—ì„œ Meta DB íŒŒì¼ì„ ì°¾ì§€ ëª»í•¨. media ë””ë ‰í† ë¦¬ ì „ì²´ ê²€ìƒ‰ ì‹œë„: {self.video_id}")
                if os.path.exists(media_dir):
                    # ëª¨ë“  meta_db.json íŒŒì¼ ê²€ìƒ‰
                    import glob
                    meta_db_files = glob.glob(os.path.join(media_dir, "*-meta_db.json"))
                    # ê°€ìž¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš© (ë¶„ì„ì´ ê°€ìž¥ ìµœê·¼ì— ì™„ë£Œëœ ê²ƒ)
                    if meta_db_files:
                        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ìœ¼ë¡œ ì •ë ¬
                        meta_db_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
                        # ì¼ë‹¨ ì²« ë²ˆì§¸ íŒŒì¼ ì‚¬ìš© (ë‚˜ì¤‘ì— ë” ì •í™•í•œ ë§¤ì¹­ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)
                        meta_db_path = meta_db_files[0]
                        logger.warning(f"âš ï¸ ê°€ìž¥ ìµœê·¼ Meta DB íŒŒì¼ ì‚¬ìš©: {os.path.basename(meta_db_path)}")
            
            if meta_db_path and os.path.exists(meta_db_path):
                with open(meta_db_path, 'r', encoding='utf-8') as f:
                    self.meta_db = json.load(f)
                self.frames = self.meta_db.get('frame', [])
                logger.info(f"âœ… Meta DB ë¡œë“œ ì„±ê³µ: {len(self.frames)}ê°œ í”„ë ˆìž„, íŒŒì¼: {os.path.basename(meta_db_path)}")
            else:
                logger.warning(f"âŒ Meta DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. video_id: {self.video_id}, filename: {self.video.filename}, original_name: {self.video.original_name}")
        
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def is_video_related_question(self, message):
        """ì˜ìƒ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        video_keywords = [
            'ì˜ìƒ', 'video', 'ë™ì˜ìƒ', 'ë¹„ë””ì˜¤',
            'ì‚¬ëžŒ', 'people', 'person', 'ë‚¨ìž', 'ì—¬ìž', 'man', 'woman',
            'ì˜·', 'clothing', 'shirt', 'jacket', 'ìƒ‰ìƒ', 'color',
            'ë°°ê²½', 'background', 'scene', 'ìž¥ë©´',
            'ëª‡', 'how many', 'count', 'ê°œìˆ˜',
            'ìžˆ', 'is there', 'are there',
            'ì°¾', 'find', 'search',
            'ì‡¼í•‘ëª°', 'mall', 'shopping',
            'ê±°ë¦¬', 'street', 'ë°¤', 'night', 'ë‚®', 'day',
            'ì „í™”', 'phone', 'ê±·', 'walk',
            'ìš”ì•½', 'summary', 'summarize'
        ]
        
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in video_keywords)
    
    def search_frames_by_keywords(self, keywords):
        """í‚¤ì›Œë“œë¡œ í”„ë ˆìž„ ê²€ìƒ‰ (ìº¡ì…˜ + ê°ì²´ ì •ë³´ ê¸°ë°˜)"""
        found_frames = []
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            match_score = 0
            matched_keywords = []
            matched_objects = []
            
            # 1. ìº¡ì…˜ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
            for keyword in keywords:
                keyword_lower = keyword.lower()
                if keyword_lower in caption:
                    match_score += 2  # ìº¡ì…˜ ë§¤ì¹­ ì‹œ 2ì 
                    matched_keywords.append(keyword)
            
            # 2. ê°ì²´ ì •ë³´ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ë” ë†’ì€ ì ìˆ˜)
            objects = frame.get('objects', [])
            for obj in objects:
                obj_class = obj.get('class', '').lower()
                for keyword in keywords:
                    keyword_lower = keyword.lower()
                    # ì •í™•ížˆ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨ë˜ëŠ” ê²½ìš°
                    if keyword_lower == obj_class or keyword_lower in obj_class or obj_class in keyword_lower:
                        match_score += 3  # ê°ì²´ ë§¤ì¹­ ì‹œ 3ì  (ìº¡ì…˜ë³´ë‹¤ ìš°ì„ )
                        if obj_class not in matched_objects:
                            matched_objects.append(obj_class)
                        if keyword not in matched_keywords:
                            matched_keywords.append(keyword)
                        logger.info(f"  ðŸŽ¯ ê°ì²´ ë§¤ì¹­ ë°œê²¬: '{keyword}' -> '{obj_class}' (í”„ë ˆìž„ {frame.get('image_id', 0)})")
            
            # ì ì–´ë„ í•˜ë‚˜ ì´ìƒì˜ í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ë©´ ì¶”ê°€
            if match_score > 0:
                frame_with_score = frame.copy()
                frame_with_score['match_score'] = match_score
                found_frames.append(frame_with_score)
                if matched_objects:
                    logger.info(f"âœ… í”„ë ˆìž„ {frame.get('image_id', 0)} ì¶”ê°€: ê°ì²´ ë§¤ì¹­ {matched_objects}, ì ìˆ˜: {match_score}")
        
        # ë§¤ì¹­ ì ìˆ˜ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        found_frames.sort(key=lambda x: x.get('match_score', 0), reverse=True)
        
        return found_frames
    
    def search_frames_by_color(self, color_name):
        """ìƒ‰ìƒìœ¼ë¡œ í”„ë ˆìž„ ê²€ìƒ‰ (ìº¡ì…˜ ìš°ì„  + ìƒ‰ìƒ ì¶”ì¶œ ë³´ì¡°)"""
        if not color_name:
            return []
        
        found_frames = []
        color_name_lower = color_name.lower()
        
        # í•œêµ­ì–´ â†’ ì˜ì–´ ê¸°ë³¸ ìƒ‰ìƒ ë§¤í•‘
        korean_to_english = {
            'ë¶„í™ìƒ‰': 'pink',
            'í•‘í¬': 'pink',
            'ë³´ë¼ìƒ‰': 'purple',
            'ë³´ë¼': 'purple',
            'ìžì£¼ìƒ‰': 'purple',
            'ìží™ìƒ‰': 'purple',
            'íŒŒëž€ìƒ‰': 'blue',
            'íŒŒëž‘': 'blue',
            'í‘¸ë¥¸ìƒ‰': 'blue',
            'ë‚¨ìƒ‰': 'blue',
            'í•˜ëŠ˜ìƒ‰': 'blue',
            'ì´ˆë¡ìƒ‰': 'green',
            'ì´ˆë¡': 'green',
            'ë…¹ìƒ‰': 'green',
            'ì—°ë‘ìƒ‰': 'green',
            'ë…¸ëž€ìƒ‰': 'yellow',
            'ë…¸ëž‘': 'yellow',
            'í™©ìƒ‰': 'yellow',
            'ì£¼í™©ìƒ‰': 'orange',
            'ì£¼í™©': 'orange',
            'ì˜¤ë Œì§€': 'orange',
            'ë¹¨ê°„ìƒ‰': 'red',
            'ë¹¨ê°•': 'red',
            'ì ìƒ‰': 'red',
            'í°ìƒ‰': 'white',
            'í•˜ì–€ìƒ‰': 'white',
            'ê²€ì€ìƒ‰': 'black',
            'ê¹Œë§Œìƒ‰': 'black',
            'íšŒìƒ‰': 'gray',
            'ê·¸ë ˆì´': 'gray',
            'ì€ìƒ‰': 'gray',
            'ì€ë¹›': 'gray'
        }
        
        base_color = korean_to_english.get(color_name_lower, color_name_lower)
        
        # ìƒ‰ìƒ ë™ì˜ì–´ ë§¤í•‘ (pink -> rose, fuchsia ë“±)
        color_synonyms = {
            'pink': ['pink', 'rose', 'fuchsia', 'magenta', 'rosy'],
            'red': ['red', 'crimson', 'scarlet'],
            'orange': ['orange', 'amber', 'tangerine'],
            'yellow': ['yellow', 'gold', 'golden'],
            'green': ['green', 'lime', 'emerald'],
            'blue': ['blue', 'navy', 'azure', 'teal'],
            'purple': ['purple', 'violet', 'lavender'],
            'white': ['white', 'ivory'],
            'black': ['black'],
            'gray': ['gray', 'grey', 'silver']
        }
        synonyms = color_synonyms.get(base_color, [base_color])
        
        # ì›ë³¸ ê²€ìƒ‰ì–´(í•œêµ­ì–´ í¬í•¨)ë¥¼ ë³´ì¡° í‚¤ì›Œë“œë¡œ ì¶”ê°€
        if color_name_lower not in synonyms:
            synonyms.append(color_name_lower)
        
        for frame in self.frames:
            match_score = 0
            caption = frame.get('caption', '').lower()
            caption_weight = 3  # Ollama ìº¡ì…˜ ìš°ì„  ê°€ì¤‘ì¹˜
            color_weight = 1    # ìƒ‰ìƒ ì¶”ì¶œ ë³´ì¡° ê°€ì¤‘ì¹˜
            explicit_weight = 2  # ëª…ì‹œì  ì–¸ê¸‰ ê°€ì¤‘ì¹˜ (ì˜ˆ: "green clothing")
            
            # 1. ìº¡ì…˜ì—ì„œ ìƒ‰ìƒ ê²€ìƒ‰ (ìš°ì„  ìˆœìœ„ ë†’ìŒ)
            if any(word in caption for word in synonyms):
                match_score += caption_weight
                
                # ëª…ì‹œì  ì–¸ê¸‰ í™•ì¸ (ì˜ˆ: "green clothing", "in green", "wearing green")
                for word in synonyms:
                    if f"{word} clothing" in caption or f"in {word}" in caption or f"wearing {word}" in caption:
                        match_score += explicit_weight
                        break
            
            # 2. ì¶”ì¶œëœ ìƒ‰ìƒ ì •ë³´ í™•ì¸ (ë³´ì¡°)
            objects = frame.get('objects', [])
            green_person_count = 0  # ì´ˆë¡ìƒ‰ ì˜·ì„ ìž…ì€ ì‚¬ëžŒ ìˆ˜
            for obj in objects:
                if obj.get('class') == 'person':
                    clothing_colors = obj.get('clothing_colors', {})
                    upper_color = (clothing_colors.get('upper') or '').lower()
                    lower_color = (clothing_colors.get('lower') or '').lower()
                    attrs = obj.get('attributes', {})
                    clothing = attrs.get('clothing', {})
                    dominant_color = (clothing.get('dominant_color') or '').lower()
                    
                    # ìƒì˜ê°€ ì´ˆë¡ìƒ‰ì´ê±°ë‚˜ dominant_colorê°€ ì´ˆë¡ìƒ‰ì¸ ê²½ìš°
                    if any(word in upper_color for word in synonyms) or any(word in dominant_color for word in synonyms):
                        match_score += color_weight
                        green_person_count += 1
            
            # ì´ˆë¡ìƒ‰ ì˜·ì„ ìž…ì€ ì‚¬ëžŒ ìˆ˜ì— ë”°ë¥¸ ì¶”ê°€ ì ìˆ˜ (ìµœëŒ€ 3ì )
            if green_person_count > 0:
                match_score += min(green_person_count, 3)
            
            if match_score > 0:
                frame_with_score = frame.copy()
                frame_with_score['match_score'] = match_score
                frame_with_score['green_person_count'] = green_person_count
                found_frames.append(frame_with_score)
        
        # ì ìˆ˜ ìˆœ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìš°ì„ ), ì ìˆ˜ê°€ ê°™ìœ¼ë©´ íƒ€ìž„ìŠ¤íƒ¬í”„ ìˆœ (ë¹ ë¥¸ ì‹œê°„ ìš°ì„ )
        found_frames.sort(key=lambda x: (x.get('match_score', 0), -x.get('timestamp', 0)), reverse=True)
        
        # ì¤‘ë³µ íƒ€ìž„ìŠ¤íƒ¬í”„ ì œê±° í›„ ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
        unique_frames = []
        seen_timestamps = set()
        for frame in found_frames:
            ts_key = round(frame.get('timestamp', 0), 2)
            if ts_key in seen_timestamps:
                continue
            unique_frames.append(frame)
            seen_timestamps.add(ts_key)
            if len(unique_frames) >= 5:
                break
        
        return unique_frames
    
    def analyze_people_count(self):
        """ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì‚¬ëžŒ ìˆ˜ ë¶„ì„ (í”„ë ˆìž„ë³„ ì¤‘ë³µ ê³ ë ¤)"""
        import re
        
        # ê° í”„ë ˆìž„ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ì‚¬ëžŒ ìˆ˜ ì¶”ì¶œ
        people_counts = []
        
        number_words = {
            'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,
            'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10
        }
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            timestamp = frame.get('timestamp', 0)
            
            # "five people", "three individuals", "two men" ë“±ì˜ íŒ¨í„´ ì°¾ê¸°
            for num_word, num in number_words.items():
                patterns = [
                    f'{num_word} people',
                    f'{num_word} individuals',
                    f'{num_word} men',
                    f'{num_word} women',
                    f'{num_word} persons'
                ]
                
                for pattern in patterns:
                    if pattern in caption:
                        people_counts.append({
                            'timestamp': timestamp,
                            'count': num,
                            'caption_excerpt': caption[:100]
                        })
                        break
                
                if people_counts and people_counts[-1]['timestamp'] == timestamp:
                    break
        
        # ìµœëŒ€ ì‚¬ëžŒ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨ (ê°™ì€ ì‚¬ëžŒë“¤ì´ ì—¬ëŸ¬ í”„ë ˆìž„ì— ë“±ìž¥)
        if people_counts:
            max_count_info = max(people_counts, key=lambda x: x['count'])
            max_count = max_count_info['count']
            
            return {
                'estimated_count': max_count,
                'confidence': 'high',
                'evidence': people_counts,
                'explanation': f"í”„ë ˆìž„ ë¶„ì„ ê²°ê³¼, í•œ ìž¥ë©´ì—ì„œ ìµœëŒ€ {max_count}ëª…ì´ ë“±ìž¥í•©ë‹ˆë‹¤. ì˜ìƒ ì „ì²´ì—ì„œëŠ” ê°™ì€ ì‚¬ëžŒë“¤ì´ ì—¬ëŸ¬ í”„ë ˆìž„ì— ë‚˜íƒ€ë‚˜ë¯€ë¡œ, ê³ ìœ í•œ ì‚¬ëžŒ ìˆ˜ëŠ” ì•½ {max_count}ëª… ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤."
            }
        else:
            # ëª…ì‹œì  ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ "group", "people" ë“±ìœ¼ë¡œ ì¶”ì •
            group_count = sum(1 for f in self.frames if 'group' in f.get('caption', '').lower() or 'people' in f.get('caption', '').lower())
            
            if group_count > 0:
                return {
                    'estimated_count': '3-5',
                    'confidence': 'medium',
                    'evidence': [],
                    'explanation': f"ì˜ìƒì—ì„œ ì—¬ëŸ¬ ëª…ì˜ ì‚¬ëžŒë“¤ì´ ê·¸ë£¹ìœ¼ë¡œ ë“±ìž¥í•˜ì§€ë§Œ, ì •í™•í•œ ìˆ«ìžëŠ” ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëŒ€ëžµ 3-5ëª… ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤."
                }
            else:
                return {
                    'estimated_count': 'unknown',
                    'confidence': 'low',
                    'evidence': [],
                    'explanation': "ì˜ìƒ ë¶„ì„ì—ì„œ ì‚¬ëžŒ ìˆ˜ë¥¼ ëª…í™•ížˆ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
    
    def analyze_gender_ratio(self):
        """ì˜ìƒ ì „ì²´ì˜ ì„±ë¹„ ë¶„ì„"""
        import re
        
        # ì„±ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        gender_keywords = {
            'man': 'male', 'men': 'male', 'male': 'male',
            'woman': 'female', 'women': 'female', 'female': 'female',
            'boy': 'male', 'boys': 'male',
            'girl': 'female', 'girls': 'female'
        }
        
        # ì—°ë ¹ëŒ€ í‚¤ì›Œë“œ
        age_keywords = {
            'young': 'young', 'teen': 'young', 'teenage': 'young',
            'adult': 'adult', 'middle-aged': 'adult',
            'elderly': 'elderly', 'old': 'elderly', 'senior': 'elderly'
        }
        
        male_count = 0
        female_count = 0
        unknown_count = 0
        
        gender_evidence = []
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            timestamp = frame.get('timestamp', 0)
            
            # ì„±ë³„ í‚¤ì›Œë“œ ì°¾ê¸°
            frame_males = 0
            frame_females = 0
            
            for keyword, gender in gender_keywords.items():
                matches = re.findall(rf'\b{keyword}\b', caption)
                if matches:
                    for match in matches:
                        if gender == 'male':
                            frame_males += 1
                        else:
                            frame_females += 1
            
            if frame_males > 0 or frame_females > 0:
                gender_evidence.append({
                    'timestamp': timestamp,
                    'males': frame_males,
                    'females': frame_females,
                    'caption_excerpt': caption[:100]
                })
        
        # ì „ì²´ ì„±ë³„ ì¹´ìš´íŠ¸
        total_males = sum(ev['males'] for ev in gender_evidence)
        total_females = sum(ev['females'] for ev in gender_evidence)
        
        if total_males > 0 or total_females > 0:
            total_people = total_males + total_females
            male_ratio = (total_males / total_people) * 100 if total_people > 0 else 0
            female_ratio = (total_females / total_people) * 100 if total_people > 0 else 0
            
            return {
                'male_count': total_males,
                'female_count': total_females,
                'total_gendered': total_people,
                'male_ratio': round(male_ratio, 1),
                'female_ratio': round(female_ratio, 1),
                'confidence': 'medium' if len(gender_evidence) > 2 else 'low',
                'evidence': gender_evidence,
                'explanation': f"ì˜ìƒì—ì„œ ì„±ë³„ì´ ëª…ì‹œëœ ì¸ë¬¼: ë‚¨ì„± {total_males}ëª…, ì—¬ì„± {total_females}ëª… (ë‚¨ì„± {male_ratio:.1f}%, ì—¬ì„± {female_ratio:.1f}%)"
            }
        else:
            return {
                'male_count': 0,
                'female_count': 0,
                'total_gendered': 0,
                'male_ratio': 0,
                'female_ratio': 0,
                'confidence': 'low',
                'evidence': [],
                'explanation': "ì˜ìƒ ë¶„ì„ì—ì„œ ì„±ë³„ ì •ë³´ë¥¼ ëª…í™•ížˆ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìº¡ì…˜ì— ì„±ë³„ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
    
    def _call_ollama_korean(self, prompt, max_tokens=500):
        """Ollama í˜¸ì¶œ (í•œêµ­ì–´ ê°•ì œ)"""
        try:
            # í•œêµ­ì–´ ì‘ë‹µ ê°•ì œë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            korean_system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. 
ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
ì˜ì–´, í”„ëž‘ìŠ¤ì–´, ë² íŠ¸ë‚¨ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ê°„ê²°í•˜ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""
            
            response = ollama.chat(
                model='llama3.2:latest',
                messages=[
                    {
                        'role': 'system',
                        'content': korean_system_prompt
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                options={
                    'temperature': 0.3,  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í–¥ìƒ
                    'num_predict': max_tokens
                }
            )
            
            return response['message']['content'].strip()
            
        except Exception as e:
            logger.error(f"âŒ Ollama í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def generate_answer_with_multi_ai(self, message, context_frames=None, include_video_context=True):
        """ë‹¤ì¤‘ AI ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„± ë° í†µí•©"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            if include_video_context:
                context = f"ì˜ìƒ ì •ë³´:\n"
                # í”„ë ˆìž„ ìˆ˜ì™€ ì˜ìƒ ê¸¸ì´ ì •ë³´ëŠ” ì œì™¸ (ë¶ˆí•„ìš”í•œ ì •ë³´)
            else:
                context = ""
            
            if context_frames:
                context += f"ê´€ë ¨ í”„ë ˆìž„ ({len(context_frames)}ê°œ):\n"
                for i, frame in enumerate(context_frames[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
                    timestamp = frame.get('timestamp', 0)
                    caption = frame.get('caption', '')
                    # child/children í‚¤ì›Œë“œê°€ ìžˆìœ¼ë©´ ì „ì²´ ìº¡ì…˜ í¬í•¨, ì—†ìœ¼ë©´ 300ìžë¡œ ì œí•œ
                    if 'child' in caption.lower() or 'children' in caption.lower() or 'kid' in caption.lower():
                        context += f"{i}. [{timestamp:.1f}s] {caption}\n"
                    else:
                        context += f"{i}. [{timestamp:.1f}s] {caption[:300]}\n"
                    
                    # ê°ì²´ ì •ë³´ ì¶”ê°€ (YOLOë¡œ ê°ì§€ëœ ê°ì²´ë“¤)
                    objects = frame.get('objects', [])
                    if objects:
                        # personì´ ì•„ë‹Œ ê°ì²´ë“¤ë§Œ ëª…ì‹œì ìœ¼ë¡œ ë‚˜ì—´
                        other_objects = [obj for obj in objects if obj.get('class', '').lower() != 'person']
                        if other_objects:
                            object_names = [obj.get('class', 'unknown') for obj in other_objects]
                            # ì¤‘ë³µ ì œê±°
                            unique_objects = list(set(object_names))
                            if unique_objects:
                                context += f"   ê°ì§€ëœ ê°ì²´: {', '.join(unique_objects)}\n"
            else:
                # ì „ì²´ ìš”ì•½
                context += "ì˜ìƒ ì£¼ìš” ë‚´ìš©:\n"
                for i, frame in enumerate(self.frames[::max(1, len(self.frames)//5)], 1):  # ìƒ˜í”Œ 5ê°œ
                    timestamp = frame.get('timestamp', 0)
                    caption = frame.get('caption', '')
                    context += f"- [{timestamp:.1f}s] {caption[:150]}\n"
            
            # AI ì§ˆë¬¸ êµ¬ì„±
            # ìš”ì•½ ì§ˆë¬¸ì¸ì§€ í™•ì¸
            is_summary_question = 'ìš”ì•½' in message.lower() or 'summary' in message.lower() or 'ì •ë¦¬' in message.lower()
            
            if include_video_context:
                if is_summary_question:
                    # ìš”ì•½ ì§ˆë¬¸ì¼ ë•ŒëŠ” ìƒ‰ìƒ ë“± ì„¸ë¶€ ì •ë³´ë¥¼ ìµœëŒ€í•œ ìƒëžµ
                    ai_prompt = f"""ë‹¤ìŒ ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ìžì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ëž˜ ì œê³µëœ ì˜ìƒ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ìƒì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.

{context}

ì‚¬ìš©ìž ì§ˆë¬¸: {message}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€ (ìµœëŒ€ 3-4ë¬¸ìž¥)
2. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ë°˜ë“œì‹œ ìœ„ì— ì œê³µëœ ì˜ìƒ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ (ì˜ìƒì— ì—†ëŠ” ë‚´ìš©ì€ "ì—†ìŠµë‹ˆë‹¤" ë˜ëŠ” "ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€)
4. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëžµ (í”„ë ˆìž„ ìˆ˜, ì˜ìƒ ê¸¸ì´ ë“± ê¸°ìˆ ì  ì •ë³´ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”)
5. âš ï¸ ìƒ‰ìƒ, ì˜·ì˜ ìƒ‰ê¹”, ì˜ìƒì˜ ìƒ‰ìƒ ë“± ì‹œê°ì  ì„¸ë¶€ ì •ë³´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ "ì´ˆë¡ìƒ‰ ì˜·", "ë…¹ìƒ‰ ì˜ìƒ", "ìƒ‰ìƒì˜ ì˜·" ê°™ì€ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
6. ì˜ìƒì˜ ì „ì²´ì ì¸ ë¶„ìœ„ê¸°, ìž¥ì†Œ, ì‚¬ëžŒë“¤ì˜ í™œë™ì— ì§‘ì¤‘í•˜ì„¸ìš”
7. ì¸ë¬¼ì— ëŒ€í•´ ì–¸ê¸‰í•  ë•ŒëŠ” "ì–´ë¦°ì´ë„ ì—¬ëŸ¬ ë²ˆ ë“±ìž¥", "ì–´ë¦°ì´ë„ ë“±ìž¥" ê°™ì€ í‘œí˜„ ëŒ€ì‹  "ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì˜ ì‚¬ëžŒë“¤", "ì–´ë¦°ì´ì™€ ì„±ì¸ë“¤ì´ í•¨ê»˜" ê°™ì€ ìžì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
8. ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ ê¸ˆì§€
9. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ìž‘ì„±"""
                else:
                    ai_prompt = f"""ë‹¤ìŒ ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ëž˜ ì œê³µëœ ì˜ìƒ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ìƒì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.

{context}

ì‚¬ìš©ìž ì§ˆë¬¸: {message}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€ (ìµœëŒ€ 3-4ë¬¸ìž¥)
2. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ë°˜ë“œì‹œ ìœ„ì— ì œê³µëœ ì˜ìƒ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ (ì˜ìƒì— ì—†ëŠ” ë‚´ìš©ì€ "ì—†ìŠµë‹ˆë‹¤" ë˜ëŠ” "ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€)
4. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëžµ (í”„ë ˆìž„ ìˆ˜, ì˜ìƒ ê¸¸ì´ ë“± ê¸°ìˆ ì  ì •ë³´ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”)
5. ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ ê¸ˆì§€
6. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ìž‘ì„±"""
            else:
                ai_prompt = f"""ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ìž ì§ˆë¬¸: {message}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€ (ìµœëŒ€ 2-3ë¬¸ìž¥)
2. ì¹œê·¼í•œ í†¤ ìœ ì§€
3. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëžµ
4. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ìž‘ì„±"""
            
            # ë‹¤ì¤‘ AI ì‘ë‹µ ìƒì„±
            ai_responses = {}
            
            # chatbots ê°€ì ¸ì˜¤ê¸° (lazy import)
            chatbots = get_chatbots()
            
            # ìš°ì„ ìˆœìœ„ AI ëª¨ë¸ ì„ íƒ (chatbotsì˜ í‚¤ ì´ë¦„)
            priority_model_keys = [
                'gpt-4o-mini',           # GPT-4o Mini
                'gemini-2.0-flash-lite', # Gemini 2.0 Flash Lite
                'claude-3.5-haiku'       # Claude 3.5 Haiku
            ]
            
            # chatbotsì—ì„œ ì§€ì •ëœ ëª¨ë¸ ì°¾ì•„ì„œ ë‹µë³€ ìƒì„±
            if chatbots:
                logger.info(f"âœ… chatbots ì‚¬ìš© ê°€ëŠ¥, ëª¨ë¸ ìˆ˜: {len(chatbots)}")
                logger.info(f"   ê°€ëŠ¥í•œ ëª¨ë¸: {list(chatbots.keys())}")
                
                for model_key in priority_model_keys:
                    if model_key in chatbots:
                        try:
                            bot = chatbots[model_key]
                            response = bot.chat(ai_prompt)
                            
                            # ë¶€ì ì ˆí•œ ì‘ë‹µ í•„í„°ë§ (ì˜ìƒ ì •ë³´ ë¶€ìž¬ ë©”ì‹œì§€ ë° ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´)
                            blocked_patterns = [
                                "ì£„ì†¡í•˜ì§€ë§Œ ì œê³µëœ ì˜ìƒ ì •ë³´ëŠ” ì‹¤ì œ ì˜ìƒì´ ì•„ë‹ˆë¼ í…ìŠ¤íŠ¸ ì„¤ëª…ì¼ ë¿ìž…ë‹ˆë‹¤",
                                "ì œê³µëœ ì˜ìƒ ì •ë³´ëŠ” ì‹¤ì œ ì˜ìƒì´ ì•„ë‹ˆë¼",
                                "í…ìŠ¤íŠ¸ ì„¤ëª…ì¼ ë¿ìž…ë‹ˆë‹¤",
                                "ì‹¤ì œ ì˜ìƒì´ ì•„ë‹ˆë¼ í…ìŠ¤íŠ¸",
                                "ì§€ê¸ˆ ìžˆëŠ” ê³³ì´ ì–´ë””ì¸ì§€",
                                "ì•Œë ¤ì£¼ì‹œë©´",
                                "ê¶ê¸ˆí•œë°",
                                "ë¬´ìŠ¨ ê²Œìž„ì´ë‚˜ ì˜í™”",
                                "ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì— ë”°ë¼"
                            ]
                            
                            # ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ íŒ¨í„´ (Gemini ë“±ì´ ìžì£¼ ì‚¬ìš©)
                            irrelevant_patterns = [
                                "ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì— ë”°ë¼",
                                "ì§€ê¸ˆ ìžˆëŠ” ê³³ì´",
                                "ì•Œë ¤ì£¼ì‹œë©´",
                                "ë¬´ìŠ¨ ê²Œìž„ì´ë‚˜ ì˜í™”",
                                "ê¶ê¸ˆí•œë°",
                                "ì‘!",
                                "ë‚˜ì˜¬ ìˆ˜ ìžˆì§€"
                            ]
                            
                            # ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´ ì œê±° (í”„ë ˆìž„ ìˆ˜, ì˜ìƒ ê¸¸ì´ ë“±)
                            unwanted_patterns = [
                                "í”„ë ˆìž„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìœ¼ë©°",
                                "ì´ˆì˜ ì§§ì€ ê¸¸ì´",
                                "í”„ë ˆìž„ ìˆ˜",
                                "ì˜ìƒ ê¸¸ì´",
                                "ì´ˆì˜ ê¸¸ì´",
                                "ê°œ í”„ë ˆìž„",
                                "í”„ë ˆìž„ìœ¼ë¡œ êµ¬ì„±"
                            ]
                            
                            response_str = str(response) if response else ""
                            is_blocked = any(pattern in response_str for pattern in blocked_patterns)
                            
                            # ì˜ìƒê³¼ ë¬´ê´€í•œ ë‹µë³€ ê²€ì¦ (ì˜ìƒ ì»¨í…ìŠ¤íŠ¸ê°€ ìžˆëŠ”ë° ì¼ë°˜ì ì¸ ë‹µë³€ì¸ ê²½ìš°)
                            if include_video_context and context:
                                is_irrelevant = any(pattern in response_str for pattern in irrelevant_patterns)
                                # ì˜ìƒ ì •ë³´ê°€ ì œê³µë˜ì—ˆëŠ”ë° ë‹µë³€ì— ì˜ìƒ ê´€ë ¨ í‚¤ì›Œë“œê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš°
                                video_keywords = ["ì˜ìƒ", "í”„ë ˆìž„", "ìž¥ë©´", "í¬ì°©", "ë“±ìž¥", "ë‚˜íƒ€", "ë³´ì—¬", "ë³´ì´"]
                                has_video_context = any(keyword in response_str for keyword in video_keywords)
                                
                                if is_irrelevant and not has_video_context:
                                    logger.warning(f"âš ï¸ {model_key} ì‘ë‹µ ì°¨ë‹¨: ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€")
                                    continue
                            
                            if is_blocked:
                                logger.warning(f"âš ï¸ {model_key} ì‘ë‹µ ì°¨ë‹¨: ë¶€ì ì ˆí•œ ë©”ì‹œì§€ í¬í•¨")
                                continue
                            
                            # ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´ ì œê±°
                            for pattern in unwanted_patterns:
                                if pattern in response_str:
                                    # í•´ë‹¹ íŒ¨í„´ì´ í¬í•¨ëœ ë¬¸ìž¥ ì œê±°
                                    # íŒ¨í„´ ì£¼ë³€ì˜ ë¬¸ìž¥ ì œê±° (ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ì œê±°)
                                    # ì˜ˆ: "6ê°œì˜ í”„ë ˆìž„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìœ¼ë©°, 0.0ì´ˆì˜ ì§§ì€ ê¸¸ì´ìž…ë‹ˆë‹¤."
                                    response_str = re.sub(
                                        r'[^.]{0,30}' + re.escape(pattern) + r'[^.]{0,30}[.]?',
                                        '',
                                        response_str,
                                        flags=re.IGNORECASE
                                    )
                                    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
                                    response_str = re.sub(r'\s+', ' ', response_str)
                                    logger.info(f"ðŸ”§ {model_key} ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´ ì œê±°: {pattern}")
                            
                            response = response_str.strip()
                            
                            ai_responses[model_key] = response
                            logger.info(f"âœ… {model_key} ë‹µë³€ ìƒì„± ì™„ë£Œ")
                        except Exception as e:
                            logger.warning(f"âš ï¸ {model_key} ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                    else:
                        logger.warning(f"âš ï¸ {model_key} ëª¨ë¸ì„ chatbotsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            else:
                logger.warning("âš ï¸ chatbotsë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ, Ollamaë§Œ ì‚¬ìš©")
            
            # Ollamaë¥¼ ë°±ì—…ìœ¼ë¡œ ì‚¬ìš© (í•œêµ­ì–´ ê°•ì œ)
            ollama_answer = self._call_ollama_korean(ai_prompt)
            
            # ì‘ë‹µì´ ì—†ìœ¼ë©´ Ollamaë§Œ ì‚¬ìš©
            if not ai_responses:
                logger.warning("âš ï¸ ëª¨ë“  AI ëª¨ë¸ ì‹¤íŒ¨, Ollamaë¡œ ìž¬ì‹œë„")
                if ollama_answer:
                    return {
                    'integrated': ollama_answer,
                    'individual': {'ollama': ollama_answer}
                }
                else:
                    return {
                        'integrated': "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                        'individual': {}
                    }
            
            # ì‘ë‹µì´ 1ê°œë§Œ ìžˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if len(ai_responses) == 1:
                single_answer = list(ai_responses.values())[0]
                return {
                    'integrated': single_answer,
                    'individual': ai_responses
                }
            
            # ë‹¤ì¤‘ ì‘ë‹µ í†µí•©
            integrated_answer = self._integrate_multi_ai_responses(ai_responses, message)
            
            # ê°œë³„ ì‘ë‹µ + í†µí•© ì‘ë‹µ ë°˜í™˜
            return {
                'integrated': integrated_answer,
                'individual': ai_responses
            }
            
        except Exception as e:
            logger.error(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'integrated': "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                'individual': {}
            }
    
    def _integrate_multi_ai_responses(self, ai_responses, original_question):
        """ë‹¤ì¤‘ AI ì‘ë‹µ í†µí•© (HCX-DASH-001 ì‚¬ìš©)"""
        try:
            # ê° AIì˜ ì‘ë‹µì„ ì •ë¦¬
            responses_text = ""
            for model_name, response in ai_responses.items():
                responses_text += f"### {model_name.upper()}:\n{response}\n\n"
            
            # HCX-DASH-001ë¡œ í†µí•© ë‹µë³€ ìƒì„±
            chatbots = get_chatbots()
            hcx_bot = None
            
            # HCX-DASH-001 ì°¾ê¸° (ì •í™•í•œ í‚¤ ì´ë¦„)
            hcx_model_keys = ['clova-hcx-dash-001', 'HCX-DASH-001', 'hcx-dash-001']
            for key in hcx_model_keys:
                if key in chatbots:
                    hcx_bot = chatbots[key]
                    logger.info(f"âœ… HCX-DASH-001 ëª¨ë¸ ë°œê²¬: {key}")
                    break
            
            # ìš”ì•½ ì§ˆë¬¸ì¸ì§€ í™•ì¸
            is_summary_question = 'ìš”ì•½' in original_question.lower() or 'summary' in original_question.lower() or 'ì •ë¦¬' in original_question.lower()
            
            if is_summary_question:
                integration_prompt = f"""ë‹¤ìŒì€ ì—¬ëŸ¬ AI ëª¨ë¸ì´ ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤.
í•µì‹¬ë§Œ ê°„ê²°í•˜ê³  ìžì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ì˜ìƒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹µë³€ë§Œ í†µí•©í•˜ì„¸ìš”. ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ì€ ì œì™¸í•˜ì„¸ìš”.

ì§ˆë¬¸: {original_question}

{responses_text}

í†µí•© ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ í†µí•© (ìµœëŒ€ 3-4ë¬¸ìž¥)
2. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ì˜ìƒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹µë³€ë§Œ í¬í•¨ (ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ì€ ì œì™¸)
4. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëžµ (í”„ë ˆìž„ ìˆ˜, ì˜ìƒ ê¸¸ì´, ì´ˆ ë‹¨ìœ„ ë“± ê¸°ìˆ ì  ì •ë³´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”)
5. âš ï¸ ìƒ‰ìƒ, ì˜·ì˜ ìƒ‰ê¹”, ì˜ìƒì˜ ìƒ‰ìƒ ë“± ì‹œê°ì  ì„¸ë¶€ ì •ë³´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ "ì´ˆë¡ìƒ‰ ì˜·", "ë…¹ìƒ‰ ì˜ìƒ", "ìƒ‰ìƒì˜ ì˜·", "ì—¬ëŸ¬ ì‚¬ëžŒì˜ ì´ˆë¡ìƒ‰ ì˜ìƒ" ê°™ì€ í‘œí˜„ì€ ì™„ì „ížˆ ì œê±°í•˜ì„¸ìš”.
6. ì˜ìƒì˜ ì „ì²´ì ì¸ ë¶„ìœ„ê¸°, ìž¥ì†Œ, ì‚¬ëžŒë“¤ì˜ í™œë™ì— ì§‘ì¤‘í•˜ì„¸ìš”
7. ì¸ë¬¼ì— ëŒ€í•´ ì–¸ê¸‰í•  ë•ŒëŠ” "ì–´ë¦°ì´ë„ ì—¬ëŸ¬ ë²ˆ ë“±ìž¥", "ì–´ë¦°ì´ë„ ë“±ìž¥" ê°™ì€ í‘œí˜„ ëŒ€ì‹  "ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì˜ ì‚¬ëžŒë“¤", "ì–´ë¦°ì´ì™€ ì„±ì¸ë“¤ì´ í•¨ê»˜" ê°™ì€ ìžì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
8. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ìž‘ì„±"""
            else:
                integration_prompt = f"""ë‹¤ìŒì€ ì—¬ëŸ¬ AI ëª¨ë¸ì´ ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤.
í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ í†µí•©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ì˜ìƒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹µë³€ë§Œ í†µí•©í•˜ì„¸ìš”. ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ì€ ì œì™¸í•˜ì„¸ìš”.

ì§ˆë¬¸: {original_question}

{responses_text}

í†µí•© ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ í†µí•© (ìµœëŒ€ 3-4ë¬¸ìž¥)
2. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ì˜ìƒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹µë³€ë§Œ í¬í•¨ (ì˜ìƒê³¼ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ì€ ì œì™¸)
4. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëžµ (í”„ë ˆìž„ ìˆ˜, ì˜ìƒ ê¸¸ì´, ì´ˆ ë‹¨ìœ„ ë“± ê¸°ìˆ ì  ì •ë³´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”)
5. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ìž‘ì„±"""
            
            # HCX-DASH-001 ì‚¬ìš©
            if hcx_bot:
                try:
                    integrated = hcx_bot.chat(integration_prompt)
                    logger.info(f"âœ… HCX-DASH-001 í†µí•© ë‹µë³€ ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ HCX-DASH-001 ì‹¤íŒ¨, Ollamaë¡œ ëŒ€ì²´: {e}")
                    integrated = self._call_ollama_korean(integration_prompt, max_tokens=800)
            else:
                # HCX-DASH-001ì´ ì—†ìœ¼ë©´ Ollama ì‚¬ìš©
                logger.warning("âš ï¸ HCX-DASH-001 ì—†ìŒ, Ollama ì‚¬ìš©")
                integrated = self._call_ollama_korean(integration_prompt, max_tokens=800)
            
            # í†µí•© ì‘ë‹µì—ì„œë„ ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´ ë° ì˜ìƒê³¼ ë¬´ê´€í•œ ë‹µë³€ ì œê±°
            if integrated:
                unwanted_patterns = [
                    "í”„ë ˆìž„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìœ¼ë©°",
                    "ì´ˆì˜ ì§§ì€ ê¸¸ì´",
                    "í”„ë ˆìž„ ìˆ˜",
                    "ì˜ìƒ ê¸¸ì´",
                    "ì´ˆì˜ ê¸¸ì´",
                    "ê°œ í”„ë ˆìž„",
                    "í”„ë ˆìž„ìœ¼ë¡œ êµ¬ì„±"
                ]
                
                irrelevant_patterns = [
                    "ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì— ë”°ë¼",
                    "ì§€ê¸ˆ ìžˆëŠ” ê³³ì´",
                    "ì•Œë ¤ì£¼ì‹œë©´",
                    "ë¬´ìŠ¨ ê²Œìž„ì´ë‚˜ ì˜í™”",
                    "ê¶ê¸ˆí•œë°",
                    "ì‘!",
                    "ë‚˜ì˜¬ ìˆ˜ ìžˆì§€"
                ]
                
                integrated_str = str(integrated)
                
                # ì˜ìƒê³¼ ë¬´ê´€í•œ ë‹µë³€ ì œê±°
                for pattern in irrelevant_patterns:
                    if pattern in integrated_str:
                        integrated_str = re.sub(
                            r'[^.]{0,30}' + re.escape(pattern) + r'[^.]{0,30}[.]?',
                            '',
                            integrated_str,
                            flags=re.IGNORECASE
                        )
                        logger.info(f"ðŸ”§ í†µí•© ì‘ë‹µì—ì„œ ì˜ìƒê³¼ ë¬´ê´€í•œ ë‹µë³€ ì œê±°: {pattern}")
                
                # ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´ ì œê±°
                for pattern in unwanted_patterns:
                    if pattern in integrated_str:
                        integrated_str = re.sub(
                            r'[^.]{0,30}' + re.escape(pattern) + r'[^.]{0,30}[.]?',
                            '',
                            integrated_str,
                            flags=re.IGNORECASE
                        )
                        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
                        integrated_str = re.sub(r'\s+', ' ', integrated_str)
                        logger.info(f"ðŸ”§ í†µí•© ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ê¸°ìˆ  ì •ë³´ ì œê±°: {pattern}")
                
                integrated = integrated_str.strip()
            
            # ê° AI ë¶„ì„ ì¶”ê°€
            if integrated:
                integrated += "\n\n---\n**ê° AI ë¶„ì„:**\n"
            for model_name in ai_responses.keys():
                integrated += f"- {model_name.upper()}\n"
            else:
                # Ollamaë„ ì‹¤íŒ¨í•˜ë©´ ì²« ë²ˆì§¸ ì‘ë‹µ ë°˜í™˜
                integrated = list(ai_responses.values())[0]
            
            return integrated
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì‘ë‹µ ë°˜í™˜
            return list(ai_responses.values())[0]
    
    def handle_general_question(self, message):
        """ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ (ì˜ìƒ ë¬´ê´€)"""
        try:
            answer = self._call_ollama_korean(message)
            return answer if answer else "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"âŒ ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def process_message(self, message):
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        
        Returns:
            dict: {
                'answer': str,  # í†µí•© ë‹µë³€
                'individual_responses': dict,  # ê° AI ê°œë³„ ë‹µë³€
                'frames': list,  # ê´€ë ¨ í”„ë ˆìž„ ì •ë³´
                'frame_images': list,  # í”„ë ˆìž„ ì´ë¯¸ì§€ ê²½ë¡œ
                'is_video_related': bool
            }
        """
        result = {
            'answer': '',
            'individual_responses': {},
            'frames': [],
            'frame_images': [],
            'is_video_related': False
        }
        
        # 1. ì˜ìƒ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        if not self.is_video_related_question(message):
            # ì¼ë°˜ ì§ˆë¬¸ë„ ë‹¤ì¤‘ AIë¡œ ì²˜ë¦¬ (ì˜ìƒ ì»¨í…ìŠ¤íŠ¸ ì œì™¸)
            ai_result = self.generate_answer_with_multi_ai(message, None, include_video_context=False)
            if isinstance(ai_result, dict):
                result['answer'] = ai_result.get('integrated', '')
                result['individual_responses'] = ai_result.get('individual', {})
            else:
                result['answer'] = ai_result
            result['is_video_related'] = False
            return result
        
        result['is_video_related'] = True
        
        # 2. í•˜ì´ë¼ì´íŠ¸/ìš”ì•½ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        highlight_keywords = ['í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì£¼ìš” ìž¥ë©´', 'í•µì‹¬ ìž¥ë©´', 'ì¤‘ìš”í•œ ìž¥ë©´']
        summary_keywords = ['ìš”ì•½', 'summary', 'ì •ë¦¬']
        
        is_highlight_question = any(keyword in message.lower() for keyword in highlight_keywords)
        is_summary_question = any(keyword in message.lower() for keyword in summary_keywords)
        
        if is_highlight_question or is_summary_question:
            # í•˜ì´ë¼ì´íŠ¸ í”„ë ˆìž„ ì„ íƒ (ë‹¤ì–‘ì„± ê¸°ë°˜)
            highlight_frames = []
            
            # ì „ì²´ í”„ë ˆìž„ì„ 5-7ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ ì„œ ëŒ€í‘œ í”„ë ˆìž„ ì„ íƒ
            if len(self.frames) > 0:
                num_highlights = min(7, len(self.frames))  # ìµœëŒ€ 7ê°œ
                step = max(1, len(self.frames) // num_highlights)
                
                for i in range(0, len(self.frames), step):
                    if len(highlight_frames) < num_highlights:
                        frame = self.frames[i]
                        # ì‚¬ëžŒì´ ë§Žê±°ë‚˜ ìº¡ì…˜ì´ ê¸´ í”„ë ˆìž„ ìš°ì„ 
                        persons = frame.get('persons', [])
                        caption = frame.get('caption', '')
                        frame_copy = frame.copy()
                        frame_copy['highlight_score'] = len(persons) + len(caption) / 10
                        highlight_frames.append(frame_copy)
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 5ê°œ ì„ íƒ
                highlight_frames.sort(key=lambda x: x.get('highlight_score', 0), reverse=True)
                highlight_frames = highlight_frames[:5]
                
                # íƒ€ìž„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ìž¬ì •ë ¬
                highlight_frames.sort(key=lambda x: x.get('timestamp', 0))
            
            if highlight_frames:
                result['frames'] = highlight_frames
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in highlight_frames
                ]
                
                # í•˜ì´ë¼ì´íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                highlight_context = f"""ðŸŽ¬ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ìž¥ë©´ ({len(highlight_frames)}ê°œ):

"""
                for i, frame in enumerate(highlight_frames, 1):
                    timestamp = frame.get('timestamp', 0)
                    caption = frame.get('caption', '')
                    persons = frame.get('persons', [])
                    highlight_context += f"{i}. [{timestamp:.1f}ì´ˆ] {caption[:150]}\n"
                    highlight_context += f"   - ë“±ìž¥ ì¸ë¬¼: {len(persons)}ëª…\n\n"
                
                highlight_context += f"\nì§ˆë¬¸: {message}\n"
                
                # ë‹¤ì¤‘ AIë¡œ ë‹µë³€ ìƒì„±
                ai_result = self.generate_answer_with_multi_ai(highlight_context, highlight_frames)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
            else:
                result['answer'] = "í•˜ì´ë¼ì´íŠ¸ ìž¥ë©´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return result
        
        # 3. ì‚¬ëžŒ ìˆ˜ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        people_count_keywords = ['ëª‡ëª…', 'ëª‡ ëª…', 'ì‚¬ëžŒ ìˆ˜', 'ì¸ì›', 'how many people', 'how many person']
        is_people_count_question = any(keyword in message.lower() for keyword in people_count_keywords)
        
        if is_people_count_question:
            # ì‚¬ëžŒ ìˆ˜ ë¶„ì„
            count_analysis = self.analyze_people_count()
            
            # ì¦ê±° í”„ë ˆìž„ ì°¾ê¸° (ìµœëŒ€ ì¹´ìš´íŠ¸ê°€ ë‚˜ì˜¨ í”„ë ˆìž„)
            evidence_frames = []
            if count_analysis['evidence']:
                max_count = count_analysis['estimated_count']
                for evidence in count_analysis['evidence']:
                    if evidence['count'] == max_count:
                        # í•´ë‹¹ íƒ€ìž„ìŠ¤íƒ¬í”„ì˜ í”„ë ˆìž„ ì°¾ê¸°
                        for frame in self.frames:
                            if frame.get('timestamp') == evidence['timestamp']:
                                evidence_frames.append(frame)
                                break
            
            if evidence_frames:
                result['frames'] = evidence_frames
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in evidence_frames
                ]
            
            # ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ AI ë‹µë³€ ìƒì„±
            enhanced_context = f"""ðŸŽ¯ ì¤‘ìš”: ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì‚¬ëžŒ ìˆ˜ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”. ê°™ì€ ì‚¬ëžŒë“¤ì´ ì—¬ëŸ¬ í”„ë ˆìž„ì— ë°˜ë³µ ë“±ìž¥í•˜ë¯€ë¡œ ì¤‘ë³µ ì¹´ìš´íŒ…í•˜ì§€ ë§ˆì„¸ìš”!

ì˜ìƒ ì „ì²´ ì‚¬ëžŒ ìˆ˜ ë¶„ì„ ê²°ê³¼:
- ì¶”ì • ì¸ì›: {count_analysis['estimated_count']}ëª…
- ì‹ ë¢°ë„: {count_analysis['confidence']}
- í•µì‹¬ ê·¼ê±°: {count_analysis['explanation']}

í”„ë ˆìž„ë³„ ëª…ì‹œëœ ì¸ì› ìˆ˜:
"""
            if count_analysis['evidence']:
                for i, ev in enumerate(count_analysis['evidence'][:5], 1):
                    enhanced_context += f"{i}. [{ev['timestamp']:.1f}ì´ˆ] {ev['count']}ëª… ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë¨\n"
                
                max_count = max([ev['count'] for ev in count_analysis['evidence']])
                enhanced_context += f"\nâœ… ê²°ë¡ : í•œ ìž¥ë©´ì—ì„œ ìµœëŒ€ {max_count}ëª…ì´ ë“±ìž¥í•˜ë©°, ì´ëŠ” ê°™ì€ ì‚¬ëžŒë“¤ì´ ë‹¤ë¥¸ í”„ë ˆìž„ì—ë„ ë‚˜íƒ€ë‚˜ë¯€ë¡œ ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì‚¬ëžŒ ìˆ˜ëŠ” ì•½ {max_count}ëª…ìž…ë‹ˆë‹¤.\n"
            
            enhanced_context += f"\nâš ï¸ ì£¼ì˜: ê° í”„ë ˆìž„ì˜ ì‚¬ëžŒ ìˆ˜ë¥¼ í•©ì‚°í•˜ì§€ ë§ê³ , ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì¸ì›ì„ ë‹µë³€í•˜ì„¸ìš”.\n"
            enhanced_context += f"\nì›ëž˜ ì§ˆë¬¸: {message}"
            
            # ë‹¤ì¤‘ AIë¡œ ë‹µë³€ ìƒì„± (ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            ai_result = self.generate_answer_with_multi_ai(enhanced_context, evidence_frames if evidence_frames else None)
            if isinstance(ai_result, dict):
                result['answer'] = ai_result.get('integrated', '')
                result['individual_responses'] = ai_result.get('individual', {})
            else:
                result['answer'] = ai_result
            
            return result
        
        # 4. ì„±ë¹„ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        gender_ratio_keywords = ['ì„±ë¹„', 'ë‚¨ë…€ë¹„', 'ì„±ë³„', 'ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨ìž', 'ì—¬ìž', 'gender ratio', 'male female']
        is_gender_ratio_question = any(keyword in message.lower() for keyword in gender_ratio_keywords)
        
        if is_gender_ratio_question:
            # ì„±ë¹„ ë¶„ì„
            gender_analysis = self.analyze_gender_ratio()
            
            # ì¦ê±° í”„ë ˆìž„ ì°¾ê¸°
            evidence_frames = []
            if gender_analysis['evidence']:
                for evidence in gender_analysis['evidence'][:3]:  # ìµœëŒ€ 3ê°œ
                    for frame in self.frames:
                        if frame.get('timestamp') == evidence['timestamp']:
                            evidence_frames.append(frame)
                            break
            
            if evidence_frames:
                result['frames'] = evidence_frames
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in evidence_frames
                ]
            
            # ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ AI ë‹µë³€ ìƒì„±
            enhanced_context = f"""ðŸŽ¯ ì¤‘ìš”: ì˜ìƒì˜ ì„±ë¹„(ë‚¨ë…€ ë¹„ìœ¨)ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”!

ì˜ìƒ ì„±ë¹„ ë¶„ì„ ê²°ê³¼:
- ë‚¨ì„±: {gender_analysis['male_count']}ëª… ({gender_analysis['male_ratio']:.1f}%)
- ì—¬ì„±: {gender_analysis['female_count']}ëª… ({gender_analysis['female_ratio']:.1f}%)
- ì„±ë³„ ëª…ì‹œëœ ì´ ì¸ì›: {gender_analysis['total_gendered']}ëª…
- ì‹ ë¢°ë„: {gender_analysis['confidence']}
- ë¶„ì„ ê·¼ê±°: {gender_analysis['explanation']}

í”„ë ˆìž„ë³„ ì„±ë³„ ì •ë³´:
"""
            if gender_analysis['evidence']:
                for i, ev in enumerate(gender_analysis['evidence'][:5], 1):
                    enhanced_context += f"{i}. [{ev['timestamp']:.1f}ì´ˆ] ë‚¨ì„± {ev['males']}ëª…, ì—¬ì„± {ev['females']}ëª…\n"
            
            enhanced_context += f"\nâš ï¸ ì£¼ì˜: ì„±ë³„ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ì¸ë¬¼ë„ ìžˆì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ, ì „ì²´ ì¸ì› ìˆ˜ì™€ ì°¨ì´ê°€ ë‚  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
            enhanced_context += f"\nì›ëž˜ ì§ˆë¬¸: {message}"
            
            # ë‹¤ì¤‘ AIë¡œ ë‹µë³€ ìƒì„±
            ai_result = self.generate_answer_with_multi_ai(enhanced_context, evidence_frames if evidence_frames else None)
            if isinstance(ai_result, dict):
                result['answer'] = ai_result.get('integrated', '')
                result['individual_responses'] = ai_result.get('individual', {})
            else:
                result['answer'] = ai_result
            
            return result
        
        # 5. ìƒ‰ìƒ ê²€ìƒ‰ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        color_keywords = {
            'ë¶„í™': 'pink', 'í•‘í¬': 'pink', 'pink': 'pink',
            'ë¹¨ê°•': 'red', 'ë¹¨ê°„': 'red', 'red': 'red',
            'íŒŒëž‘': 'blue', 'íŒŒëž€': 'blue', 'blue': 'blue',
            'ë…¸ëž‘': 'yellow', 'ë…¸ëž€': 'yellow', 'yellow': 'yellow',
            'ì´ˆë¡': 'green', 'ë…¹ìƒ‰': 'green', 'green': 'green',
            'í•˜ì–‘': 'white', 'í°': 'white', 'white': 'white',
            'ê²€ì •': 'black', 'ê²€ì€': 'black', 'black': 'black',
            'ì£¼í™©': 'orange', 'ì˜¤ë Œì§€': 'orange', 'orange': 'orange',
            'ë³´ë¼': 'purple', 'purple': 'purple',
            'íšŒìƒ‰': 'gray', 'gray': 'gray', 'grey': 'gray'
        }
        
        found_color = None
        for korean, english in color_keywords.items():
            if korean in message.lower():
                found_color = english
                break
        
        if found_color:
            # ìƒ‰ìƒ ê¸°ë°˜ ê²€ìƒ‰
            context_frames = self.search_frames_by_color(found_color)
            
            if context_frames:
                result['frames'] = context_frames[:10]  # ìµœëŒ€ 10ê°œ
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in context_frames[:10]
                ]
                
                # ë‹µë³€ ìƒì„± (ë‹¤ì¤‘ AI)
                ai_result = self.generate_answer_with_multi_ai(message, context_frames)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
            else:
                result['answer'] = f"ì˜ìƒì—ì„œ {found_color} ìƒ‰ìƒì˜ ì˜·ì„ ìž…ì€ ì‚¬ëžŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        else:
            # ì¼ë°˜ ì˜ìƒ ì§ˆë¬¸ (í‚¤ì›Œë“œ ê²€ìƒ‰)
            # ì˜ë¯¸ ìžˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (ë¶ˆìš©ì–´ ì œê±°)
            import re
            message_lower = message.lower()
            stopwords = ['ë³´ì—¬ì¤˜', 'ì•Œë ¤ì¤˜', 'ìžˆë‚˜ìš”', 'ë‚˜ì™€', 'ë“±ìž¥', 'ìž¥ë©´', 'ë‚˜ì˜¤ëŠ”', 'í•˜ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ì°¾ì•„ì¤˜', 'ì°¾ì•„', 'í”„ë ˆìž„ì€', 'í”„ë ˆìž„']
            
            # í•œêµ­ì–´ ë‹¨ì–´ ì¶”ì¶œ
            korean_words = re.findall(r'[ê°€-íž£]+', message)
            keywords = []
            for word in korean_words:
                # ì¡°ì‚¬ ì œê±°
                cleaned = re.sub(r'[ì´ê°€ì„ë¥¼ì—ì˜]$', '', word)
                if cleaned and cleaned not in stopwords and len(cleaned) > 1:
                    keywords.append(cleaned)
            
            # ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ
            english_words = re.findall(r'[a-zA-Z]+', message_lower)
            for word in english_words:
                if word not in stopwords and len(word) > 1:
                    keywords.append(word)
            
            # í•œêµ­ì–´ -> ì˜ì–´ ê°ì²´ëª… ë§¤í•‘
            korean_to_english_objects = {
                # ì‚¬ëžŒ/ë™ë¬¼
                'ì‚¬ëžŒ': ['person', 'people', 'human'],
                'ì–´ë¦°ì´': ['child', 'children', 'kid', 'kids'],
                'ì•„ì´': ['child', 'children', 'kid', 'kids'],
                'ì•„ë™': ['child', 'children', 'kid', 'kids'],
                'ë…¸ì¸': ['elderly', 'old person', 'senior'],
                'ê°•ì•„ì§€': ['dog', 'puppy'],
                'ê°œ': ['dog'],
                'ê³ ì–‘ì´': ['cat', 'kitten'],
                'ì†Œ': ['cow', 'cattle'],
                'ë™ë¬¼': ['animal', 'dog', 'cat', 'cow', 'bird'],
                
                # ì°¨ëŸ‰
                'ìžë™ì°¨': ['car', 'vehicle', 'automobile'],
                'ì°¨': ['car', 'vehicle'],
                'ì°¨ëŸ‰': ['vehicle', 'car', 'bus'],
                'íŠ¸ëŸ­': ['truck', 'lorry'],
                'ë²„ìŠ¤': ['bus'],
                'ì˜¤í† ë°”ì´': ['motorcycle', 'motorbike', 'bike'],
                'ìžì „ê±°': ['bicycle', 'bike'],
                
                # ê°€ë°©/ì†Œì§€í’ˆ
                'ê°€ë°©': ['bag', 'backpack', 'handbag', 'purse'],
                'ë°±íŒ©': ['backpack', 'rucksack'],
                'í•¸ë“œë°±': ['handbag', 'purse'],
                'ì„œë¥˜ê°€ë°©': ['briefcase'],
                'ì§€ê°‘': ['wallet', 'purse'],
                'ìš°ì‚°': ['umbrella'],
                'ì–‘ì‚°': ['umbrella', 'parasol'],
                'ìˆ˜í•˜ë¬¼': ['suitcase', 'luggage', 'baggage'],
                'ì—¬í–‰ê°€ë°©': ['suitcase', 'luggage'],
                
                # ê°€êµ¬
                'ì˜ìž': ['chair', 'seat'],
                'ë²¤ì¹˜': ['bench', 'seat'],
                'í…Œì´ë¸”': ['table', 'desk'],
                'ì‹íƒ': ['dining table', 'table'],
                'ì¹¨ëŒ€': ['bed'],
                'ì†ŒíŒŒ': ['sofa', 'couch'],
                
                # ì „ìžì œí’ˆ
                'í…”ë ˆë¹„ì „': ['tv', 'television'],
                'í‹°ë¹„': ['tv', 'television'],
                'TV': ['tv', 'television'],
                'ë…¸íŠ¸ë¶': ['laptop', 'notebook'],
                'ì»´í“¨í„°': ['computer', 'laptop', 'pc'],
                'ìŠ¤ë§ˆíŠ¸í°': ['cell phone', 'mobile phone', 'phone'],
                'í•¸ë“œí°': ['cell phone', 'mobile phone', 'phone'],
                'ì „í™”ê¸°': ['phone', 'telephone'],
                
                # ìŒì‹/ì‹ê¸°
                'ë³‘': ['bottle'],
                'ì»µ': ['cup', 'mug'],
                'ìž”': ['cup', 'glass'],
                'ì ‘ì‹œ': ['plate', 'dish'],
                'í¬í¬': ['fork'],
                'ë‚˜ì´í”„': ['knife'],
                'ìˆŸê°€ë½': ['spoon'],
                
                # ê¸°íƒ€
                'ë§ˆìŠ¤ì½”íŠ¸': ['mascot', 'character', 'costume'],
                'ìºë¦­í„°': ['character', 'mascot', 'costume'],
                'ì¸í˜•': ['teddy bear', 'doll', 'toy'],
                'ê³°ì¸í˜•': ['teddy bear', 'bear'],
                'ì‹ í˜¸ë“±': ['traffic light', 'traffic signal'],
                'í‘œì§€íŒ': ['sign', 'signboard'],
                'ë„¥íƒ€ì´': ['tie', 'neckite', 'neck tie'],
                'ì„œí•‘ë³´ë“œ': ['surfboard'],
                'ë³´ë“œ': ['surfboard', 'skateboard'],
                'ì‚¬ìž': ['lion'],
                'ê²½ì°°': ['police', 'officer'],
            }
            
            for korean, english_list in korean_to_english_objects.items():
                if korean in message:
                    keywords.extend(english_list)
                    logger.info(f"  âœ… í•œêµ­ì–´ '{korean}' -> ì˜ì–´ í‚¤ì›Œë“œ ì¶”ê°€: {english_list}")
            
            # íŠ¹ìˆ˜ íŒ¨í„´ ë§¤ì¹­
            if 'ëª¨ìž' in message:
                keywords.extend(['hat', 'cap', 'beanie'])
            if 'ê¸°íƒ€' in message:
                keywords.extend(['guitar'])
            if 'ì»¤í”¼' in message:
                keywords.extend(['coffee', 'cup'])
            if 'ì–´ë¦°ì´' in message or 'ì•„ì´' in message or 'ì•„ë™' in message:
                keywords.extend(['child', 'children', 'kid', 'kids'])
            
            if keywords:
                context_frames = self.search_frames_by_keywords(keywords[:5])  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
                
                if context_frames:
                    result['frames'] = context_frames[:10]
                    result['frame_images'] = [
                        frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                        for frame in context_frames[:10]
                    ]
                
                # ë‹µë³€ ìƒì„± (ë‹¤ì¤‘ AI)
                ai_result = self.generate_answer_with_multi_ai(message, context_frames if context_frames else None)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
            else:
                # ì „ì²´ ì˜ìƒ ìš”ì•½ ì§ˆë¬¸
                ai_result = self.generate_answer_with_multi_ai(message, None)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
        
        return result


def get_video_chat_handler(video_id, video):
    """ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return EnhancedVideoChatHandler(video_id, video)