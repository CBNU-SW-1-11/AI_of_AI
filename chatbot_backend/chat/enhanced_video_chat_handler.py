"""
ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬
- Ollama ìº¡ì…˜ ê¸°ë°˜ ë‹µë³€
- ë‹¤ì¤‘ AI ëª¨ë¸ (GPT, Claude, Mixtral) í†µí•©
- ìƒ‰ìƒ 2ì¤‘ ê²€ì¦ (ìº¡ì…˜ + ì¶”ì¶œëœ ìƒ‰ìƒ)
- ì˜ìƒ/ì¼ë°˜ ì§ˆë¬¸ ìë™ êµ¬ë¶„
"""

import os
import json
import logging
import ollama
from django.conf import settings

logger = logging.getLogger(__name__)


def get_chatbots():
    """chatbots ì „ì—­ ë³€ìˆ˜ë¥¼ ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜ (lazy import)"""
    try:
        from ..utils.chatbot import chatbots
        return chatbots
    except Exception as e:
        logger.warning(f"âš ï¸ chatbots import ì‹¤íŒ¨: {e}")
        return {}


class EnhancedVideoChatHandler:
    """ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬"""
    
    def __init__(self, video_id, video):
        self.video_id = video_id
        self.video = video
        self.meta_db = None
        self.detection_db = None
        self.frames = []
        self._load_analysis_data()
    
    def _load_analysis_data(self):
        """ì˜ìƒ ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            # Meta DB ë¡œë“œ (Ollama ìº¡ì…˜ í¬í•¨)
            video_name = self.video.original_name or self.video.filename
            meta_db_path = os.path.join(settings.MEDIA_ROOT, f"{video_name}-meta_db.json")
            
            if os.path.exists(meta_db_path):
                with open(meta_db_path, 'r', encoding='utf-8') as f:
                    self.meta_db = json.load(f)
                self.frames = self.meta_db.get('frame', [])
                logger.info(f"âœ… Meta DB ë¡œë“œ ì„±ê³µ: {len(self.frames)}ê°œ í”„ë ˆì„")
            else:
                logger.warning(f"âŒ Meta DB íŒŒì¼ ì—†ìŒ: {meta_db_path}")
        
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def is_video_related_question(self, message):
        """ì˜ìƒ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        video_keywords = [
            'ì˜ìƒ', 'video', 'ë™ì˜ìƒ', 'ë¹„ë””ì˜¤',
            'ì‚¬ëŒ', 'people', 'person', 'ë‚¨ì', 'ì—¬ì', 'man', 'woman',
            'ì˜·', 'clothing', 'shirt', 'jacket', 'ìƒ‰ìƒ', 'color',
            'ë°°ê²½', 'background', 'scene', 'ì¥ë©´',
            'ëª‡', 'how many', 'count', 'ê°œìˆ˜',
            'ìˆ', 'is there', 'are there',
            'ì°¾', 'find', 'search',
            'ì‡¼í•‘ëª°', 'mall', 'shopping',
            'ê±°ë¦¬', 'street', 'ë°¤', 'night', 'ë‚®', 'day',
            'ì „í™”', 'phone', 'ê±·', 'walk',
            'ìš”ì•½', 'summary', 'summarize'
        ]
        
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in video_keywords)
    
    def search_frames_by_keywords(self, keywords):
        """í‚¤ì›Œë“œë¡œ í”„ë ˆì„ ê²€ìƒ‰ (ìº¡ì…˜ ê¸°ë°˜)"""
        found_frames = []
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            
            # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ìº¡ì…˜ì— ìˆìœ¼ë©´ ë§¤ì¹­ (ì ìˆ˜ ê¸°ë°˜)
            match_score = 0
            for keyword in keywords:
                if keyword.lower() in caption:
                    match_score += 1
            
            # ì ì–´ë„ í•˜ë‚˜ ì´ìƒì˜ í‚¤ì›Œë“œê°€ ë§¤ì¹­ë˜ë©´ ì¶”ê°€
            if match_score > 0:
                frame_with_score = frame.copy()
                frame_with_score['match_score'] = match_score
                found_frames.append(frame_with_score)
        
        # ë§¤ì¹­ ì ìˆ˜ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        found_frames.sort(key=lambda x: x.get('match_score', 0), reverse=True)
        
        return found_frames
    
    def search_frames_by_color(self, color_name):
        """ìƒ‰ìƒìœ¼ë¡œ í”„ë ˆì„ ê²€ìƒ‰ (ìº¡ì…˜ ìš°ì„  + ìƒ‰ìƒ ì¶”ì¶œ ë³´ì¡°)"""
        if not color_name:
            return []
        
        found_frames = []
        color_name_lower = color_name.lower()
        
        # í•œêµ­ì–´ â†’ ì˜ì–´ ê¸°ë³¸ ìƒ‰ìƒ ë§¤í•‘
        korean_to_english = {
            'ë¶„í™ìƒ‰': 'pink',
            'í•‘í¬': 'pink',
            'ë³´ë¼ìƒ‰': 'purple',
            'ë³´ë¼': 'purple',
            'ìì£¼ìƒ‰': 'purple',
            'ìí™ìƒ‰': 'purple',
            'íŒŒë€ìƒ‰': 'blue',
            'íŒŒë‘': 'blue',
            'í‘¸ë¥¸ìƒ‰': 'blue',
            'ë‚¨ìƒ‰': 'blue',
            'í•˜ëŠ˜ìƒ‰': 'blue',
            'ì´ˆë¡ìƒ‰': 'green',
            'ì´ˆë¡': 'green',
            'ë…¹ìƒ‰': 'green',
            'ì—°ë‘ìƒ‰': 'green',
            'ë…¸ë€ìƒ‰': 'yellow',
            'ë…¸ë‘': 'yellow',
            'í™©ìƒ‰': 'yellow',
            'ì£¼í™©ìƒ‰': 'orange',
            'ì£¼í™©': 'orange',
            'ì˜¤ë Œì§€': 'orange',
            'ë¹¨ê°„ìƒ‰': 'red',
            'ë¹¨ê°•': 'red',
            'ì ìƒ‰': 'red',
            'í°ìƒ‰': 'white',
            'í•˜ì–€ìƒ‰': 'white',
            'ê²€ì€ìƒ‰': 'black',
            'ê¹Œë§Œìƒ‰': 'black',
            'íšŒìƒ‰': 'gray',
            'ê·¸ë ˆì´': 'gray',
            'ì€ìƒ‰': 'gray',
            'ì€ë¹›': 'gray'
        }
        
        base_color = korean_to_english.get(color_name_lower, color_name_lower)
        
        # ìƒ‰ìƒ ë™ì˜ì–´ ë§¤í•‘ (pink -> rose, fuchsia ë“±)
        color_synonyms = {
            'pink': ['pink', 'rose', 'fuchsia', 'magenta', 'rosy'],
            'red': ['red', 'crimson', 'scarlet'],
            'orange': ['orange', 'amber', 'tangerine'],
            'yellow': ['yellow', 'gold', 'golden'],
            'green': ['green', 'lime', 'emerald'],
            'blue': ['blue', 'navy', 'azure', 'teal'],
            'purple': ['purple', 'violet', 'lavender'],
            'white': ['white', 'ivory'],
            'black': ['black'],
            'gray': ['gray', 'grey', 'silver']
        }
        synonyms = color_synonyms.get(base_color, [base_color])
        
        # ì›ë³¸ ê²€ìƒ‰ì–´(í•œêµ­ì–´ í¬í•¨)ë¥¼ ë³´ì¡° í‚¤ì›Œë“œë¡œ ì¶”ê°€
        if color_name_lower not in synonyms:
            synonyms.append(color_name_lower)
        
        for frame in self.frames:
            match_score = 0
            caption = frame.get('caption', '').lower()
            caption_weight = 3  # Ollama ìº¡ì…˜ ìš°ì„  ê°€ì¤‘ì¹˜
            color_weight = 1    # ìƒ‰ìƒ ì¶”ì¶œ ë³´ì¡° ê°€ì¤‘ì¹˜
            
            # 1. ìº¡ì…˜ì—ì„œ ìƒ‰ìƒ ê²€ìƒ‰ (ìš°ì„  ìˆœìœ„ ë†’ìŒ)
            if any(word in caption for word in synonyms):
                match_score += caption_weight
            
            # 2. ì¶”ì¶œëœ ìƒ‰ìƒ ì •ë³´ í™•ì¸ (ë³´ì¡°)
            objects = frame.get('objects', [])
            for obj in objects:
                if obj.get('class') == 'person':
                    clothing_colors = obj.get('clothing_colors', {})
                    upper_color = (clothing_colors.get('upper') or '').lower()
                    lower_color = (clothing_colors.get('lower') or '').lower()
                    if any(word in upper_color for word in synonyms) or any(word in lower_color for word in synonyms):
                        match_score += color_weight
                        break
            
            if match_score > 0:
                frame_with_score = frame.copy()
                frame_with_score['match_score'] = match_score
                found_frames.append(frame_with_score)
        
        # ìº¡ì…˜ ë§¤ì¹­ ìš°ì„ , ì´í›„ ì ìˆ˜ ìˆœ ì •ë ¬
        found_frames.sort(key=lambda x: (x.get('match_score', 0), x.get('timestamp', 0)), reverse=True)
        
        # ì¤‘ë³µ íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° í›„ ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
        unique_frames = []
        seen_timestamps = set()
        for frame in found_frames:
            ts_key = round(frame.get('timestamp', 2))
            if ts_key in seen_timestamps:
                continue
            unique_frames.append(frame)
            seen_timestamps.add(ts_key)
            if len(unique_frames) >= 5:
                break
        
        return unique_frames
    
    def analyze_people_count(self):
        """ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì‚¬ëŒ ìˆ˜ ë¶„ì„ (í”„ë ˆì„ë³„ ì¤‘ë³µ ê³ ë ¤)"""
        import re
        
        # ê° í”„ë ˆì„ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ì‚¬ëŒ ìˆ˜ ì¶”ì¶œ
        people_counts = []
        
        number_words = {
            'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,
            'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10
        }
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            timestamp = frame.get('timestamp', 0)
            
            # "five people", "three individuals", "two men" ë“±ì˜ íŒ¨í„´ ì°¾ê¸°
            for num_word, num in number_words.items():
                patterns = [
                    f'{num_word} people',
                    f'{num_word} individuals',
                    f'{num_word} men',
                    f'{num_word} women',
                    f'{num_word} persons'
                ]
                
                for pattern in patterns:
                    if pattern in caption:
                        people_counts.append({
                            'timestamp': timestamp,
                            'count': num,
                            'caption_excerpt': caption[:100]
                        })
                        break
                
                if people_counts and people_counts[-1]['timestamp'] == timestamp:
                    break
        
        # ìµœëŒ€ ì‚¬ëŒ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨ (ê°™ì€ ì‚¬ëŒë“¤ì´ ì—¬ëŸ¬ í”„ë ˆì„ì— ë“±ì¥)
        if people_counts:
            max_count_info = max(people_counts, key=lambda x: x['count'])
            max_count = max_count_info['count']
            
            return {
                'estimated_count': max_count,
                'confidence': 'high',
                'evidence': people_counts,
                'explanation': f"í”„ë ˆì„ ë¶„ì„ ê²°ê³¼, í•œ ì¥ë©´ì—ì„œ ìµœëŒ€ {max_count}ëª…ì´ ë“±ì¥í•©ë‹ˆë‹¤. ì˜ìƒ ì „ì²´ì—ì„œëŠ” ê°™ì€ ì‚¬ëŒë“¤ì´ ì—¬ëŸ¬ í”„ë ˆì„ì— ë‚˜íƒ€ë‚˜ë¯€ë¡œ, ê³ ìœ í•œ ì‚¬ëŒ ìˆ˜ëŠ” ì•½ {max_count}ëª… ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤."
            }
        else:
            # ëª…ì‹œì  ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ "group", "people" ë“±ìœ¼ë¡œ ì¶”ì •
            group_count = sum(1 for f in self.frames if 'group' in f.get('caption', '').lower() or 'people' in f.get('caption', '').lower())
            
            if group_count > 0:
                return {
                    'estimated_count': '3-5',
                    'confidence': 'medium',
                    'evidence': [],
                    'explanation': f"ì˜ìƒì—ì„œ ì—¬ëŸ¬ ëª…ì˜ ì‚¬ëŒë“¤ì´ ê·¸ë£¹ìœ¼ë¡œ ë“±ì¥í•˜ì§€ë§Œ, ì •í™•í•œ ìˆ«ìëŠ” ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëŒ€ëµ 3-5ëª… ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤."
                }
            else:
                return {
                    'estimated_count': 'unknown',
                    'confidence': 'low',
                    'evidence': [],
                    'explanation': "ì˜ìƒ ë¶„ì„ì—ì„œ ì‚¬ëŒ ìˆ˜ë¥¼ ëª…í™•íˆ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
    
    def analyze_gender_ratio(self):
        """ì˜ìƒ ì „ì²´ì˜ ì„±ë¹„ ë¶„ì„"""
        import re
        
        # ì„±ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        gender_keywords = {
            'man': 'male', 'men': 'male', 'male': 'male',
            'woman': 'female', 'women': 'female', 'female': 'female',
            'boy': 'male', 'boys': 'male',
            'girl': 'female', 'girls': 'female'
        }
        
        # ì—°ë ¹ëŒ€ í‚¤ì›Œë“œ
        age_keywords = {
            'young': 'young', 'teen': 'young', 'teenage': 'young',
            'adult': 'adult', 'middle-aged': 'adult',
            'elderly': 'elderly', 'old': 'elderly', 'senior': 'elderly'
        }
        
        male_count = 0
        female_count = 0
        unknown_count = 0
        
        gender_evidence = []
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            timestamp = frame.get('timestamp', 0)
            
            # ì„±ë³„ í‚¤ì›Œë“œ ì°¾ê¸°
            frame_males = 0
            frame_females = 0
            
            for keyword, gender in gender_keywords.items():
                matches = re.findall(rf'\b{keyword}\b', caption)
                if matches:
                    for match in matches:
                        if gender == 'male':
                            frame_males += 1
                        else:
                            frame_females += 1
            
            if frame_males > 0 or frame_females > 0:
                gender_evidence.append({
                    'timestamp': timestamp,
                    'males': frame_males,
                    'females': frame_females,
                    'caption_excerpt': caption[:100]
                })
        
        # ì „ì²´ ì„±ë³„ ì¹´ìš´íŠ¸
        total_males = sum(ev['males'] for ev in gender_evidence)
        total_females = sum(ev['females'] for ev in gender_evidence)
        
        if total_males > 0 or total_females > 0:
            total_people = total_males + total_females
            male_ratio = (total_males / total_people) * 100 if total_people > 0 else 0
            female_ratio = (total_females / total_people) * 100 if total_people > 0 else 0
            
            return {
                'male_count': total_males,
                'female_count': total_females,
                'total_gendered': total_people,
                'male_ratio': round(male_ratio, 1),
                'female_ratio': round(female_ratio, 1),
                'confidence': 'medium' if len(gender_evidence) > 2 else 'low',
                'evidence': gender_evidence,
                'explanation': f"ì˜ìƒì—ì„œ ì„±ë³„ì´ ëª…ì‹œëœ ì¸ë¬¼: ë‚¨ì„± {total_males}ëª…, ì—¬ì„± {total_females}ëª… (ë‚¨ì„± {male_ratio:.1f}%, ì—¬ì„± {female_ratio:.1f}%)"
            }
        else:
            return {
                'male_count': 0,
                'female_count': 0,
                'total_gendered': 0,
                'male_ratio': 0,
                'female_ratio': 0,
                'confidence': 'low',
                'evidence': [],
                'explanation': "ì˜ìƒ ë¶„ì„ì—ì„œ ì„±ë³„ ì •ë³´ë¥¼ ëª…í™•íˆ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìº¡ì…˜ì— ì„±ë³„ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
    
    def generate_answer_with_multi_ai(self, message, context_frames=None, include_video_context=True):
        """ë‹¤ì¤‘ AI ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„± ë° í†µí•©"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            if include_video_context:
                context = f"ì˜ìƒ ì •ë³´:\n"
                context += f"- ì´ í”„ë ˆì„ ìˆ˜: {len(self.frames)}ê°œ\n"
                context += f"- ì˜ìƒ ê¸¸ì´: {self.video.duration}ì´ˆ\n\n"
            else:
                context = ""
            
            if context_frames:
                context += f"ê´€ë ¨ í”„ë ˆì„ ({len(context_frames)}ê°œ):\n"
                for i, frame in enumerate(context_frames[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
                    timestamp = frame.get('timestamp', 0)
                    caption = frame.get('caption', '')
                    context += f"{i}. [{timestamp:.1f}s] {caption[:200]}\n"
            else:
                # ì „ì²´ ìš”ì•½
                context += "ì˜ìƒ ì£¼ìš” ë‚´ìš©:\n"
                for i, frame in enumerate(self.frames[::max(1, len(self.frames)//5)], 1):  # ìƒ˜í”Œ 5ê°œ
                    timestamp = frame.get('timestamp', 0)
                    caption = frame.get('caption', '')
                    context += f"- [{timestamp:.1f}s] {caption[:150]}\n"
            
            # AI ì§ˆë¬¸ êµ¬ì„±
            if include_video_context:
                ai_prompt = f"""ë‹¤ìŒ ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{context}

ì‚¬ìš©ì ì§ˆë¬¸: {message}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€ (ìµœëŒ€ 3-4ë¬¸ì¥)
2. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëµ
4. í•œêµ­ì–´ë¡œ ì‘ì„±"""
            else:
                ai_prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {message}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€ (ìµœëŒ€ 2-3ë¬¸ì¥)
2. ì¹œê·¼í•œ í†¤ ìœ ì§€
3. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëµ
4. í•œêµ­ì–´ë¡œ ì‘ì„±"""
            
            # ë‹¤ì¤‘ AI ì‘ë‹µ ìƒì„±
            ai_responses = {}
            
            # chatbots ê°€ì ¸ì˜¤ê¸° (lazy import)
            chatbots = get_chatbots()
            
            # ìš°ì„ ìˆœìœ„ AI ëª¨ë¸ ì„ íƒ (chatbotsì˜ í‚¤ ì´ë¦„)
            priority_model_keys = [
                'gpt-4o-mini',           # GPT-4o Mini
                'gemini-2.0-flash-lite', # Gemini 2.0 Flash Lite
                'claude-3.5-haiku'       # Claude 3.5 Haiku
            ]
            
            # chatbotsì—ì„œ ì§€ì •ëœ ëª¨ë¸ ì°¾ì•„ì„œ ë‹µë³€ ìƒì„±
            if chatbots:
                for model_key in priority_model_keys:
                    if model_key in chatbots:
                        try:
                            bot = chatbots[model_key]
                            response = bot.chat(ai_prompt)
                            ai_responses[model_key] = response
                            logger.info(f"âœ… {model_key} ë‹µë³€ ìƒì„± ì™„ë£Œ")
                        except Exception as e:
                            logger.warning(f"âš ï¸ {model_key} ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                    else:
                        logger.warning(f"âš ï¸ {model_key} ëª¨ë¸ì„ chatbotsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # Ollamaë¥¼ ë°±ì—…ìœ¼ë¡œ ì¶”ê°€ (ë¬´ë£Œ)
            try:
                response = ollama.chat(
                    model='llama3.2:latest',
                    messages=[{
                        'role': 'user',
                        'content': ai_prompt
                    }],
                    options={
                        'temperature': 0.7,
                        'num_predict': 500
                    }
                )
                # OllamaëŠ” í•­ìƒ í¬í•¨ (ë¬´ë£Œì´ë¯€ë¡œ)
                # ai_responses['ollama'] = response['message']['content'].strip()
                # logger.info(f"âœ… Ollama ë‹µë³€ ìƒì„± ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ Ollama ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ì‘ë‹µì´ ì—†ìœ¼ë©´ Ollamaë§Œ ì‚¬ìš©
            if not ai_responses:
                logger.warning("âš ï¸ ëª¨ë“  AI ëª¨ë¸ ì‹¤íŒ¨, Ollamaë¡œ ì¬ì‹œë„")
                response = ollama.chat(
                    model='llama3.2:latest',
                    messages=[{'role': 'user', 'content': ai_prompt}],
                    options={'temperature': 0.7, 'num_predict': 500}
                )
                ollama_answer = response['message']['content'].strip()
                return {
                    'integrated': ollama_answer,
                    'individual': {'ollama': ollama_answer}
                }
            
            # ì‘ë‹µì´ 1ê°œë§Œ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if len(ai_responses) == 1:
                single_answer = list(ai_responses.values())[0]
                return {
                    'integrated': single_answer,
                    'individual': ai_responses
                }
            
            # ë‹¤ì¤‘ ì‘ë‹µ í†µí•©
            integrated_answer = self._integrate_multi_ai_responses(ai_responses, message)
            
            # ê°œë³„ ì‘ë‹µ + í†µí•© ì‘ë‹µ ë°˜í™˜
            return {
                'integrated': integrated_answer,
                'individual': ai_responses
            }
            
        except Exception as e:
            logger.error(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _integrate_multi_ai_responses(self, ai_responses, original_question):
        """ë‹¤ì¤‘ AI ì‘ë‹µ í†µí•© (HCX-DASH-001 ì‚¬ìš©)"""
        try:
            # ê° AIì˜ ì‘ë‹µì„ ì •ë¦¬
            responses_text = ""
            for model_name, response in ai_responses.items():
                responses_text += f"### {model_name.upper()}:\n{response}\n\n"
            
            # HCX-DASH-001ë¡œ í†µí•© ë‹µë³€ ìƒì„±
            chatbots = get_chatbots()
            hcx_bot = None
            
            # HCX-DASH-001 ì°¾ê¸° (ì •í™•í•œ í‚¤ ì´ë¦„)
            hcx_model_keys = ['clova-hcx-dash-001', 'HCX-DASH-001', 'hcx-dash-001']
            for key in hcx_model_keys:
                if key in chatbots:
                    hcx_bot = chatbots[key]
                    logger.info(f"âœ… HCX-DASH-001 ëª¨ë¸ ë°œê²¬: {key}")
                    break
            
            integration_prompt = f"""ë‹¤ìŒì€ ì—¬ëŸ¬ AI ëª¨ë¸ì´ ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ í†µí•©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {original_question}

{responses_text}

í†µí•© ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ í†µí•© (ìµœëŒ€ 3-4ë¬¸ì¥)
2. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëµ
4. í•œêµ­ì–´ë¡œ ì‘ì„±

í†µí•© ë‹µë³€:"""
            
            # HCX-DASH-001 ì‚¬ìš©
            if hcx_bot:
                try:
                    integrated = hcx_bot.chat(integration_prompt)
                    logger.info(f"âœ… HCX-DASH-001 í†µí•© ë‹µë³€ ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ HCX-DASH-001 ì‹¤íŒ¨, Ollamaë¡œ ëŒ€ì²´: {e}")
                    response = ollama.chat(
                        model='llama3.2:latest',
                        messages=[{'role': 'user', 'content': integration_prompt}],
                        options={'temperature': 0.5, 'num_predict': 800}
                    )
                    integrated = response['message']['content'].strip()
            else:
                # HCX-DASH-001ì´ ì—†ìœ¼ë©´ Ollama ì‚¬ìš©
                logger.warning("âš ï¸ HCX-DASH-001 ì—†ìŒ, Ollama ì‚¬ìš©")
                response = ollama.chat(
                    model='llama3.2:latest',
                    messages=[{'role': 'user', 'content': integration_prompt}],
                    options={'temperature': 0.5, 'num_predict': 800}
                )
                integrated = response['message']['content'].strip()
            
            # ê° AI ë¶„ì„ ì¶”ê°€
            integrated += "\n\n---\n**ê° AI ë¶„ì„:**\n"
            for model_name in ai_responses.keys():
                integrated += f"- {model_name.upper()}\n"
            
            return integrated
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì‘ë‹µ ë°˜í™˜
            return list(ai_responses.values())[0]
    
    def handle_general_question(self, message):
        """ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ (ì˜ìƒ ë¬´ê´€)"""
        try:
            response = ollama.chat(
                model='llama3.2:latest',
                messages=[{
                    'role': 'user',
                    'content': message
                }],
                options={
                    'temperature': 0.7,
                    'num_predict': 500
                }
            )
            
            return response['message']['content'].strip()
            
        except Exception as e:
            logger.error(f"âŒ ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def process_message(self, message):
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        
        Returns:
            dict: {
                'answer': str,  # í†µí•© ë‹µë³€
                'individual_responses': dict,  # ê° AI ê°œë³„ ë‹µë³€
                'frames': list,  # ê´€ë ¨ í”„ë ˆì„ ì •ë³´
                'frame_images': list,  # í”„ë ˆì„ ì´ë¯¸ì§€ ê²½ë¡œ
                'is_video_related': bool
            }
        """
        result = {
            'answer': '',
            'individual_responses': {},
            'frames': [],
            'frame_images': [],
            'is_video_related': False
        }
        
        # 1. ì˜ìƒ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        if not self.is_video_related_question(message):
            # ì¼ë°˜ ì§ˆë¬¸ë„ ë‹¤ì¤‘ AIë¡œ ì²˜ë¦¬ (ì˜ìƒ ì»¨í…ìŠ¤íŠ¸ ì œì™¸)
            ai_result = self.generate_answer_with_multi_ai(message, None, include_video_context=False)
            if isinstance(ai_result, dict):
                result['answer'] = ai_result.get('integrated', '')
                result['individual_responses'] = ai_result.get('individual', {})
            else:
                result['answer'] = ai_result
            result['is_video_related'] = False
            return result
        
        result['is_video_related'] = True
        
        # 2. í•˜ì´ë¼ì´íŠ¸/ìš”ì•½ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        highlight_keywords = ['í•˜ì´ë¼ì´íŠ¸', 'highlight', 'ì£¼ìš” ì¥ë©´', 'í•µì‹¬ ì¥ë©´', 'ì¤‘ìš”í•œ ì¥ë©´']
        summary_keywords = ['ìš”ì•½', 'summary', 'ì •ë¦¬']
        
        is_highlight_question = any(keyword in message.lower() for keyword in highlight_keywords)
        is_summary_question = any(keyword in message.lower() for keyword in summary_keywords)
        
        if is_highlight_question or is_summary_question:
            # í•˜ì´ë¼ì´íŠ¸ í”„ë ˆì„ ì„ íƒ (ë‹¤ì–‘ì„± ê¸°ë°˜)
            highlight_frames = []
            
            # ì „ì²´ í”„ë ˆì„ì„ 5-7ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ ì„œ ëŒ€í‘œ í”„ë ˆì„ ì„ íƒ
            if len(self.frames) > 0:
                num_highlights = min(7, len(self.frames))  # ìµœëŒ€ 7ê°œ
                step = max(1, len(self.frames) // num_highlights)
                
                for i in range(0, len(self.frames), step):
                    if len(highlight_frames) < num_highlights:
                        frame = self.frames[i]
                        # ì‚¬ëŒì´ ë§ê±°ë‚˜ ìº¡ì…˜ì´ ê¸´ í”„ë ˆì„ ìš°ì„ 
                        persons = frame.get('persons', [])
                        caption = frame.get('caption', '')
                        frame_copy = frame.copy()
                        frame_copy['highlight_score'] = len(persons) + len(caption) / 10
                        highlight_frames.append(frame_copy)
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 5ê°œ ì„ íƒ
                highlight_frames.sort(key=lambda x: x.get('highlight_score', 0), reverse=True)
                highlight_frames = highlight_frames[:5]
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ì¬ì •ë ¬
                highlight_frames.sort(key=lambda x: x.get('timestamp', 0))
            
            if highlight_frames:
                result['frames'] = highlight_frames
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in highlight_frames
                ]
                
                # í•˜ì´ë¼ì´íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                highlight_context = f"""ğŸ¬ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸ ì¥ë©´ ({len(highlight_frames)}ê°œ):

"""
                for i, frame in enumerate(highlight_frames, 1):
                    timestamp = frame.get('timestamp', 0)
                    caption = frame.get('caption', '')
                    persons = frame.get('persons', [])
                    highlight_context += f"{i}. [{timestamp:.1f}ì´ˆ] {caption[:150]}\n"
                    highlight_context += f"   - ë“±ì¥ ì¸ë¬¼: {len(persons)}ëª…\n\n"
                
                highlight_context += f"\nì§ˆë¬¸: {message}\n"
                
                # ë‹¤ì¤‘ AIë¡œ ë‹µë³€ ìƒì„±
                ai_result = self.generate_answer_with_multi_ai(highlight_context, highlight_frames)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
            else:
                result['answer'] = "í•˜ì´ë¼ì´íŠ¸ ì¥ë©´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return result
        
        # 3. ì‚¬ëŒ ìˆ˜ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        people_count_keywords = ['ëª‡ëª…', 'ëª‡ ëª…', 'ì‚¬ëŒ ìˆ˜', 'ì¸ì›', 'how many people', 'how many person']
        is_people_count_question = any(keyword in message.lower() for keyword in people_count_keywords)
        
        if is_people_count_question:
            # ì‚¬ëŒ ìˆ˜ ë¶„ì„
            count_analysis = self.analyze_people_count()
            
            # ì¦ê±° í”„ë ˆì„ ì°¾ê¸° (ìµœëŒ€ ì¹´ìš´íŠ¸ê°€ ë‚˜ì˜¨ í”„ë ˆì„)
            evidence_frames = []
            if count_analysis['evidence']:
                max_count = count_analysis['estimated_count']
                for evidence in count_analysis['evidence']:
                    if evidence['count'] == max_count:
                        # í•´ë‹¹ íƒ€ì„ìŠ¤íƒ¬í”„ì˜ í”„ë ˆì„ ì°¾ê¸°
                        for frame in self.frames:
                            if frame.get('timestamp') == evidence['timestamp']:
                                evidence_frames.append(frame)
                                break
            
            if evidence_frames:
                result['frames'] = evidence_frames
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in evidence_frames
                ]
            
            # ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ AI ë‹µë³€ ìƒì„±
            enhanced_context = f"""ğŸ¯ ì¤‘ìš”: ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì‚¬ëŒ ìˆ˜ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”. ê°™ì€ ì‚¬ëŒë“¤ì´ ì—¬ëŸ¬ í”„ë ˆì„ì— ë°˜ë³µ ë“±ì¥í•˜ë¯€ë¡œ ì¤‘ë³µ ì¹´ìš´íŒ…í•˜ì§€ ë§ˆì„¸ìš”!

ì˜ìƒ ì „ì²´ ì‚¬ëŒ ìˆ˜ ë¶„ì„ ê²°ê³¼:
- ì¶”ì • ì¸ì›: {count_analysis['estimated_count']}ëª…
- ì‹ ë¢°ë„: {count_analysis['confidence']}
- í•µì‹¬ ê·¼ê±°: {count_analysis['explanation']}

í”„ë ˆì„ë³„ ëª…ì‹œëœ ì¸ì› ìˆ˜:
"""
            if count_analysis['evidence']:
                for i, ev in enumerate(count_analysis['evidence'][:5], 1):
                    enhanced_context += f"{i}. [{ev['timestamp']:.1f}ì´ˆ] {ev['count']}ëª… ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë¨\n"
                
                max_count = max([ev['count'] for ev in count_analysis['evidence']])
                enhanced_context += f"\nâœ… ê²°ë¡ : í•œ ì¥ë©´ì—ì„œ ìµœëŒ€ {max_count}ëª…ì´ ë“±ì¥í•˜ë©°, ì´ëŠ” ê°™ì€ ì‚¬ëŒë“¤ì´ ë‹¤ë¥¸ í”„ë ˆì„ì—ë„ ë‚˜íƒ€ë‚˜ë¯€ë¡œ ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì‚¬ëŒ ìˆ˜ëŠ” ì•½ {max_count}ëª…ì…ë‹ˆë‹¤.\n"
            
            enhanced_context += f"\nâš ï¸ ì£¼ì˜: ê° í”„ë ˆì„ì˜ ì‚¬ëŒ ìˆ˜ë¥¼ í•©ì‚°í•˜ì§€ ë§ê³ , ì˜ìƒ ì „ì²´ì˜ ê³ ìœ í•œ ì¸ì›ì„ ë‹µë³€í•˜ì„¸ìš”.\n"
            enhanced_context += f"\nì›ë˜ ì§ˆë¬¸: {message}"
            
            # ë‹¤ì¤‘ AIë¡œ ë‹µë³€ ìƒì„± (ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            ai_result = self.generate_answer_with_multi_ai(enhanced_context, evidence_frames if evidence_frames else None)
            if isinstance(ai_result, dict):
                result['answer'] = ai_result.get('integrated', '')
                result['individual_responses'] = ai_result.get('individual', {})
            else:
                result['answer'] = ai_result
            
            return result
        
        # 4. ì„±ë¹„ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        gender_ratio_keywords = ['ì„±ë¹„', 'ë‚¨ë…€ë¹„', 'ì„±ë³„', 'ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨ì', 'ì—¬ì', 'gender ratio', 'male female']
        is_gender_ratio_question = any(keyword in message.lower() for keyword in gender_ratio_keywords)
        
        if is_gender_ratio_question:
            # ì„±ë¹„ ë¶„ì„
            gender_analysis = self.analyze_gender_ratio()
            
            # ì¦ê±° í”„ë ˆì„ ì°¾ê¸°
            evidence_frames = []
            if gender_analysis['evidence']:
                for evidence in gender_analysis['evidence'][:3]:  # ìµœëŒ€ 3ê°œ
                    for frame in self.frames:
                        if frame.get('timestamp') == evidence['timestamp']:
                            evidence_frames.append(frame)
                            break
            
            if evidence_frames:
                result['frames'] = evidence_frames
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in evidence_frames
                ]
            
            # ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ AI ë‹µë³€ ìƒì„±
            enhanced_context = f"""ğŸ¯ ì¤‘ìš”: ì˜ìƒì˜ ì„±ë¹„(ë‚¨ë…€ ë¹„ìœ¨)ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”!

ì˜ìƒ ì„±ë¹„ ë¶„ì„ ê²°ê³¼:
- ë‚¨ì„±: {gender_analysis['male_count']}ëª… ({gender_analysis['male_ratio']:.1f}%)
- ì—¬ì„±: {gender_analysis['female_count']}ëª… ({gender_analysis['female_ratio']:.1f}%)
- ì„±ë³„ ëª…ì‹œëœ ì´ ì¸ì›: {gender_analysis['total_gendered']}ëª…
- ì‹ ë¢°ë„: {gender_analysis['confidence']}
- ë¶„ì„ ê·¼ê±°: {gender_analysis['explanation']}

í”„ë ˆì„ë³„ ì„±ë³„ ì •ë³´:
"""
            if gender_analysis['evidence']:
                for i, ev in enumerate(gender_analysis['evidence'][:5], 1):
                    enhanced_context += f"{i}. [{ev['timestamp']:.1f}ì´ˆ] ë‚¨ì„± {ev['males']}ëª…, ì—¬ì„± {ev['females']}ëª…\n"
            
            enhanced_context += f"\nâš ï¸ ì£¼ì˜: ì„±ë³„ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ì¸ë¬¼ë„ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì „ì²´ ì¸ì› ìˆ˜ì™€ ì°¨ì´ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            enhanced_context += f"\nì›ë˜ ì§ˆë¬¸: {message}"
            
            # ë‹¤ì¤‘ AIë¡œ ë‹µë³€ ìƒì„±
            ai_result = self.generate_answer_with_multi_ai(enhanced_context, evidence_frames if evidence_frames else None)
            if isinstance(ai_result, dict):
                result['answer'] = ai_result.get('integrated', '')
                result['individual_responses'] = ai_result.get('individual', {})
            else:
                result['answer'] = ai_result
            
            return result
        
        # 5. ìƒ‰ìƒ ê²€ìƒ‰ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        color_keywords = {
            'ë¶„í™': 'pink', 'í•‘í¬': 'pink', 'pink': 'pink',
            'ë¹¨ê°•': 'red', 'ë¹¨ê°„': 'red', 'red': 'red',
            'íŒŒë‘': 'blue', 'íŒŒë€': 'blue', 'blue': 'blue',
            'ë…¸ë‘': 'yellow', 'ë…¸ë€': 'yellow', 'yellow': 'yellow',
            'ì´ˆë¡': 'green', 'ë…¹ìƒ‰': 'green', 'green': 'green',
            'í•˜ì–‘': 'white', 'í°': 'white', 'white': 'white',
            'ê²€ì •': 'black', 'ê²€ì€': 'black', 'black': 'black',
            'ì£¼í™©': 'orange', 'ì˜¤ë Œì§€': 'orange', 'orange': 'orange',
            'ë³´ë¼': 'purple', 'purple': 'purple',
            'íšŒìƒ‰': 'gray', 'gray': 'gray', 'grey': 'gray'
        }
        
        found_color = None
        for korean, english in color_keywords.items():
            if korean in message.lower():
                found_color = english
                break
        
        if found_color:
            # ìƒ‰ìƒ ê¸°ë°˜ ê²€ìƒ‰
            context_frames = self.search_frames_by_color(found_color)
            
            if context_frames:
                result['frames'] = context_frames[:10]  # ìµœëŒ€ 10ê°œ
                result['frame_images'] = [
                    frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                    for frame in context_frames[:10]
                ]
                
                # ë‹µë³€ ìƒì„± (ë‹¤ì¤‘ AI)
                ai_result = self.generate_answer_with_multi_ai(message, context_frames)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
            else:
                result['answer'] = f"ì˜ìƒì—ì„œ {found_color} ìƒ‰ìƒì˜ ì˜·ì„ ì…ì€ ì‚¬ëŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        else:
            # ì¼ë°˜ ì˜ìƒ ì§ˆë¬¸ (í‚¤ì›Œë“œ ê²€ìƒ‰)
            # ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (ë¶ˆìš©ì–´ ì œê±°)
            stopwords = ['ë³´ì—¬ì¤˜', 'ì•Œë ¤ì¤˜', 'ìˆë‚˜ìš”', 'ë‚˜ì™€', 'ë“±ì¥', 'ì¥ë©´', 'ë‚˜ì˜¤ëŠ”', 'í•˜ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜']
            keywords = [word for word in message.split() if len(word) > 1 and word not in stopwords]
            
            # íŠ¹ìˆ˜ íŒ¨í„´ ë§¤ì¹­ (ë” ì •í™•í•œ ê²€ìƒ‰)
            import re
            # "ëª¨ìì“´ ì‚¬ëŒ" -> "hat", "cap", "ëª¨ì"
            if 'ëª¨ì' in message:
                keywords.extend(['hat', 'cap', 'beanie'])
            # "ê¸°íƒ€ ì¹˜ëŠ”" -> "guitar"
            if 'ê¸°íƒ€' in message:
                keywords.extend(['guitar'])
            # "ì»¤í”¼" -> "coffee", "cup"
            if 'ì»¤í”¼' in message:
                keywords.extend(['coffee', 'cup'])
            
            if keywords:
                context_frames = self.search_frames_by_keywords(keywords[:5])  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
                
                if context_frames:
                    result['frames'] = context_frames[:10]
                    result['frame_images'] = [
                        frame.get('frame_image_path') or f"images/video{self.video_id}_frame{frame.get('image_id')}.jpg"
                        for frame in context_frames[:10]
                    ]
                
                # ë‹µë³€ ìƒì„± (ë‹¤ì¤‘ AI)
                ai_result = self.generate_answer_with_multi_ai(message, context_frames if context_frames else None)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
            else:
                # ì „ì²´ ì˜ìƒ ìš”ì•½ ì§ˆë¬¸
                ai_result = self.generate_answer_with_multi_ai(message, None)
                if isinstance(ai_result, dict):
                    result['answer'] = ai_result.get('integrated', '')
                    result['individual_responses'] = ai_result.get('individual', {})
                else:
                    result['answer'] = ai_result
        
        return result


def get_video_chat_handler(video_id, video):
    """ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return EnhancedVideoChatHandler(video_id, video)

