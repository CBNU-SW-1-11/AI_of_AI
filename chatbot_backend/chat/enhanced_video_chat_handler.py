"""
ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ v3.0 - ëŒ€í­ ê°œì„  ë²„ì „
=======================================

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. ì—­í•  ëª…í™• ë¶„ë¦¬: Ollama(ë¶„ì„) vs ìƒìš© LLM(ë‹µë³€)
2. ìºì‹± ì‹œìŠ¤í…œ: ë°˜ë³µ ë¶„ì„ ë°©ì§€
3. í´ë°± ì²´ì¸: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ LLM ì„ íƒ
4. ì»¨í…ìŠ¤íŠ¸ ìµœì í™”: í† í° íš¨ìœ¨ì„±
5. ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
6. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import os
import json
import logging
import time
from functools import lru_cache
from typing import Dict, List, Optional, Tuple
import ollama
from django.conf import settings
from django.core.cache import cache

logger = logging.getLogger(__name__)


class LLMManager:
    """LLM ê´€ë¦¬ í´ë˜ìŠ¤ - ìš°ì„ ìˆœìœ„ ê¸°ë°˜ í´ë°± ì²´ì¸"""
    
    # LLM ìš°ì„ ìˆœìœ„ ì •ì˜ (ë¹„ìš©/ì„±ëŠ¥/ì†ë„ ê³ ë ¤)
    LLM_PRIORITY = [
        {
            'key': 'gemini-2.0-flash-lite',
            'name': 'Gemini Flash',
            'cost': 'low',
            'speed': 'fast',
            'quality': 'high'
        },
        {
            'key': 'gpt-4o-mini',
            'name': 'GPT-4o Mini',
            'cost': 'low',
            'speed': 'fast',
            'quality': 'high'
        },
        {
            'key': 'claude-3.5-haiku',
            'name': 'Claude Haiku',
            'cost': 'low',
            'speed': 'fast',
            'quality': 'high'
        },
        {
            'key': 'clova-hcx-dash-001',
            'name': 'HCX-DASH',
            'cost': 'medium',
            'speed': 'medium',
            'quality': 'very_high',
            'use_case': 'integration'  # í†µí•© ì „ìš©
        }
    ]
    
    def __init__(self):
        self.chatbots = self._load_chatbots()
        self.available_models = self._check_available_models()
        logger.info(f"âœ… LLM Manager ì´ˆê¸°í™”: {len(self.available_models)}ê°œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
    
    def _load_chatbots(self) -> Dict:
        """chatbots ë¡œë“œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)"""
        try:
            from core.utils.chatbot import chatbots
            logger.info("âœ… chatbots import ì„±ê³µ (core.utils.chatbot)")
            return chatbots
        except ImportError:
            try:
                from utils.chatbot import chatbots
                logger.info("âœ… chatbots import ì„±ê³µ (utils.chatbot)")
                return chatbots
            except Exception as e:
                logger.error(f"âŒ chatbots import ì‹¤íŒ¨: {e}")
                return {}
    
    def _check_available_models(self) -> List[Dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì²´í¬"""
        available = []
        for model_info in self.LLM_PRIORITY:
            key = model_info['key']
            if key in self.chatbots:
                try:
                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ API í‚¤ ìœ íš¨ì„± ì²´í¬
                    bot = self.chatbots[key]
                    # ì‹¤ì œë¡œëŠ” í…ŒìŠ¤íŠ¸í•˜ì§€ ì•Šê³  ì¡´ì¬ë§Œ í™•ì¸ (API ë¹„ìš© ì ˆì•½)
                    available.append(model_info)
                    logger.info(f"   âœ“ {model_info['name']} ì‚¬ìš© ê°€ëŠ¥")
                except Exception as e:
                    logger.warning(f"   âœ— {model_info['name']} ì‚¬ìš© ë¶ˆê°€: {e}")
            else:
                logger.debug(f"   âœ— {model_info['name']} ë¯¸ë“±ë¡")
        
        return available
    
    def get_response(self, prompt: str, use_case: str = 'general') -> Optional[Tuple[str, str]]:
        """
        LLM ì‘ë‹µ ìƒì„± (í´ë°± ì²´ì¸)
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            use_case: 'general' ë˜ëŠ” 'integration'
        
        Returns:
            (ì‘ë‹µ, ëª¨ë¸ëª…) ë˜ëŠ” None
        """
        # use_caseì— ë§ëŠ” ëª¨ë¸ í•„í„°ë§
        candidates = [m for m in self.available_models 
                     if use_case == 'general' or m.get('use_case') == use_case]
        
        if not candidates:
            candidates = self.available_models  # í´ë°±: ëª¨ë“  ëª¨ë¸ ì‹œë„
        
        # ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì‹œë„
        for model_info in candidates:
            try:
                start_time = time.time()
                bot = self.chatbots[model_info['key']]
                response = bot.chat(prompt)
                elapsed = time.time() - start_time
                
                logger.info(f"âœ… {model_info['name']} ì‘ë‹µ ì„±ê³µ ({elapsed:.2f}s)")
                return response, model_info['name']
                
            except Exception as e:
                logger.warning(f"âš ï¸ {model_info['name']} ì‹¤íŒ¨: {e}")
                continue
        
        logger.error("âŒ ëª¨ë“  LLM ì‹¤íŒ¨")
        return None
    
    def get_multi_responses(self, prompt: str, max_models: int = 3) -> Dict[str, str]:
        """
        ì—¬ëŸ¬ LLMì—ì„œ ì‘ë‹µ ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„)
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            max_models: ìµœëŒ€ ì‚¬ìš© ëª¨ë¸ ìˆ˜
        
        Returns:
            {ëª¨ë¸ëª…: ì‘ë‹µ} ë”•ì…”ë„ˆë¦¬
        """
        responses = {}
        
        # í†µí•© ì „ìš© ëª¨ë¸ ì œì™¸
        candidates = [m for m in self.available_models[:max_models] 
                     if m.get('use_case') != 'integration']
        
        for model_info in candidates:
            try:
                bot = self.chatbots[model_info['key']]
                response = bot.chat(prompt)
                responses[model_info['name']] = response
                logger.info(f"âœ… {model_info['name']} ì‘ë‹µ ìˆ˜ì§‘")
            except Exception as e:
                logger.warning(f"âš ï¸ {model_info['name']} ì‹¤íŒ¨: {e}")
        
        return responses


class FrameAnalyzer:
    """í”„ë ˆì„ ë¶„ì„ í´ë˜ìŠ¤ - Ollama ì „ë‹´"""
    
    def __init__(self, frames: List[Dict]):
        self.frames = frames
    
    @lru_cache(maxsize=100)
    def search_by_keywords(self, keywords_tuple: Tuple[str]) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ í”„ë ˆì„ ê²€ìƒ‰ (ìºì‹±)"""
        keywords = list(keywords_tuple)
        found_frames = []
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            match_score = sum(1 for kw in keywords if kw.lower() in caption)
            
            if match_score > 0:
                frame_copy = frame.copy()
                frame_copy['match_score'] = match_score
                found_frames.append(frame_copy)
        
        found_frames.sort(key=lambda x: x['match_score'], reverse=True)
        return found_frames
    
    def search_by_color(self, color_name: str) -> List[Dict]:
        """ìƒ‰ìƒìœ¼ë¡œ í”„ë ˆì„ ê²€ìƒ‰"""
        # ê¸°ì¡´ ë¡œì§ ìœ ì§€
        korean_to_english = {
            'ë¶„í™': 'pink', 'í•‘í¬': 'pink',
            'ë¹¨ê°•': 'red', 'íŒŒë‘': 'blue',
            'ë…¸ë‘': 'yellow', 'ì´ˆë¡': 'green',
            'í°': 'white', 'ê²€ì •': 'black',
            'ë³´ë¼': 'purple', 'íšŒìƒ‰': 'gray'
        }
        
        base_color = korean_to_english.get(color_name.lower(), color_name.lower())
        color_synonyms = {
            'pink': ['pink', 'rose', 'magenta'],
            'red': ['red', 'crimson'],
            'blue': ['blue', 'navy', 'azure'],
            'yellow': ['yellow', 'gold'],
            'green': ['green', 'lime'],
            'purple': ['purple', 'violet'],
            'white': ['white', 'ivory'],
            'black': ['black'],
            'gray': ['gray', 'grey', 'silver']
        }
        
        synonyms = color_synonyms.get(base_color, [base_color])
        found_frames = []
        
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            if any(word in caption for word in synonyms):
                frame_copy = frame.copy()
                frame_copy['match_score'] = 3  # ìº¡ì…˜ ë§¤ì¹­ ìš°ì„ 
                found_frames.append(frame_copy)
        
        found_frames.sort(key=lambda x: x['match_score'], reverse=True)
        return found_frames[:5]
    
    def analyze_people_count(self) -> Dict:
        """ì‚¬ëŒ ìˆ˜ ë¶„ì„"""
        number_words = {
            'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,
            'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10
        }
        
        people_counts = []
        for frame in self.frames:
            caption = frame.get('caption', '').lower()
            timestamp = frame.get('timestamp', 0)
            
            for num_word, num in number_words.items():
                patterns = [f'{num_word} people', f'{num_word} individuals']
                if any(p in caption for p in patterns):
                    people_counts.append({
                        'timestamp': timestamp,
                        'count': num,
                        'caption': caption[:100]
                    })
                    break
        
        if people_counts:
            max_count = max(people_counts, key=lambda x: x['count'])['count']
            return {
                'estimated_count': max_count,
                'confidence': 'high',
                'evidence': people_counts,
                'explanation': f"ì˜ìƒì—ì„œ ìµœëŒ€ {max_count}ëª…ì´ ë“±ì¥í•©ë‹ˆë‹¤."
            }
        else:
            return {
                'estimated_count': 'unknown',
                'confidence': 'low',
                'evidence': [],
                'explanation': "ì‚¬ëŒ ìˆ˜ë¥¼ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
    
    def get_highlights(self, max_count: int = 5) -> List[Dict]:
        """í•˜ì´ë¼ì´íŠ¸ í”„ë ˆì„ ì„ íƒ"""
        if not self.frames:
            return []
        
        # í”„ë ˆì„ì„ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
        step = max(1, len(self.frames) // (max_count + 2))
        sampled = self.frames[step::step][:max_count]
        
        # ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
        for frame in sampled:
            persons = frame.get('persons', [])
            caption = frame.get('caption', '')
            frame['highlight_score'] = len(persons) * 2 + len(caption) / 50
        
        sampled.sort(key=lambda x: x['highlight_score'], reverse=True)
        return sampled


class ContextBuilder:
    """ì»¨í…ìŠ¤íŠ¸ ìƒì„± ìµœì í™” í´ë˜ìŠ¤"""
    
    MAX_CAPTION_LENGTH = 150  # ìº¡ì…˜ ìµœëŒ€ ê¸¸ì´
    MAX_FRAMES_IN_CONTEXT = 5  # ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
    
    @staticmethod
    def build_video_context(frames: List[Dict], video_duration: float) -> str:
        """ì˜ìƒ ì „ì²´ ì»¨í…ìŠ¤íŠ¸"""
        context = f"ì˜ìƒ ì •ë³´: {len(frames)}ê°œ í”„ë ˆì„, {video_duration:.1f}ì´ˆ\n\n"
        
        # ìƒ˜í”Œë§ëœ í”„ë ˆì„ ìš”ì•½
        step = max(1, len(frames) // 5)
        for i, frame in enumerate(frames[::step][:5], 1):
            ts = frame.get('timestamp', 0)
            caption = frame.get('caption', '')[:ContextBuilder.MAX_CAPTION_LENGTH]
            context += f"[{ts:.1f}s] {caption}\n"
        
        return context
    
    @staticmethod
    def build_search_context(frames: List[Dict], query: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸"""
        context = f"'{query}' ê²€ìƒ‰ ê²°ê³¼ ({len(frames)}ê°œ í”„ë ˆì„):\n\n"
        
        for i, frame in enumerate(frames[:ContextBuilder.MAX_FRAMES_IN_CONTEXT], 1):
            ts = frame.get('timestamp', 0)
            caption = frame.get('caption', '')[:ContextBuilder.MAX_CAPTION_LENGTH]
            score = frame.get('match_score', 0)
            context += f"{i}. [{ts:.1f}s, ì ìˆ˜:{score}] {caption}\n"
        
        return context
    
    @staticmethod
    def build_prompt(context: str, question: str, language: str = "í•œêµ­ì–´") -> str:
        """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""{context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
- {language}ë¡œë§Œ ì‘ì„±
- í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ (2-4ë¬¸ì¥)
- ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€
- ë¶ˆí•„ìš”í•œ ì„¤ëª… ìƒëµ

ë‹µë³€:"""


class EnhancedVideoChatHandler:
    """ê°œì„ ëœ ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ v3.0"""
    
    def __init__(self, video_id, video):
        self.video_id = video_id
        self.video = video
        self.frames = []
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.llm_manager = LLMManager()
        self._load_analysis_data()
        self.frame_analyzer = FrameAnalyzer(self.frames)
        self.context_builder = ContextBuilder()
        
        logger.info(f"âœ… ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ (video_id={video_id})")
    
    def _load_analysis_data(self):
        """ì˜ìƒ ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            video_name = self.video.original_name or self.video.filename
            meta_db_path = os.path.join(settings.MEDIA_ROOT, f"{video_name}-meta_db.json")
            
            if os.path.exists(meta_db_path):
                with open(meta_db_path, 'r', encoding='utf-8') as f:
                    meta_db = json.load(f)
                self.frames = meta_db.get('frame', [])
                logger.info(f"âœ… Meta DB ë¡œë“œ: {len(self.frames)}ê°œ í”„ë ˆì„")
            else:
                logger.warning(f"âŒ Meta DB íŒŒì¼ ì—†ìŒ: {meta_db_path}")
        
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _is_video_question(self, message: str) -> bool:
        """ì˜ìƒ ê´€ë ¨ ì§ˆë¬¸ íŒë‹¨"""
        video_keywords = [
            'ì˜ìƒ', 'video', 'ì‚¬ëŒ', 'people', 'ì˜·', 'clothing',
            'ìƒ‰ìƒ', 'color', 'ì¥ë©´', 'scene', 'ëª‡', 'how many',
            'ìš”ì•½', 'summary', 'í•˜ì´ë¼ì´íŠ¸', 'highlight'
        ]
        message_lower = message.lower()
        return any(kw in message_lower for kw in video_keywords)
    
    def _detect_question_type(self, message: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ê°ì§€"""
        message_lower = message.lower()
        
        if any(kw in message_lower for kw in ['ìš”ì•½', 'summary', 'í•˜ì´ë¼ì´íŠ¸', 'highlight']):
            return 'summary'
        elif any(kw in message_lower for kw in ['ëª‡ëª…', 'ëª‡ ëª…', 'ì‚¬ëŒ ìˆ˜', 'how many people']):
            return 'people_count'
        elif any(kw in message_lower for kw in ['ì„±ë¹„', 'ë‚¨ë…€', 'gender']):
            return 'gender'
        elif any(color in message_lower for color in ['ë¶„í™', 'í•‘í¬', 'ë¹¨ê°•', 'íŒŒë‘', 'ë…¸ë‘']):
            return 'color_search'
        else:
            return 'general'
    
    def _handle_summary_question(self, message: str) -> Dict:
        """ìš”ì•½/í•˜ì´ë¼ì´íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬"""
        highlight_frames = self.frame_analyzer.get_highlights(max_count=5)
        
        if not highlight_frames:
            return {
                'answer': 'í•˜ì´ë¼ì´íŠ¸ ì¥ë©´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'individual_responses': {},
                'frames': [],
                'frame_images': []
            }
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = "ğŸ¬ ì˜ìƒ í•˜ì´ë¼ì´íŠ¸:\n\n"
        for i, frame in enumerate(highlight_frames, 1):
            ts = frame.get('timestamp', 0)
            caption = frame.get('caption', '')[:150]
            context += f"{i}. [{ts:.1f}ì´ˆ] {caption}\n"
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.context_builder.build_prompt(context, message)
        
        # LLM ì‘ë‹µ
        result = self.llm_manager.get_response(prompt)
        
        if result:
            answer, model_name = result
            return {
                'answer': answer,
                'individual_responses': {model_name: answer},
                'frames': highlight_frames,
                'frame_images': [
                    f"images/video{self.video_id}_frame{f.get('image_id')}.jpg"
                    for f in highlight_frames
                ]
            }
        else:
            return {
                'answer': 'ì£„ì†¡í•©ë‹ˆë‹¤. AI ëª¨ë¸ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                'individual_responses': {},
                'frames': highlight_frames,
                'frame_images': []
            }
    
    def _handle_people_count_question(self, message: str) -> Dict:
        """ì‚¬ëŒ ìˆ˜ ì§ˆë¬¸ ì²˜ë¦¬"""
        analysis = self.frame_analyzer.analyze_people_count()
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = f"""ğŸ¯ ì˜ìƒ ì‚¬ëŒ ìˆ˜ ë¶„ì„:
- ì¶”ì • ì¸ì›: {analysis['estimated_count']}ëª…
- ì‹ ë¢°ë„: {analysis['confidence']}
- ì„¤ëª…: {analysis['explanation']}

âš ï¸ ê°™ì€ ì‚¬ëŒì´ ì—¬ëŸ¬ í”„ë ˆì„ì— ë“±ì¥í•˜ë¯€ë¡œ ì¤‘ë³µ ì œê±°ëœ ê³ ìœ  ì¸ì›ì…ë‹ˆë‹¤."""
        
        prompt = self.context_builder.build_prompt(context, message)
        result = self.llm_manager.get_response(prompt)
        
        if result:
            answer, model_name = result
            return {
                'answer': answer,
                'individual_responses': {model_name: answer},
                'frames': [],
                'frame_images': []
            }
        else:
            return {
                'answer': f"ì˜ìƒì—ì„œ ì•½ {analysis['estimated_count']}ëª…ì´ ë“±ì¥í•©ë‹ˆë‹¤.",
                'individual_responses': {},
                'frames': [],
                'frame_images': []
            }
    
    def _handle_color_search(self, message: str) -> Dict:
        """ìƒ‰ìƒ ê²€ìƒ‰ ì§ˆë¬¸ ì²˜ë¦¬"""
        # ìƒ‰ìƒ ì¶”ì¶œ
        color_map = {
            'ë¶„í™': 'pink', 'í•‘í¬': 'pink', 'ë¹¨ê°•': 'red',
            'íŒŒë‘': 'blue', 'ë…¸ë‘': 'yellow', 'ì´ˆë¡': 'green'
        }
        
        found_color = None
        for korean, english in color_map.items():
            if korean in message or english in message.lower():
                found_color = english
                break
        
        if not found_color:
            return {
                'answer': 'ìƒ‰ìƒì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'individual_responses': {},
                'frames': [],
                'frame_images': []
            }
        
        # í”„ë ˆì„ ê²€ìƒ‰
        frames = self.frame_analyzer.search_by_color(found_color)
        
        if not frames:
            return {
                'answer': f"ì˜ìƒì—ì„œ {found_color} ìƒ‰ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                'individual_responses': {},
                'frames': [],
                'frame_images': []
            }
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self.context_builder.build_search_context(frames, f"{found_color} ìƒ‰ìƒ")
        prompt = self.context_builder.build_prompt(context, message)
        
        result = self.llm_manager.get_response(prompt)
        
        if result:
            answer, model_name = result
            return {
                'answer': answer,
                'individual_responses': {model_name: answer},
                'frames': frames[:5],
                'frame_images': [
                    f"images/video{self.video_id}_frame{f.get('image_id')}.jpg"
                    for f in frames[:5]
                ]
            }
        else:
            return {
                'answer': f"{found_color} ìƒ‰ìƒì˜ ì˜·ì„ ì…ì€ ì‚¬ëŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
                'individual_responses': {},
                'frames': frames[:5],
                'frame_images': []
            }
    
    def _handle_general_question(self, message: str) -> Dict:
        """ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬"""
        # ì˜ìƒ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        if self._is_video_question(message):
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ í† í°í™”)
            keywords = [w for w in message.split() if len(w) > 1]
            keywords_tuple = tuple(keywords[:5])  # ìºì‹±ì„ ìœ„í•´ íŠœí”Œë¡œ ë³€í™˜
            
            # í”„ë ˆì„ ê²€ìƒ‰
            frames = self.frame_analyzer.search_by_keywords(keywords_tuple)
            
            if frames:
                context = self.context_builder.build_search_context(frames, message)
            else:
                context = self.context_builder.build_video_context(
                    self.frames, 
                    self.video.duration
                )
            
            prompt = self.context_builder.build_prompt(context, message)
            result = self.llm_manager.get_response(prompt)
            
            if result:
                answer, model_name = result
                return {
                    'answer': answer,
                    'individual_responses': {model_name: answer},
                    'frames': frames[:5] if frames else [],
                    'frame_images': [
                        f"images/video{self.video_id}_frame{f.get('image_id')}.jpg"
                        for f in frames[:5]
                    ] if frames else []
                }
        
        # ì¼ë°˜ ëŒ€í™” (ì˜ìƒ ë¬´ê´€)
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {message}

í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš” (2-3ë¬¸ì¥)."""
        
        result = self.llm_manager.get_response(prompt)
        
        if result:
            answer, model_name = result
            return {
                'answer': answer,
                'individual_responses': {model_name: answer},
                'frames': [],
                'frame_images': []
            }
        else:
            return {
                'answer': 'ì£„ì†¡í•©ë‹ˆë‹¤. AI ëª¨ë¸ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                'individual_responses': {},
                'frames': [],
                'frame_images': []
            }
    
    def process_message(self, message: str) -> Dict:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        
        Returns:
            dict: {
                'answer': str,
                'individual_responses': dict,
                'frames': list,
                'frame_images': list,
                'is_video_related': bool
            }
        """
        start_time = time.time()
        
        # ì§ˆë¬¸ ìœ í˜• ê°ì§€
        question_type = self._detect_question_type(message)
        logger.info(f"ğŸ” ì§ˆë¬¸ ìœ í˜•: {question_type}")
        
        # ìœ í˜•ë³„ ì²˜ë¦¬
        handlers = {
            'summary': self._handle_summary_question,
            'people_count': self._handle_people_count_question,
            'color_search': self._handle_color_search,
            'gender': self._handle_general_question,  # ì„±ë¹„ëŠ” ì¼ë°˜ìœ¼ë¡œ ì²˜ë¦¬
            'general': self._handle_general_question
        }
        
        handler = handlers.get(question_type, self._handle_general_question)
        result = handler(message)
        
        # ë©”íƒ€ ì •ë³´ ì¶”ê°€
        result['is_video_related'] = self._is_video_question(message)
        result['question_type'] = question_type
        result['processing_time'] = time.time() - start_time
        
        logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ ({result['processing_time']:.2f}s)")
        
        return result


def get_video_chat_handler(video_id, video):
    """ì˜ìƒ ì±„íŒ… í•¸ë“¤ëŸ¬ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return EnhancedVideoChatHandler(video_id, video)